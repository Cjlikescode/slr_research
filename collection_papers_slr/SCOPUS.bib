Scopus
EXPORT DATE: 13 June 2025

@BOOK{Rajkumar2025271,
	author = {Rajkumar, M. and Ch, Viswanathasarma and Anandhi, R.J. and Anandhasilambarasan, D. and Prakash Yadav, Om and Dhanraj, Joshuva Arockia},
	title = {Natural Language Processing Using Soft Computing},
	year = {2025},
	journal = {Natural Language Processing for Software Engineering},
	pages = {271 – 282},
	doi = {10.1002/9781394272464.ch19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217322464&doi=10.1002%2f9781394272464.ch19&partnerID=40&md5=557d2bb21a47030e24d720e0110a76f0},
	abstract = {The fields of text mining and information retrieval were the origins of natural language processing (NLP), which was first developed from those fields. Throughout the years, several applications that are based on artificial intelligence have developed out of its initial domain. Some examples of these applications include machine translation, query expansion, robotic command detection, and many more. The origins of natural language processing (NLP) may be traced back to a variety of disciplines, such as psychology, mathematics, computer science, linguistics, computer engineering, electrical and electronic engineering, artificial intelligence, robotics, and computer science and information. This paper provides a comprehensive analysis of a wide variety of soft computing techniques to natural language processing (NLP). © 2025 Scrivener Publishing LLC.},
	author_keywords = {Natural language processing; NLP challenges; soft computing; support vector machine},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Peng2025,
	author = {Peng, Liwen and Jian, Songlei and Li, Minne and Kan, Zhigang and Qiao, Linbo and Li, Dongsheng},
	title = {A unified multimodal classification framework based on deep metric learning},
	year = {2025},
	journal = {Neural Networks},
	volume = {181},
	doi = {10.1016/j.neunet.2024.106747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205595950&doi=10.1016%2fj.neunet.2024.106747&partnerID=40&md5=d04cc090ea18379124f6d26eb8eb6231},
	abstract = {Multimodal classification algorithms play an essential role in multimodal machine learning, aiming to categorize distinct data points by analyzing data characteristics from multiple modalities. Extensive research has been conducted on distilling multimodal attributes and devising specialized fusion strategies for targeted classification tasks. Nevertheless, current algorithms mainly concentrate on a specific classification task and process data about the corresponding modalities. To address these limitations, we propose a unified multimodal classification framework proficient in handling diverse multimodal classification tasks and processing data from disparate modalities. UMCF is task-independent, and its unimodal feature extraction module can be adaptively substituted to accommodate data from diverse modalities. Moreover, we construct the multimodal learning scheme based on deep metric learning to mine latent characteristics within multimodal data. Specifically, we design the metric-based triplet learning to extract the intra-modal relationships within each modality and the contrastive pairwise learning to capture the inter-modal relationships across various modalities. Extensive experiments on two multimodal classification tasks, fake news detection and sentiment analysis, demonstrate that UMCF can extract multimodal data features and achieve superior classification performance than task-specific benchmarks. UMCF outperforms the best fake news detection baselines by 2.3% on average regarding F1 scores. © 2024},
	author_keywords = {Deep metric learning; Fake news detection; Multimodal classification; Multimodal learning; Sentiment analysis},
	keywords = {Algorithms; Deep Learning; Humans; Machine Learning; Neural Networks, Computer; Adversarial machine learning; Deep learning; Classification algorithm; Classification framework; Classification tasks; Deep metric learning; Fake news detection; Metric learning; Multi-modal; Multi-modal learning; Multimodal classification; Sentiment analysis; adult; algorithm; article; benchmarking; classification; classification algorithm; cohort analysis; diagnosis; disease management; disinformation; feature extraction; female; human; human experiment; learning; machine learning; male; sentiment analysis; algorithm; artificial neural network; deep learning; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Semary2024,
	author = {Semary, Noura A. and Ahmed, Wesam and Amin, Khalid and Pławiak, Paweł and Hammad, Mohamed},
	title = {Enhancing machine learning-based sentiment analysis through feature extraction techniques},
	year = {2024},
	journal = {PLoS ONE},
	volume = {19},
	number = {2 February},
	doi = {10.1371/journal.pone.0294968},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185345140&doi=10.1371%2fjournal.pone.0294968&partnerID=40&md5=a1395722deb89c6b2c89fef00476d440},
	abstract = {A crucial part of sentiment classification is featuring extraction because it involves extracting valuable information from text data, which affects the model’s performance. The goal of this paper is to help in selecting a suitable feature extraction method to enhance the performance of sentiment analysis tasks. In order to provide directions for future machine learning and feature extraction research, it is important to analyze and summarize feature extraction techniques methodically from a machine learning standpoint. There are several methods under consideration, including Bag-of-words (BOW), Word2Vector, N-gram, Term Frequency- Inverse Document Frequency (TF-IDF), Hashing Vectorizer (HV), and Global vector for word representation (GloVe). To prove the ability of each feature extractor, we applied it to the Twitter US airlines and Amazon musical instrument reviews datasets. Finally, we trained a random forest classifier using 70% of the training data and 30% of the testing data, enabling us to evaluate and compare the performance using different metrics. Based on our results, we find that the TD-IDF technique demonstrates superior performance, with an accuracy of 99% in the Amazon reviews dataset and 96% in the Twitter US airlines dataset. This study underscores the paramount significance of feature extraction in sentiment analysis, endowing pragmatic insights to elevate model performance and steer future research pursuits. Copyright: © 2024 A. Semary et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Algorithms; Humans; Machine Learning; Sentiment Analysis; Article; artificial neural network; benchmarking; classifier; data mining; decision tree; entropy; feature extraction; human; learning algorithm; long short term memory network; machine learning; prevalence; quantitative structure activity relation; random forest; sentiment analysis; support vector machine; algorithm; machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Faisal2025281,
	author = {Faisal, Syed Mohd and Khan, Wasim and Ishrat, Mohammad},
	title = {AI and financial risk management: Transforming risk mitigation with AI-driven insights and automation},
	year = {2025},
	journal = {Artificial Intelligence for Financial Risk Management and Analysis},
	pages = {281 – 305},
	doi = {10.4018/979-8-3373-1200-2.ch014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004404113&doi=10.4018%2f979-8-3373-1200-2.ch014&partnerID=40&md5=efdd9de807e4aa47843f3ad590716638},
	abstract = {Artificial Intelligence (AI) is revolutionizing financial risk management by improving risk identification, assessment, and mitigation through machine learning, natural language processing (NLP), and predictive analytics. Traditional methods struggle with scalability and real-time analysis, while AI-driven models enhance predictive accuracy, automate risk assessments, and optimize decision-making. This chapter explores AI's applications in credit risk evaluation, fraud detection, market risk modeling, portfolio optimization, and regulatory compliance, enabling financial institutions to proactively address risks. AI enhances fraud detection by identifying anomalies, improves market risk modeling with sentiment analysis and forecasting, and streamlines compliance through automated monitoring. Despite benefits, AI poses challenges like data privacy, algorithmic bias, and model interpretability. The study discusses ethical considerations, Explainable AI (XAI), AI-blockchain integration, edge computing, and AI-driven ESG risk analysis, shaping the future of financial risk management. © 2025 by IGI Global Scientific Publishing.},
	keywords = {Banking; Financial markets; Fintech; Investments; Risk perception; Sentiment analysis; Financial risk management; Fraud detection; Language processing; Machine-learning; Market risks; Natural languages; Risk Identification; Risk mitigation; Risk modeling; Risks assessments; Risk management},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Prajna2024,
	author = {Prajna, K.B. and Pinto, Reenal Sony and Lakshmishree, V.S. and Vrajesh, S.},
	title = {Visualizing Parts of Speech Tags by Analysing English Language Text},
	year = {2024},
	journal = {3rd IEEE International Conference on Distributed Computing and Electrical Circuits and Electronics, ICDCECE 2024},
	doi = {10.1109/ICDCECE60827.2024.10548901},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196800760&doi=10.1109%2fICDCECE60827.2024.10548901&partnerID=40&md5=6be4c4d7cfd03d215fb3fb8075ebaa58},
	abstract = {Part of Speech (POS) tagging is vital in natural language processing (NLP) for various applications. Hidden Markov Models (HMMs) have traditionally been used for this task, yet they struggle with capturing complex dependencies. This study explores Conditional Random Fields (CRFs) and their integration with Spacy for POS tagging. CRFs offer better sequence modelling capabilities, while Spacy provides rich linguistic features. Experimental evaluation demonstrates superiority of CRFs and CRF with Spacy over HMMs. They exhibit improved accuracy, particularly in capturing context and handling ambiguous sequence. The findings underscore the efficiency of advanced techniques like CRFs and their integration with comprehensive NLP libraries like Spacy for accurate POS tagging. Such methods are crucial for advancing NLP applications.  © 2024 IEEE.},
	author_keywords = {CRF; HMM; natural language processing; part of speech tagging; SpaCy},
	keywords = {Computational linguistics; Natural language processing systems; Syntactics; Conditional random field; Hidden-Markov models; Language processing; Natural language processing; Natural languages; Part of speech tagging; Part-of-speech tags; Parts-of-speech tagging; Random fields; Spacy; Hidden Markov models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pan2024,
	author = {Pan, Ruiying},
	title = {Multimodal fusion-powered English speaking robot},
	year = {2024},
	journal = {Frontiers in Neurorobotics},
	volume = {18},
	doi = {10.3389/fnbot.2024.1478181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210574279&doi=10.3389%2ffnbot.2024.1478181&partnerID=40&md5=488018dcd4526a13bcff2ebf52b203ee},
	abstract = {Introduction: Speech recognition and multimodal learning are two critical areas in machine learning. Current multimodal speech recognition systems often encounter challenges such as high computational demands and model complexity. Methods: To overcome these issues, we propose a novel framework-EnglishAL-Net, a Multimodal Fusion-powered English Speaking Robot. This framework leverages the ALBEF model, optimizing it for real-time speech and multimodal interaction, and incorporates a newly designed text and image editor to fuse visual and textual information. The robot processes dynamic spoken input through the integration of Neural Machine Translation (NMT), enhancing its ability to understand and respond to spoken language. Results and discussion: In the experimental section, we constructed a dataset containing various scenarios and oral instructions for testing. The results show that compared to traditional unimodal processing methods, our model significantly improves both language understanding accuracy and response time. This research not only enhances the performance of multimodal interaction in robots but also opens up new possibilities for applications of robotic technology in education, rescue, customer service, and other fields, holding significant theoretical and practical value. Copyright © 2024 Pan.},
	author_keywords = {ALBEF; cross-attention mechanism; multimodal robot; Neural Machine Translation (NMT); speech recognition},
	keywords = {Computer aided language translation; Educational robots; Modeling languages; Multipurpose robots; Neural machine translation; Robot applications; Robot learning; ALBEF; Attention mechanisms; Cross-attention mechanism; Machine translations; Multi-modal; Multi-modal fusion; Multi-modal learning; Multimodal Interaction; Multimodal robot; Neural machine translation; accuracy; Article; artificial neural network; convolutional neural network; crossmodal attention; deep learning; deep neural network; diagnostic accuracy; emotion; emotion recognition; gated recurrent unit network; hidden Markov model; human; long short term memory network; machine learning; natural language processing; nerve cell network; neural machine translation; recurrent neural network; speech discrimination; support vector machine; telecommunication; traditional unimodal processing method; Speech recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@BOOK{Saha2025341,
	author = {Saha, Soumitra and Lilhore, Umesh Kumar and Simaiya, Sarita},
	title = {Biomedical Research Enrichment Through Sentiment Analysis in Patient Feedback: A Natural Language Processing Approach},
	year = {2025},
	journal = {Multimodal Data Fusion for Bioinformatics Artificial Intelligence},
	pages = {341 – 374},
	doi = {10.1002/9781394269969.ch16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218016256&doi=10.1002%2f9781394269969.ch16&partnerID=40&md5=5423f70f8b763527b748c1adedae0d85},
	abstract = {This chapter consults the trajectory committed by utilizing patient feedback (PF) in the wake of biomedical research through sentimental analysis (SA) in natural language processing (NLP). PF has been compared to a gold mine for the healthcare industry, delivering clinical efficacy, preserving quality, and overall insight into a disorder. Analyzing these patient responses is vastly more time-consuming and more likely to be subjective. However, employing SA can efficiently extract beneficial insights from this feedback by automating patients’ positive, negative, or neutral sentiments. By systematically investigating thousands or millions of observations to identify familiar themes, distinct concerns, and patient satisfaction levels, researchers can employ these sentiments to understand disease status, improve patient care, and assist in making intelligent decisions by analyzing judgments. Miscellaneous traditional methods depend on surveys or structured questionnaires to accumulate PF that fails to deliver the preferred results in terms of sentiment. On the other hand, by studying sentiment data from mixed social media posts and electronic health records, SA can work with structured and unstructured data to furnish favorable results, allowing researchers to sweeten the grade of biomedical research. Eventually, this chapter discloses worthwhile wisdom to enrich biomedical research by employing PF through SA. © 2025 Scrivener Publishing LLC.},
	author_keywords = {Biomedical research; Healthcare; Machine learning; Natural language processing; Sentimental analysis},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Fan2024,
	author = {Fan, Zipeng and Zhang, Jing and Zhang, Peng and Lin, Qianxi and Li, Yizhe and Qian, Yuhua},
	title = {Quantum-inspired language models based on unitary transformation},
	year = {2024},
	journal = {Information Processing and Management},
	volume = {61},
	number = {4},
	doi = {10.1016/j.ipm.2024.103741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189943893&doi=10.1016%2fj.ipm.2024.103741&partnerID=40&md5=a6accd4f265c2e714755d74a1b52ba0f},
	abstract = {Quantum language models (QLMs), a novel domain in Natural Language Processing (NLP), employ the mathematical framework of quantum mechanics to model language. Although QLMs have demonstrated good performance in NLP tasks, they still have a limitation: they cannot effectively model the dynamic evolution process of sentence semantics. In this paper, we propose a Quantum-inspired Language Model based on Unitary Transformation (QLM-UT) that employs a unitary transformation module to model the dynamic evolution process of sentence semantics. When constructing the unitary matrix, semantic information from the words is incorporated. Furthermore, QLM-UT belongs to the category of real-valued QLMs, and the unitary transformation process implies temporal order information. In comparison to complex-valued QLMs, QLM-UT does not encode word order information through complex word embeddings, resulting in fewer embedding parameters. In question-answering tasks, QLM-UT outperformed real-valued QLMs by 0.2% to 28.4% and complex-valued QLMs by 0.1% to 4.1%. We also evaluated the performance of QLM-UT in text classification tasks. The results demonstrate that QLM-UT can outperform other QLMs on most text classification datasets, showing improvements ranging from 0.1% to 2.5%. Furthermore, through case studies, we illustrated the impact of unitary transformation processes on keyword weights during sentence classification prediction, validating the effectiveness of the unitary transformation in QLM-UT. © 2024},
	author_keywords = {Dynamic semantic; Quantum-inspired language model; Question answering; Unitary transformation},
	keywords = {Classification (of information); Computational linguistics; Embeddings; Natural language processing systems; Quantum theory; Text processing; Dynamic evolution; Dynamic semantic; Language model; Language processing; Model-based OPC; Natural languages; Performance; Quantum-inspired language model; Question Answering; Unitary transformations; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Sarris20245,
	author = {Sarris, Jerome and Halman, Andreas and Urokohara, Anna and Lehrner, Mathew and Perkins, Daniel},
	title = {Artificial intelligence and psychedelic medicine},
	year = {2024},
	journal = {Annals of the New York Academy of Sciences},
	volume = {1540},
	number = {1},
	pages = {5 – 12},
	doi = {10.1111/nyas.15229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204589972&doi=10.1111%2fnyas.15229&partnerID=40&md5=21a33a6509ad57a93917fbe6b7c06d89},
	abstract = {Artificial intelligence (AI) and psychedelic medicines are among the most high-profile evolving disruptive innovations within mental healthcare in recent years. Although AI and psychedelics may not have historically shared any common ground, there exists the potential for these subjects to combine in generating innovative mental health treatment approaches. In order to inform our perspective, we conducted a scoping review of relevant literature up to late August 2024 via PubMed intersecting AI with psychomedical use of psychedelics. Our perspective covers the potential application of AI in psychedelic medicine for: drug discovery and clinical trial optimization (including pharmacodynamics); study design; understanding psychedelic experiences; personalization of treatments; clinical screening, delivery, and follow-up (potentially delivered via chatbots/apps); application of psychological preparation, integration, and general mental health support; its role in enhancing treatment via brain modulatory devices (including virtual reality and haptic suits); and the consideration of ethical and security safeguards. Challenges include the need for sufficient data protection and security, and a range of necessary ethical protections. Future avenues of exploration could involve directly administering psychedelics (or providing algorithm-generated effects) to inorganic AI-interfaced neural networks that may exceed human brain activity (i.e., cognitive capacity) and intelligence. © 2024 The Author(s). Annals of the New York Academy of Sciences published by Wiley Periodicals LLC on behalf of The New York Academy of Sciences.},
	author_keywords = {AI; computational psychiatry; disruptive innovation; DMT; machine learning; natural language processing; psilocybin; virtual reality},
	keywords = {Artificial Intelligence; Drug Discovery; Hallucinogens; Humans; Mental Disorders; mebufotenin; psilocybine; psychedelic agent; psychedelic agent; algorithm; Article; artificial intelligence; audio recording; binding affinity; biological activity; cancer research; ChatGPT; cognitive behavioral therapy; convolutional neural network; data analysis; data protection; dorsolateral prefrontal cortex; electroencephalogram; follow up; good manufacturing practice; human; machine learning; mental health; natural language processing; nerve cell network; obstetric delivery; patient compliance; psychedelic therapy; quality control; scoping review; sentiment analysis; synergistic effect; systematic review; transcranial magnetic stimulation; virtual reality; wearable technology; drug development; drug therapy; mental disease; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Bailke202513,
	author = {Bailke, Preeti and Junghare, Rugved and Kumbhare, Prajakta and Mandalkar, Pratik and Mane, Pratik and Mohekar, Netra},
	title = {YouTube comment summarizer and time-based analysis},
	year = {2025},
	journal = {Quantum Computing Models for Cybersecurity and Wireless Communications},
	pages = {13 – 32},
	doi = {10.1002/9781394271429.ch2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218828209&doi=10.1002%2f9781394271429.ch2&partnerID=40&md5=e04d2c248c0b303be0ec16174be47081},
	abstract = {With the explosive growth of YouTube as a platform for sharing videos and fostering online communities, the comments section has become a vital arena for discourse and interaction. The YouTube Comment Analyzer is a powerful tool designed to delve into this vast repository of user-generated comments, offering invaluable insights and analytics. This innovative tool employs cutting-edge Natural Language Processing (NLP) techniques dissect and understand wealth of information contained within YouTube comments. Its primary functionalities include sentiment analysis, comment extraction, real-time monitoring, and summary generation. © 2025 Scrivener Publishing LLC. All rights reserved.},
	author_keywords = {Comment extraction; Extractive summarization; Sentiment analysis},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Basisth2024273,
	author = {Basisth, Nihar Jyoti and Sachan, Tushar and Kumari, Neha and Pandey, Shyambabu and Pakray, Partha},
	title = {An Automatic POS Tagger System for Code Mixed Indian Social Media Text},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {1956 CCIS},
	pages = {273 – 286},
	doi = {10.1007/978-3-031-48879-5_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180630057&doi=10.1007%2f978-3-031-48879-5_21&partnerID=40&md5=e17b03e5bb21fa9233155808487f74f4},
	abstract = {For a range of Natural Language Processing (NLP) applications, including Sentiment Analysis, Sarcasm Detection, Information Retrieval, Question Answering, and Named Entity Identification, text derived from multiple users’ posts and what they comment on social media constitute significant information (IR). All such applications require part-of-speech (POS) tagging to add tag information to the raw text. Code-mixing, a social media user’s natural desire to submit content in multiple languages, presents a difficulty to POS tagging. In addition, sophisticated and freestyle writing increases the intricacy of the issue. For POS tagging of Code-Mixed Indian social media text, a supervised algorithm using Hidden Markov Model (HMM) with the Viterbi algorithm has been developed to address the problem. The suggested system has been trained and tested using publicly accessible social media text in Indian languages (ILs), particularly Bengali, Telugu, English, and Hindi. On the basis of the F-measure, the accuracy of the system-annotated tags have been assessed. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Code-mixing; Hidden Markov Model; Natural Language Processing; Parts-of-speech tagging; Social media text; Viterbi algorithm},
	keywords = {Computational linguistics; Mixing; Sentiment analysis; Social networking (online); Syntactics; Viterbi algorithm; Code-mixing; Hidden-Markov models; Language processing; Natural language processing; Natural languages; Part of speech tagging; Part-of-speech tags; Parts-of-speech tagging; Social media; Social medium text; Hidden Markov models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Goswami2025283,
	author = {Goswami, Brijesh and Bhavsar, Nidhi and Alzobidy, Soleman Awad and Lavanya, B. and Kumar, R. Udhaya and Rajapandian, K.},
	title = {Sentiment Analysis Using Natural Language Processing},
	year = {2025},
	journal = {Natural Language Processing for Software Engineering},
	pages = {283 – 294},
	doi = {10.1002/9781394272464.ch20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217318473&doi=10.1002%2f9781394272464.ch20&partnerID=40&md5=5eefa75f27262502153306c995eb1967},
	abstract = {Complex text mining techniques include text classification, topic discovery and summarization, concept extraction, document clustering, sentiment extraction, text conversion, natural language processing, and more. These techniques can then be used to extract non-trivial information from a set of text-based documents. Arguments, divergent points of view, and verbal altercations are all useful tools for presenting the facts around a current topic. Text mining, as used in natural language processing, is the process of gleaning sentiment from text that has been obtained through online networking web-based systems. This research outlines a strategy to enhance machine learning and natural language processing in an attempt to simplify and pinpoint the textual feelings that underlie information that is extracted from social media comments. © 2025 Scrivener Publishing LLC.},
	author_keywords = {challenges; machine learning; preprocessing; Sentiment analysis; text analysis; tokenization},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Rodriguez20245593,
	author = {Rodriguez, Axel and Chen, Yi-Ling and Argueta, Carlos},
	title = {SINCERE: A Hybrid Framework With Graph-Based Compact Textual Models Using Emotion Classification and Sentiment Analysis for Twitter Sarcasm Detection},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {5},
	pages = {5593 – 5606},
	doi = {10.1109/TCSS.2023.3315754},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206131519&doi=10.1109%2fTCSS.2023.3315754&partnerID=40&md5=1b61d8faf7977ed31a270d1a13eb12c1},
	abstract = {Sarcasm is an expression of contempt expressed through verbal irony. It is a nuanced form of language that individuals use to imply the opposite of what they are actually saying, and thus it can be difficult to detect at times. The lack of large, annotated datasets is one of the major challenges and limitations of building systems to detect sarcasm automatically. To address this issue, we propose a hybrid graph-based framework, namely, SINCERE, to build compact sarcasm detection models with sentiment and emotion analysis by leveraging only a small amount of prior data. To automatically extract patterns from a small dataset collected by distant supervision, a graph is first constructed. This approach is used to discover latent representations of vertices in a network, as the basis for a language model. We demonstrate that simple classifiers built from the model can detect sarcasm and generalize better than the state-of-the-art approach. According to the experimental results, the proposed SINCERE framework is able to outperform the SOTA baselines on accuracy by 5%. © 2014 IEEE.},
	author_keywords = {Language models; pattern discovery; sarcasm detection; sentiment analysis; social networks},
	keywords = {Annotated datasets; Classification analysis; Emotion classification; Graph-based; Hybrid framework; Language model; Pattern discovery; Sarcasm detection; Sentiment analysis; Social network; Tweets},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Liu2024,
	author = {Liu, Yaochen and Li, Qiuchi and Wang, Benyou and Zhang, Yazhou and Song, Dawei},
	title = {A Survey of Quantum-cognitively Inspired Sentiment Analysis Models},
	year = {2024},
	journal = {ACM Computing Surveys},
	volume = {56},
	number = {1},
	doi = {10.1145/3604550},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173253427&doi=10.1145%2f3604550&partnerID=40&md5=754255089afb296a95fe6fac334a2341},
	abstract = {Quantum theory, originally proposed as a physical theory to describe the motions of microscopic particles, has been applied to various non-physics domains involving human cognition and decision-making that are inherently uncertain and exhibit certain non-classical, quantum-like characteristics. Sentiment analysis is a typical example of such domains. In the last few years, by leveraging the modeling power of quantum probability (a non-classical probability stemming from quantum mechanics methodology) and deep neural networks, a range of novel quantum-cognitively inspired models for sentiment analysis have emerged and performed well. This survey presents a timely overview of the latest developments in this fascinating cross-disciplinary area. We first provide a background of quantum probability and quantum cognition at a theoretical level, analyzing their advantages over classical theories in modeling the cognitive aspects of sentiment analysis. Then, recent quantum-cognitively inspired models are introduced and discussed in detail, focusing on how they approach the key challenges of the sentiment analysis task. Finally, we discuss the limitations of the current research and highlight future research directions. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {emotion recognition; non-classical probability from quantum mechanics methodology; Quantum-cognitively inspired models; sarcasm detection; sentiment analysis},
	keywords = {Decision making; Decision theory; Deep neural networks; Emotion Recognition; Analysis models; Classical probabilities; Emotion recognition; Microscopic particle; Non-classical probability from quantum mechanic methodology; Physical theory; Quantum probabilities; Quantum-cognitively inspired model; Sarcasm detection; Sentiment analysis; Quantum theory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Roshan Ahmed2024,
	author = {Roshan Ahmed, N. and Shridevi, S.},
	title = {DeepKet- Quantum Space-Efficient Word Embedding Layer for Steganalysis},
	year = {2024},
	journal = {2024 3rd International Conference on Artificial Intelligence for Internet of Things, AIIoT 2024},
	doi = {10.1109/AIIoT58432.2024.10574718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198526800&doi=10.1109%2fAIIoT58432.2024.10574718&partnerID=40&md5=60c7acb4472b26f9cd1db4f5314599da},
	abstract = {Text-based Statistical steganography is one of the most non-human detectable methods of embedding hidden messages in plain text format which is useful in concealing information. Steganalysis is its counter, the process of detecting if a text has any encrypted data in it. This paper applies quantum computing to create DeepKet Embedding, which optimizes the space requirements for word embeddings similar to Word2Vec. DeepKet is benchmarked against existing embedding layers and a significant size reduction is achieved while maintaining accuracy for steganalysis.  © 2024 IEEE.},
	author_keywords = {Convolution Neural Network; Quantum Computing; Quantum NLP; Steganalysis; Steganography; Text Classification; Word2Vec},
	keywords = {Classification (of information); Quantum computers; Quantum efficiency; Steganography; Text processing; Convolution neural network; Embeddings; Hidden messages; Plain text; Quantum Computing; Quantum NLP; Space efficient; Steganalysis; Text classification; Word2vec; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Widdows20241249,
	author = {Widdows, Dominic and Alexander, Aaranya and Zhu, Daiwei and Zimmerman, Chase and Majumder, Arunava},
	title = {Near-term advances in quantum natural language processing},
	year = {2024},
	journal = {Annals of Mathematics and Artificial Intelligence},
	volume = {92},
	number = {5},
	pages = {1249 – 1272},
	doi = {10.1007/s10472-024-09940-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190283249&doi=10.1007%2fs10472-024-09940-y&partnerID=40&md5=081454bc3cef0568203d9131db3b52e3},
	abstract = {This paper describes experiments showing that some tasks in natural language processing (NLP) can already be performed using quantum computers, though so far only with small datasets. We demonstrate various approaches to topic classification. The first uses an explicit word-based approach, in which word-topic weights are implemented as fractional rotations of individual qubits, and a phrase is classified based on the accumulation of these weights onto a scoring qubit, using entangling quantum gates. This is compared with more scalable quantum encodings of word embedding vectors, which are used to compute kernel values in a quantum support vector machine: this approach achieved an average of 62% accuracy on classification tasks involving over 10000 words, which is the largest such quantum computing experiment to date. We describe a quantum probability approach to bigram modeling that can be applied to understand sequences of words and formal concepts, investigate a generative approximation to these distributions using a quantum circuit Born machine, and introduce an approach to ambiguity resolution in verb-noun composition using single-qubit rotations for simple nouns and 2-qubit entangling gates for simple verbs. The smaller systems presented have been run successfully on physical quantum computers, and the larger ones have been simulated. We show that statistically meaningful results can be obtained, but the quality of individual results varies much more using real datasets than using artificial language examples from previous quantum NLP research. Related NLP research is compared, partly with respect to contemporary challenges including informal language, fluency, and truthfulness. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {68T50; 81P68; QNLP; Quantum computing; Quantum natural language processing; Quantum NLP},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Zhao2025,
	author = {Zhao, Chuanjun and Kang, Lu and Sun, Xuzhuang and Xi, Xiaoxiong and Shen, Lihua and Gao, Jing and Wang, Yanjie},
	title = {Aspect-Level Sentiment Classification of Consumer Reviews Utilizing BERT and Category-Aware Multi-Head Attention},
	year = {2025},
	journal = {IEEE Transactions on Consumer Electronics},
	doi = {10.1109/TCE.2025.3563150},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003492860&doi=10.1109%2fTCE.2025.3563150&partnerID=40&md5=7bde7ce908d74168d7e3f82e3a51f6a7},
	abstract = {In recent years, the explosive growth of user-generated review texts has underscored the academic and societal significance of sentiment analysis. Although deep learning has achieved remarkable progress in this field, existing aspect-based sentiment classification (ABSC) methods face challenges in capturing the dynamic nature of sentiment categories. Furthermore, these methods often lack explicit modeling of category information, limiting their ability to adapt attention distributions based on sentiment categories. To address these challenges, this paper proposes a BERT-based model with a category-aware multi-head attention mechanism. The model introduces an aspect projection layer that maps aspect word embeddings into a feature space aligned with the context, thereby enhancing interaction between aspect words and the surrounding text. Additionally, a category-aware multi-head attention mechanism combines category weights and dynamic content weights to effectively fuse sentiment category information. This design significantly improves the model’s ability to capture sentiment features of multiple categories. Experimental evaluations on SemEval public datasets demonstrate that the proposed method outperforms state-of-the-art techniques, and ablation studies further confirm the effectiveness of its design. © 1975-2011 IEEE.},
	author_keywords = {Aspect-Based Sentiment Classification; BERT Model; Category-aware; Consumer Reviews; Multi-head Attention},
	keywords = {Aspect-based sentiment classification; Attention mechanisms; BERT model; Category-aware; Consumer reviews; Explosive growth; Multi-head attention; Sentiment analysis; Sentiment classification; User-generated; Classification (of information)},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kumari2024,
	author = {Kumari, Swati and Mahajan, Jayant and Jain, Pritty and Panikulangara, Lekha and Kulkarni, Shruti and Saxena, Anshul},
	title = {Charting the Future of Fintech: Unveiling Finoracle through an In-depth Comparison of LLAMA 2, FLAN, and GPT-3.5},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545266},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204488359&doi=10.1109%2fTQCEBT59414.2024.10545266&partnerID=40&md5=9b439d952de37c564aa05b22022c158c},
	abstract = {The research paper compares three Large Language Models (LLMs): LLAMA 2, FLAN, and GPT-3.5, in summarizing financial technology (fintech) news. Using 100 articles and the Rouge scoring system, it focuses on LLAMA 2's superior performance in creating concise and precise summaries. The study also introduces FinSage, a new framework utilizing LLAMA 2, promising to enhance fintech text analysis and decision-making. It concludes that LLAMA 2 sets a new standard for AI in financial data processing and analysis.  © 2024 IEEE.},
	author_keywords = {Artificial Intelligence (AI); Financial Technology (Fintech); Large Language Models (LLMs); Text Summarization},
	keywords = {Artificial intelligence; Decentralized finance; Financial data processing; Fintech; Artificial intelligence; Financial technology; It focus; Language model; Large language model; Performance; Research papers; Scoring systems; Text analysis; Text Summarisation; Data handling},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jamadar2024,
	author = {Jamadar, Jitendrasinh and Karnik, Kruttika and Birari, Abhijeet and Patil, Yogita},
	title = {User Perception of Mobile Banking: Application of Sentiment Analysis and Topic Modelling Approaches to Online Reviews},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204457290&doi=10.1109%2fTQCEBT59414.2024.10545236&partnerID=40&md5=b86692262582e53f3ef946dfc9b33c46},
	abstract = {The digital revolution has led to significant changes in the global as well as Indian banking sector. The introduction of mobile banking apps has provided increased convenience to customers, who can now avail various banking services remotely. Thus, it is imperative to study the customers' sentiments regarding these applications and find scope for improvement, so that customers can seamlessly operate their bank accounts without having to visit bank branches. Thus, the primary purpose of this research is to study the perceptions of customers towards mobile applications of six major banks in India. A sample of 3000 reviews left by users of these apps was scraped from Google Play Store and sentiment analysis was conducted using RoBERTa-base model from the Transformers library. This was followed by topic modeling using Latent Dirichlet Allocation to find the aspects that are most important to the users. Results revealed that user experience is majorly driven by customer support service, features and functionality of apps, and app performance. Our findings shall help banks identify key areas of improvement so that they can work on enhancing overall customer experience. Despite the growing popularity of mobile banking, this study is the first of its kind in Indian context.  © 2024 IEEE.},
	author_keywords = {Latent Dirichlet Allocation; Mobile Banking; Mobile Banking Applications; RoBERTa; Sentiment Analysis; Topic Modeling},
	keywords = {Banking; Economic and social effects; Mobile commerce; Reviews; Analysis models; Latent Dirichlet allocation; Mobile banking application; Mobile bankings; Modeling approach; RoBERTa; Sentiment analysis; Topic Modeling; User perceptions; Sales},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20241006,
	author = {Chen, I.-Chi and Singh, Harshdeep and Anukruti, V.L. and Quanz, Brian and Yogaraj, Kavitha},
	title = {A Survey of Classical and Quantum Sequence Models},
	year = {2024},
	journal = {2024 16th International Conference on COMmunication Systems and NETworkS, COMSNETS 2024},
	pages = {1006 – 1011},
	doi = {10.1109/COMSNETS59351.2024.10426944},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186678076&doi=10.1109%2fCOMSNETS59351.2024.10426944&partnerID=40&md5=a66d24fbc4786b1c87c716250cfac4ea},
	abstract = {Our primary objective is to conduct a brief survey of various classical and quantum neural net sequence models, which includes self-attention and recurrent neural networks, with a focus on recent quantum approaches proposed to work with near-term quantum devices, while exploring some basic enhancements for these quantum models. We re-implement a key representative set of these existing methods, adapting an image classification approach using quantum self-attention to create a quantum hybrid transformer that works for text and image classification, and applying quantum self-attention and quantum recurrent neural networks to natural language processing tasks. We also explore different encoding techniques and introduce positional encoding into quantum self-attention neural networks leading to improved accuracy and faster convergence in text and image classification experiments. This paper also performs a comparative analysis of classical self-attention models and their quantum counterparts, helping shed light on the differences in these models and their performance.  © 2024 IEEE.},
	author_keywords = {quantum-computing; quantum-machine-learning; self-attention; transformers},
	keywords = {Classification (of information); Encoding (symbols); Image classification; Image enhancement; Learning algorithms; Natural language processing systems; Quantum computers; Signal encoding; Text processing; Images classification; Machine-learning; Primary objective; Quantum Computing; Quantum machines; Quantum-machine-learning; Self-attention; Sequence models; Text classification; Transformer; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Doody2024349,
	author = {Doody, Jacob and Holden, Roxanne and Zaret, David and Kavaler, Nathaniel},
	title = {Discrete Quantum Random Walks for Semantic Text Similarity},
	year = {2024},
	journal = {Proceedings - IEEE Quantum Week 2024, QCE 2024},
	volume = {1},
	pages = {349 – 355},
	doi = {10.1109/QCE60285.2024.00049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217417962&doi=10.1109%2fQCE60285.2024.00049&partnerID=40&md5=09ba5d4c1a1003102ef023f96b3e5fef},
	abstract = {Context-based determination of text similarity is a fundamental computation task that enables identification and attribution of emerging topics and narratives within and across information platforms. Most existing techniques for text similarity scoring are not context-based, or are context-based but struggle to process large amounts of data. In our work, we have developed an end-to-end quantum random walk protocol that determines semantic text similarity. As part of our work on the quantum protocol, we also developed a novel regularization protocol for irregular graphs, and a clean implementation of a weighted and directed graph decomposition protocol, all of which may provide speedup in context-based analysis of texts. © 2024 IEEE.},
	author_keywords = {Graph Regularization; Quantum Random Walk; Sentiment Analysis},
	keywords = {Computation tasks; Context-based; Emerging topics; Graph regularization; Information platform; Large amounts of data; Quantum random walks; Regularisation; Sentiment analysis; Text similarity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{MacEda2024,
	author = {MacEda, Lany L.},
	title = {Enhanced Sentiment Classification in Code-Mixed Texts Using Hybrid Embeddings and Synthetic Data Generation},
	year = {2024},
	journal = {2024 International Conference on Computer and Applications, ICCA 2024},
	doi = {10.1109/ICCA62237.2024.10928006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002232112&doi=10.1109%2fICCA62237.2024.10928006&partnerID=40&md5=2c6ec51a2fbc050174205bc9c859ef71},
	abstract = {Social media platforms provide a space for users to share thoughts, connect, and discuss various topics. While some communicate in a single language, others use multiple languages, reflecting the linguistic diversity of their nations. Existing research has largely focused on monolingual data, with less attention on code-mixed data. Studies have explored hybrid models, which have been shown to improve sentiment analysis accuracy compared to single models across various datasets. To enhance sentiment classification in this type of data, we employed a hybrid model combining the distilled multilingual embeddings of BERT with BiLSTM to capture sequential dependencies. Further, we address class imbalance through generating synthetic data with ChatGPT, a large language model with human language comprehension. Our approach shows significant performance improvements across various hyperparameter settings over its vanilla counterparts. Best result showed a 4.82% increase in both accuracy and macro F1 score against DistilmBERT alone. We observed that when prompting ChatGPT for generating synthetic data, every prompt should be distinct to avoid data duplication during data generation. With LIME (Local Interpretable Model-agnostic Explanations) technique, we provide interpretations for correctly classified and misclassified instances weighing words according to their contribution to our model's prediction. A potential area of further study adapting the model to a more large, extensive, and diverse datasets, including various social media platforms and languages, could improve its generalizability and robustness.  © 2024 IEEE.},
	author_keywords = {code-mixed languages; data augmentation; hybrid models; sentiment classification; social media},
	keywords = {Code-mixed language; Data augmentation; Embeddings; Hybrid model; Multiple languages; Sentiment classification; Social media; Social media platforms; Synthetic data; Synthetic data generations},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhimin2025,
	author = {Zhimin, He and Guohong, Li and Haozhen, Situ and Yan, Zhou and Shenggen, Zheng and Lvzhou, Li},
	title = {Code-level quantum circuit generation based on large language models; [基于大语言模型的代码级量子线路生成]},
	year = {2025},
	journal = {Scientia Sinica: Physica, Mechanica et Astronomica},
	volume = {55},
	number = {4},
	doi = {10.1360/SSPMA-2024-0594},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003288819&doi=10.1360%2fSSPMA-2024-0594&partnerID=40&md5=e4a9f5d11e70a37996fe78e187879bae},
	abstract = {Large language models (LLMs), based on deep learning techniques, are trained on vast amounts of textual data and possess the ability to understand and generate natural language.They have found widespread application in tasks such as machine translation, text generation, and question answering.This work proposes a novel approach for code-level quantum circuit generation using LLM. By fine-tuning existing LLM, we enable it to generate quantum circuit code tailored to user specifications, offering an efficient and high-performance solution for quantum circuit design. Simulation results demonstrate that this method achieves high accuracy in generating quantum circuit codes with only a small set of training data. This work provides a new perspective on quantum circuit design. It highlights the potential of LLMs in quantum programming and algorithm automation, laying the foundation for future research and practical applications in quantum artificial intelligence. © 2025 Science Press. All rights reserved.},
	author_keywords = {large language model; quantum artificial intelligence; quantum circuit},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{An2024,
	author = {An, Zheng and Wu, Jiahui and Yang, Muchun and Zhou, D.L. and Zeng, Bei},
	title = {Unified quantum state tomography and Hamiltonian learning: A language-translation-like approach for quantum systems},
	year = {2024},
	journal = {Physical Review Applied},
	volume = {21},
	number = {1},
	doi = {10.1103/PhysRevApplied.21.014037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183643073&doi=10.1103%2fPhysRevApplied.21.014037&partnerID=40&md5=ae014ed6a4924fe6488daa7e42b71057},
	abstract = {As quantum technology rapidly advances, the need for efficient scalable methods to characterize quantum systems intensifies. Quantum state tomography and Hamiltonian learning are essential for interpreting and optimizing quantum systems, yet a unified approach remains elusive. Such an integration could enhance our understanding of the complex relationship between quantum states and Hamiltonians, contributing to the development of more efficient methodologies. In this paper, we present a method that integrates quantum state tomography and Hamiltonian learning, drawing inspiration from machine translation in the field of natural language processing (NLP). We demonstrate the effectiveness of our approach across a variety of quantum systems, successfully learning the complex relationships between quantum states and Hamiltonians. Furthermore, the scalability and few-shot learning capabilities of our method could potentially minimize the resources required for characterizing and optimizing quantum systems. Our research provides valuable insights into the relationship between quantum states and Hamiltonians, paving the way for further studies on quantum systems and advancing quantum computation and related technologies.  © 2024 American Physical Society. },
	keywords = {Learning systems; Natural language processing systems; Quantum computers; Quantum optics; Scalability; Tomography; Complex relationships; Language translation; Machine translations; Quantum Hamiltonians; Quantum state; Quantum state tomography; Quantum system; Quantum technologies; Scalable methods; Unified approach; Hamiltonians},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@CONFERENCE{Choudhury2024,
	author = {Choudhury, Ritabrata Roy and Dey, Soumik and Paul, Prithwineel},
	title = {A Comparative Study of LSTM Models on Sentiment Analysis},
	year = {2024},
	journal = {Proceedings - International Conference on Computational Intelligence and Networks},
	doi = {10.1109/CINE63708.2024.10881938},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000265250&doi=10.1109%2fCINE63708.2024.10881938&partnerID=40&md5=43af5a4141a36292869a681634ee2aae},
	abstract = {In this paper, we conduct a comparative analysis of LSTM (Long Short-Term Memory) architectures, including GPU LSTM and Convolutional LSTM, for sentiment analysis tasks on an e-commerce dataset. The evaluation is based on precision, recall, and F1-score metrics for classifying positive and negative sentiments in product reviews. Both GPU LSTM and Convolutional LSTM models demonstrate strong performance in classifying positive sentiments. Moreover, these models achieve high precision, recall, and F1-score. However, they struggle with negative sentiment classification, exhibiting zero precision, recall, and F1-score for this class. Overall, both models achieve an accuracy of 0.97, indicating their effectiveness in sentiment analysis tasks. Furthermore, our study underscores the importance of further research to enhance the ability of the LSTM model to classify negative sentiments in e-commerce datasets accurately.  © 2024 IEEE.},
	author_keywords = {Convolutional LSTM; E-commerce; F1-score; GPU LSTM; LSTM; Precision; Recall; Sentiment Analysis},
	keywords = {Analog storage; Digital storage; Graphics processing unit; Memory architecture; Convolutional long short-term memory; F1 scores; GPU long short-term memory; Memory modeling; Precision; Recall; Sentiment analysis; Short term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lateshwari202544,
	author = {Lateshwari and Bansal, Sushil Kumar},
	title = {Quantum Influence on Social Media Content: Employing Machine Learning for Sentiment Analysis},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2238 CCIS},
	pages = {44 – 58},
	doi = {10.1007/978-3-031-75861-4_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209992537&doi=10.1007%2f978-3-031-75861-4_5&partnerID=40&md5=091d17d91a155f04588f17a507b33c31},
	abstract = {The application of natural language processing has proven to be particularly advantageous in the realm of sentiment analysis, particularly when dealing with vast and intricate amounts of unstructured data found within social media platforms. These insights contribute to making informed decisions. Among its multifaceted uses, social media serves as platform for individuals to articulate themselves through tweets and posts. The sentiment of written content, specifically within the realm of social media data, holds the potential to be dissected to extract opinions, emotions, and significant perspectives. Effectively assessing sentiment in publicly available social media data faces challenges from both theoretical and technological sources. While various methodologies have been developed over time, their effectiveness has been constrained by their focus on small datasets, rendering them inadequate in addressing the aforementioned complexities optimally. The recommended approach offers a solution to these challenges, encompassing critical facets such as data collection, feature encoding, feature selection, data pre-processing, and classification, as previously delineated. Notably, the feature encoding stage adopts a hybrid technique that combines the incorporation of bi-gram and tri-gram words. Rigorous testing conducted across multiple benchmark datasets to comprehensively evaluate the performance of the proposed framework. Significantly, the suggested method not only delivers comparable outcomes but, in various instances, superior results while necessitating less intricate computational processes. The average accuracy results attained using the multilayer perceptron neural network ranged from 89 to 91. The methodologies presented in paper are poised to substantially elevate the efficacy of sentiment analysis across diverse blog and social media content. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {and multilayer perceptron neural networks; sentiment analysis; Social media Tweets},
	keywords = {Multilayer neural networks; And multilayer perceptron neural network; Encodings; Machine-learning; Media content; Multilayers perceptrons; Natural languages; Perceptron neural networks; Sentiment analysis; Social media; Social medium tweet; Tweets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yao2025,
	author = {Yao, Ben and Tiwari, Prayag and Li, Qiuchi},
	title = {Self-supervised pre-trained neural network for quantum natural language processing},
	year = {2025},
	journal = {Neural Networks},
	volume = {184},
	doi = {10.1016/j.neunet.2024.107004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211993533&doi=10.1016%2fj.neunet.2024.107004&partnerID=40&md5=47f7786979c7219f8a6e76c662829a8c},
	abstract = {Quantum computing models have propelled advances in many application domains. However, in the field of natural language processing (NLP), quantum computing models are limited in representation capacity due to the high linearity of the underlying quantum computing architecture. This work attempts to address this limitation by leveraging the concept of self-supervised pre-training, a paradigm that has been propelling the rocketing development of NLP, to increase the power of quantum NLP models on the representation level. Specifically, we present a self-supervised pre-training approach to train quantum encodings of sentences, and fine-tune quantum circuits for downstream tasks on its basis. Experiments show that pre-trained mechanism brings remarkable improvement over end-to-end pure quantum models, yielding meaningful prediction results on a variety of downstream text classification datasets. © 2024 The Authors},
	author_keywords = {Natural language processing; Quantum computing; Self-supervised pre-training},
	keywords = {Humans; Natural Language Processing; Neural Networks, Computer; Quantum Theory; Computer architecture; Gluing; Natural language processing systems; Neural networks; Quantum optics; Self-supervised learning; Applications domains; Down-stream; Language processing; Natural language processing; Natural languages; Pre-training; Quantum Computing; Quantum computing models; Self-supervised pre-training; Trained neural networks; article; controlled study; natural language processing; nerve cell network; prediction; training; artificial neural network; human; quantum theory; Quantum electronics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Arora2025185,
	author = {Arora, Jay and Jain, Vishal},
	title = {Innovative Applications and Advanced Practices in Financial Data Science and Machine Learning for High-Frequency Trading},
	year = {2025},
	journal = {Machine Learning and Modeling Techniques in Financial Data Science},
	pages = {185 – 207},
	doi = {10.4018/979-8-3693-8186-1.ch007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007278465&doi=10.4018%2f979-8-3693-8186-1.ch007&partnerID=40&md5=564d4c56db1d6f19df9571fe0b3ddfcf},
	abstract = {High- frequency trading (HFT) has revolutionized financial markets, leveraging advancements in automation, machine learning (ML), and high- speed data transmission to achieve rapid and adaptive trading strategies. ML techniques like reinforcement learning (RL), anomaly detection, and natural language processing (NLP) have transformed HFT, enabling dynamic decision- making, real- time anomaly detection, and sentiment- based analysis with models like BERT and GPT. Emerging technologies, including quantum computing and blockchain, promise further enhancements, offering unparalleled optimization speed, transparency, and fraud reduction. Despite these advancements, challenges such as model interpretability, overfitting, and regulatory requirements persist. This chapter explores how cutting- edge ML and emerging technologies are reshaping HFT, providing insights into their potential to drive innovation, improve risk management, and redefine the financial markets for a competitive future. © 2025 by IGI Global Scientific Publishing. All rights reserved.},
	keywords = {Anomaly detection; Financial markets; Reinforcement learning; Risk management; Sentiment analysis; Emerging technologies; Financial data; High-frequency trading; High-speed data transmission; Learning speed; Machine learning techniques; Machine-learning; Reinforcement learnings; Science learning; Trading strategies; Risk perception},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gupta2024,
	author = {Gupta, Shivani and Rakhesh, K. and Velmurugan, S. and Brindha, T.V.},
	title = {Improving the Extraction of Aspect Terms from Customer Reviews using MSRL-NET and BERT},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204427549&doi=10.1109%2fTQCEBT59414.2024.10545177&partnerID=40&md5=b433019ee9376928d048c5373129cb2d},
	abstract = {Aspect Term Extraction (ATE) is a significant task in natural language processing that determinations to normalize and extract particular aspects or properties of things referenced in text. This technique is essential in a dissimilarity of applications, with sentiment analysis, opinion mining, and review summarization. The determination of aspect term extraction is to automatically label and classify words or phrases that express aspects of a specific entity, which could be products, services, or any topic under discussion. In ATE, static word embeddings are required to capture dynamic word meanings properly. We designate a original method for dealing with the intricacies of this difficult and enhancing sentiment analysis accuracy, which uses a Multi-level Semantic Relation-enhanced Learning Network (MSRL-Net) and Bidirectional Encoder Representations from Transformers (BERT). In this paper, we suggest a synergistic framework that uses MSRL-Nets to develop the resolution and clarity of text representations, subsequent by BERT's input format, which is limited to a collection of words and cannot include more context knowledge. MSRL-Net and BERT addresses aspect extraction, sentiment polarity identification, and context-dependent sentiment comprehension by leveraging MSRL-Net's capabilities to create high-resolution text representation and BERT's contextualized language considerate. The combination of MSRL-Nets with BERT designates a promising future path for aspect-based sentiment analysis, with applications such as customer feedback analysis, market research, and social media sentiment monitoring. The experimental evaluation revealed that the proposed technique outperforms the SemEval dataset regarding precision, F1 score, and accuracy.  © 2024 IEEE.},
	author_keywords = {Aspect term extraction (ATE); Bidirectional Encoder Representations from Transformers (BERT); context-dependent sentiment; Multi-level Semantic Relation-enhanced Learning Network (MSRL-Net); Sentiment polarity identification},
	keywords = {Commerce; Economic and social effects; Market Research; Reviews; Sales; Aspect term extraction; Bidirectional encoder representation from transformer; Context dependent; Context-dependent sentiment; Enhanced learning; Learning network; Multi-level semantic relation-enhanced learning network; Multilevels; Semantic relations; Sentiment polarity identification; Term extraction; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Getu20241649,
	author = {Getu, Tilahun M. and Kaddoum, Georges and Bennis, Mehdi},
	title = {Semantic Communication: A Survey on Research Landscape, Challenges, and Future Directions},
	year = {2024},
	journal = {Proceedings of the IEEE},
	volume = {112},
	number = {11},
	pages = {1649 – 1685},
	doi = {10.1109/JPROC.2024.3520707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216992340&doi=10.1109%2fJPROC.2024.3520707&partnerID=40&md5=4d5bec0227d5d26ef824872147f7a19d},
	abstract = {Amid the global rollout of fifth-generation (5G) services, researchers in academia, industry, and national laboratories have been developing proposals for the sixth-generation (6G), whose materialization is fraught with many fundamental challenges. To alleviate these challenges, a deep learning (DL)-enabled semantic communication (SemCom) has emerged as a promising 6G technology enabler, which embodies a paradigm shift that can change the status quo viewpoint that wireless connectivity is an opaque data pipe carrying messages whose context-dependent meanings have been ignored. Since 6G is also critical for the materialization of major SemCom use cases, the paradigms of 6G for SemCom and SemCom for 6G call for a tighter integration of 6G and SemCom. For this purpose, this comprehensive article provides the fundamentals of semantic information, semantic representation, and semantic entropy; details the state-of-the-art SemCom research landscape; presents the major SemCom trends and use cases; discusses current SemCom theories; exposes the fundamental and major challenges of SemCom; and offers future research directions for SemCom. We hope this article stimulates many lines of research on SemCom theories, algorithms, and implementation.  © 1963-2012 IEEE.},
	author_keywords = {Semantic communication (SemCom); semantic information; SemCom challenges and future directions; SemCom research landscape; sixth-generation (6G)},
	keywords = {5G mobile communication systems; Economic and social effects; Semantics; Communication research; National laboratory; Semantic communication; Semantic communication challenge and future direction; Semantic communication research landscape; Semantics Information; Sixth-generation (6g); Latent semantic analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Chi},
	title = {Improved Word Segmentation System for Chinese Criminal Judgment Documents},
	year = {2024},
	journal = {Applied Artificial Intelligence},
	volume = {38},
	number = {1},
	doi = {10.1080/08839514.2023.2297524},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180690777&doi=10.1080%2f08839514.2023.2297524&partnerID=40&md5=f2b0ee2658579216758efa8de711192e},
	abstract = {In this paper, a system for automatic word segmentation of Chinese criminal judgment documents is proposed. The system uses a hybrid model composed of fine-tuned BERT (Bidirectional Encoder Representations from Transformers), BiLSTM (Bidirectional Long Short Term Memory) and CRF (Conditional Random Field) for named entity recognition, and introduces a custom dictionary that includes common professional terms in Chinese criminal trial documents, as well as a rule system based on judicial system and litigation procedure related regulations, to further improve the accuracy of word segmentation. BERT uses a deep bidirectional Transformer encoder to pre-train general language representations from large-scale unlabeled text corpora. BiLSTM uses two LSTM networks, one for the forward direction and one for the backward direction, to capture the context from both sides of the input sequence. CRF uses a set of features and weights to define a log-linear distribution over the output sequence. Experimental results show that the proposed system has significantly improved word segmentation accuracy compared to the current commonly used Chinese word segmentation models. In the results of the segmentation of the test data, the F1 scores for jieba, THULAC and the segmentation system proposed in this paper are 85.59%, 87.94% and 94.82%, respectively. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	keywords = {Computational linguistics; Crime; Random processes; Signal encoding; Automatic word segmentation; Hybrid model; Judicial systems; Large-scales; Named entity recognition; Random fields; System use; Text corpora; Word segmentation; Word segmentation systems; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@BOOK{Meenakshi2025155,
	author = {Meenakshi},
	title = {Opinion Mining Using Classification Techniques on Electronic Media Data},
	year = {2025},
	journal = {Natural Language Processing for Software Engineering},
	pages = {155 – 168},
	doi = {10.1002/9781394272464.ch10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217336607&doi=10.1002%2f9781394272464.ch10&partnerID=40&md5=8ec06c4fcf5e17dc0e8d5c862ac4c4d8},
	abstract = {Both businesses and consumers have changed their viewpoint in reaction to the movement of the Web from being a producer of information to being a receiver of information. Consequently, an increasing number of individuals are opting to make judgments using online platforms. Companies highly value these evaluations as they provide impartial depictions of the customer’s genuine sentiments. Although possessing such information ensures substantial advantages, it also presents notable challenges. One significant factor behind this phenomenon is the widespread availability of social media applications. Prior to the advent of technology, individuals relied on personal networks of family and friends to obtain information for informed purchasing choices. However, in the present day, the internet has taken control, and individuals rely on online assessments to inform their purchasing decisions. Moreover, rather than engaging in face-to-face interactions, numerous individuals seek for these types of evaluations on the internet. A plausible rationale for this predicament is the surge in the prevalence of social media. Internet users now have the ability to access a vast amount of information that may be advantageous to both companies and their customers. Although this data is undeniably beneficial, the overwhelming number of views required for just one product has resulted in choice fatigue. To mitigate choice fatigue for individuals and facilitate effective decision-making for enterprises, the root-cause analysis approach offers a comprehensive and accurate understanding of products. Aspect extraction, often referred to as opinion target extraction, and sentiment identification, also called opinion mining, are two components of root-cause analysis. Sentiment analysis is to ascertain the reviewer’s overall position about a certain product. Consequently, both customers and companies may more effectively evaluate the advantages and disadvantages of their products. Both organizations and consumers can gain advantages by enhancing the root-cause analysis method proposed in this thesis. Support Vector Machines (SVM), Random Forest, Multilayer perception and CNN algorithms are efficient in opinion mining task. © 2025 Scrivener Publishing LLC.},
	author_keywords = {electronic media analysis; machine learning; natural language processing; Opinion mining},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2025,
	author = {Chen, Fu and Zhao, Qinglin and Feng, Li and Chen, Chuangtao and Lin, Yangbin and Lin, Jianhong},
	title = {Quantum mixed-state self-attention network},
	year = {2025},
	journal = {Neural Networks},
	volume = {185},
	doi = {10.1016/j.neunet.2025.107123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214837616&doi=10.1016%2fj.neunet.2025.107123&partnerID=40&md5=11c360ce6ea3ba14a928c3acebc6df60},
	abstract = {Attention mechanisms have revolutionized natural language processing. Combining them with quantum computing aims to further advance this technology. This paper introduces a novel Quantum Mixed-State Self-Attention Network (QMSAN) for natural language processing tasks. Our model leverages quantum computing principles to enhance the effectiveness of self-attention mechanisms. QMSAN uses a quantum attention mechanism based on mixed state, allowing for direct similarity estimation between queries and keys in the quantum domain. This approach leads to more effective attention coefficient calculations. We also propose an innovative quantum positional encoding scheme, implemented through fixed quantum gates within the circuit, improving the model's ability to capture sequence information without additional qubit resources. In numerical experiments of text classification tasks on public datasets, QMSAN outperforms Quantum Self-Attention Neural Network (QSANN). Furthermore, we demonstrate QMSAN's robustness in different quantum noise environments, highlighting its potential for near-term quantum devices. © 2025},
	author_keywords = {Quantum machine learning; Quantum self-attention mechanism; Self-attention mechanism; Text classification},
	keywords = {Algorithms; Attention; Humans; Natural Language Processing; Neural Networks, Computer; Quantum Theory; Encoding (symbols); Natural language processing systems; Neural networks; Quantum electronics; Quantum optics; quantum dot; Attention mechanisms; Machine-learning; Mixed state; Natural languages; Quantum machine learning; Quantum machines; Quantum self-attention mechanism; Self-attention mechanism; Text classification; Article; artificial neural network; attention network; classification algorithm; human; language processing; machine learning; mathematical parameters; natural language processing; quantum mechanics; quantum theory; signal noise ratio; time series analysis; algorithm; artificial neural network; attention; natural language processing; physiology; Quantum computers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Bensoltane2024,
	author = {Bensoltane, Rajae and Zaki, Taher},
	title = {Knowledge-enhanced graph convolutional networks for Arabic aspect sentiment classification},
	year = {2024},
	journal = {Social Network Analysis and Mining},
	volume = {14},
	number = {1},
	doi = {10.1007/s13278-023-01166-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178964513&doi=10.1007%2fs13278-023-01166-w&partnerID=40&md5=3da9a104ff62b639bbebf00a432fa95b},
	abstract = {Aspect sentiment classification (ASC) is a sub-task of aspect-based sentiment analysis (ABSA) that aims at identifying the sentiment polarity toward a specific aspect in a given text or sentence. Most existing research on Arabic ABSA adopted rule-based or machine learning-based methods, with little attention to deep learning techniques. Additionally, the majority of these deep learning-based models relied on attention mechanisms to capture the interaction between the context and aspect words. However, attention-based methods are generally inefficient in extracting the syntactic dependencies between contextual tokens and aspects. Therefore, we introduce a combined model that incorporates an Arabic BERT model with graph convolutional network and local context focus layers to capture syntactic dependencies relevant to a specific aspect while emphasizing the contribution of semantic-related tokens related to this aspect. We also integrate affective commonsense knowledge into the graph networks to capture the sentiment-related dependencies between contextual words and the specific aspect. The experimental results on an Arabic hotel dataset show that the proposed method outperforms the baseline and related work models and achieves a state-of-the-art accuracy score of 92.77% in Arabic ASC. The achieved results show the effectiveness of the proposed model in enhancing the aspect-specific sentiment representations, which can be promising for future research in this field. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.},
	author_keywords = {Affective commonsense knowledge; Arabic; Aspect sentiment classification; BERT; Graph convolutional networks; Local context focus},
	keywords = {Convolution; Convolutional neural networks; Deep learning; Graph neural networks; Learning systems; Semantics; Syntactics; Affective commonsense knowledge; Arabic; Aspect sentiment classification; BERT; Commonsense knowledge; Convolutional networks; Graph convolutional network; Local context focus; Local contexts; Sentiment classification; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kulkarni2024,
	author = {Kulkarni, Yogesh and Mahamuni, Archana and Sane, Sandip and Kalshetti, Prashant and Patil, Kunal and Jarad, Rajendra Subhash},
	title = {Analysing How Marketing Management and Artificial Intelligence are used to Change Customer Engagement},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545064},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204466677&doi=10.1109%2fTQCEBT59414.2024.10545064&partnerID=40&md5=59b53619914d680b9c170c37c0ace5f0},
	abstract = {The integration of marketing management and AI can transform customer engagement strategies across industries. Marketing management underpins business operations, connecting customers and boosting success. AI becomes a key digitization tool as businesses adapt to new technology, processing massive amounts of data and changing customer interactions. This study examines how marketing management and AI interact to change customer engagement dynamics. Marketing management is crucial to business efficiency, customer relations, and growth. Effective marketing strategies help businesses increase revenue, market share, and reputation. Marketing initiatives also support non-profit goals, community engagement, and social causes. Understanding AI tools for customer engagement reveals voice-activated chatbots, sentiment analysis, facial recognition, NLP, and visual search. These AI-powered tools help businesses personalize interactions, interpret customer sentiment, and streamline service delivery, improving customer experiences.Businesses can deliver ultra-personalized solutions, predict consumer preferences, and optimize communication channels using AI tools to improve customer engagement. Companies can boost customer satisfaction, brand loyalty, and market share by using AI-driven insights and analytics. The study explore how AI may affect customer engagement to see its transformative potential across industries. AI helps businesses analyse data, predict consumer behaviour, and personalize interactions, revolutionizing customer experience. However, data privacy, security, and ethics require responsible deployment and strategic adaptation. The convergence of marketing management and AI offers unprecedented opportunities to transform customer engagement strategies. Businesses can improve customer satisfaction, brand loyalty, and digital growth by adopting AI-driven technologies and addressing their challenges.  © 2024 IEEE.},
	author_keywords = {AI tools; artificial intelligence; brand loyalty; customer engagement; customer satisfaction; data analysis; digital era; marketing management; personalized interactions},
	keywords = {Data privacy; Information management; Public relations; Sales; Steganography; Strategic planning; AI tool; Brand loyalty; Business operation; Customer engagement; Customer experience; Customers' satisfaction; Digital era; Market share; Marketing management; Personalized interaction; Customer satisfaction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Phukan20245740,
	author = {Phukan, Arpan and Pal, Santanu and Ekbal, Asif},
	title = {Hybrid Quantum-Classical Neural Network for Multimodal Multitask Sarcasm, Emotion, and Sentiment Analysis},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	volume = {11},
	number = {5},
	pages = {5740 – 5750},
	doi = {10.1109/TCSS.2024.3388016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192964573&doi=10.1109%2fTCSS.2024.3388016&partnerID=40&md5=342d287d80a4c4465669afb67d6dfbe2},
	abstract = {Sarcasm detection in unimodal or multimodal setting is a very complex task. Sarcasm, emotion, and sentiment are related to each other, and hence any multitask model could be an effective way to leverage the interdependence among these tasks. In order to better represent these clandestine associations, we avoid solely relying on traditional machine learning methods to encode the relationships between the modalities. In this article, we propose a hybrid quantum model that banks upon the low computational complexity and robust representational power of a variational quantum circuit (VQC) and the tried and tested dense neural network to tackle sentiment, emotion, and sarcasm classification simultaneously. We empirically establish that the quantum properties like superposition, entanglement, and interference will better capture and replicate not only the cross-modal interactions between text, acoustics, and visuals but also the correlations between the three responses. We consider the extended MUStARD dataset to evaluate our proposed hybrid model. The results show that our proposed hybrid quantum framework yields more promising results for the primary task of sarcasm detection with the help of the two secondary classification tasks, viz. sentiment and emotion. © 2014 IEEE.},
	author_keywords = {Hybrid quantum-classical neural network; multimodal data; quantum machine learning},
	keywords = {Complex networks; Job analysis; Machine learning; Modal analysis; Quantum entanglement; Quantum optics; Classical neural networks; Hybrid quantum-classical neural network; Interference; Machine-learning; Multi-modal data; Quantum Computing; Quantum machine learning; Quantum machines; Quantum state; Quantum system; Quantum-classical; Task analysis; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Silver2024,
	author = {Silver, Daniel and Ranjan, Aditya and Achutha, Rakesh and Patel, Tirthak and Tiwari, Devesh},
	title = {LEXIQL: Quantum Natural Language Processing on NISQ-era Machines},
	year = {2024},
	journal = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC},
	doi = {10.1109/SC41406.2024.00073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214972426&doi=10.1109%2fSC41406.2024.00073&partnerID=40&md5=f42134061debf7769a930597f121b5b6},
	abstract = {The rapid evolution of quantum hardware is propelling quantum computing to new frontiers. Nonetheless, the potential of natural language processing in the quantum paradigm (QNLP) is yet to be explored, including for Noisy Intermediate-Scale Quantum (NISQ) machines. To explore the QNLP frontier, we introduce LEXIQL, a novel noise-aware QNLP technique for text classification on NISQ quantum machines. LEXIQL employs an incremental data injection approach to process textual data in a quantum circuit. It also develops new and effective training methods, such as leveraging a diverse mix of expressible and shallow quantum circuits for the QNLP task of text classification. Our extensive evaluation using Yelp, IMDB, and Amazon datasets (along with synthetic QLNP datasets) demonstrates the effectiveness of LEXIQL's noise-aware design in both ideal and noisy environments. © 2024 IEEE.},
	author_keywords = {Natural Language Processing; Quantum Computing; Quantum Machine Learning},
	keywords = {Adversarial machine learning; Natural language processing systems; Network security; Quantum electronics; Incremental data; Language processing; Machine-learning; Natural language processing; Natural languages; Quantum circuit; Quantum Computing; Quantum machine learning; Quantum machines; Text classification; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Swathi2024,
	author = {Swathi, K. and Kamalam, G.K. and Suganya Baby, N. and Aadhishri, A. and Kawethaa Shree, D.K.},
	title = {Emotion Analysis of English-Translated Tamil Literature},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211188287&doi=10.1109%2fICCCNT61001.2024.10724485&partnerID=40&md5=08aea29e37414aa00d716915948ce086},
	abstract = {Focus of this study is to investigate the nuanced world of emotions in English-translated Tamil literature through the lens of sentiment analysis. The dataset consists of poems expressing a range of emotions including joy, sadness, love, anger, pride, courage, and fear. To effectively analyze and classify these emotions, we utilized cutting-edge transformer-based models, like BERT, DistilBERT, and RoBERTa, to conduct our analysis. The outcomes of our study showcase the exceptional capabilities of these models in effectively analyzing emotions within poetic expressions. RoBERTa, in particular, emerged as a standout choice, consistently achieving high accuracy, precision, recall, and F1 scores across all emotion categories. Its extensive pre-training and dynamic masking techniques allowed itto excel in capturing the intricate emotional nuancesembedded in the translated poems. DistilBERT demonstrated commendable efficiency without compromising accuracy, making it a practical option for real-time sentiment analysis. BERT, although a strong performer, showcased marginally reduced efficiency compared to RoBERTa and DistilBERT.  © 2024 IEEE.},
	author_keywords = {BERT; DistilBERT; Emotion Analysis; Natural Language Processing; poem; RoBERTa},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nagaraj2024,
	author = {Nagaraj, R. and Rohith Adithya, C.R. and Sri Chakra Teja, Sakalabathula and Deepika, T.},
	title = {Identifying the Influences Behind the LinkedIn Posts using Topic Modeling and Sentiment Analysis},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545141},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204459772&doi=10.1109%2fTQCEBT59414.2024.10545141&partnerID=40&md5=55e8aa6cd06cb5e25747cfb40d2aa5cf},
	abstract = {The proliferation of social networking in the modern world has made it a ubiquitous presence in people's lives. On a daily basis, individuals post and share their opinions, rating products, and engage in business-related activities. Social media platforms play a crucial role in the business field, facilitating the establishment of relationships with prospects and clients. As such, LinkedIn has emerged as the ideal online platform for building trust by sharing success stories, business promotions, and recommendations through posts. This professional website serves as a means of connecting the world's professionals with the general public. At the same time, many people post opinions and professional content regularly, and only a select few post become influenced by reaching larger community. The factors responsible for this influence remain unknown, prompting us to propose a solution based on topic modeling and sentiment analysis. Our project aims to identify the influences behind LinkedIn posts by examining the role of media content in posts, and by utilizing natural language processing techniques to analyze the underlying aspects of posts which then examined using topic modeling and sentiment analysis to identify subtopics and aspects present in the posts.  © 2024 IEEE.},
	author_keywords = {Media; Natural language processing; Sentiment analysis; Topic modeling; Topics},
	keywords = {Tweets; Language processing; LinkedIn; Medium; Modeling analyzes; Natural language processing; Natural languages; Sentiment analysis; Social-networking; Topic; Topic Modeling; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gao2025,
	author = {Gao, Hui and Zhang, Peng and Zhang, Jing and Yang, Chang},
	title = {QSIM: A Quantum-inspired hierarchical semantic interaction model for text classification},
	year = {2025},
	journal = {Neurocomputing},
	volume = {611},
	doi = {10.1016/j.neucom.2024.128658},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205739010&doi=10.1016%2fj.neucom.2024.128658&partnerID=40&md5=f7c308e7ffee3a888f36aabeb98b7a4d},
	abstract = {Semantic interaction modeling is a fundamental technology in natural language understanding that guides models to extract deep semantic information from text. Currently, the attention mechanism is one of the most effective techniques in semantic interaction modeling, which learns word-level attention representation by measuring the relevance between different words. However, the attention mechanism is limited to word-level semantic interaction, it cannot meet the needs of fine-grained interactive information for some text classification tasks. In recent years, quantum-inspired language modeling methods have successfully constructed quantized representations of language systems in Hilbert spaces, which use density matrices to achieve fine-grained semantic interaction modeling. This paper presents a Quantum-inspired hierarchical Semantic Interaction Model (QSIM), which follows the sememe-word-sentence language construction principle and utilizes quantum entanglement theory to capture hierarchical semantic interaction information in Hilbert space. Our work builds on the idea of the attention mechanism and extends it. Specifically, we explore the original semantic space from a quantum theory perspective and derive the core semantic space using the Schmidt decomposition technique, where: (1) Sememe is represented as the unit vector in the two-dimensional minimum semantic space; (2) Word is represented as reduced density matrices in the core semantic space, where Schmidt coefficients quantify sememe-level semantic interaction. Compared to density matrices, reduced density matrices capture fine-grained semantic interaction information with lower computational cost; (3) Sentence is represented as quantum superposition states of words, and the degree of word-level semantic interaction is measured using entanglement entropy. To evaluate the model's performance, we conducted experiments on 15 text classification datasets. The experimental results demonstrate that our model is superior to classical neural network models and traditional quantum-inspired language models. Furthermore, the experiment also confirms two distinct advantages of QISM: (1) flexibility, as it can be integrated into various mainstream neural network text classification architectures; and (2) practicability, as it alleviates the problem of parameter growth inherent in density matrix calculation in quantum language model. © 2024},
	author_keywords = {Attention mechanism; Entanglement entropy; Quantum language model; Schmidt decomposition},
	keywords = {Hilbert spaces; Matrix algebra; Natural language processing systems; Problem oriented languages; Semantics; Attention mechanisms; Entanglement entropy; Interaction modeling; Language model; Quantum language model; Schmidt decomposition; Semantic interactions; Semantic Space; Text classification; Word level; article; artificial neural network; classification; controlled study; decomposition; entropy; human; language model; nerve cell network; quantum theory; Quantum entanglement},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Zhang202497,
	author = {Zhang, Chi and Kumari, Akriti and Cavar, Damir},
	title = {Entangled Meanings: Classification and Ambiguity Resolution in QNLP},
	year = {2024},
	journal = {Proceedings - IEEE Quantum Week 2024, QCE 2024},
	volume = {2},
	pages = {97 – 102},
	doi = {10.1109/QCE60285.2024.10260},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217154508&doi=10.1109%2fQCE60285.2024.10260&partnerID=40&md5=7115714c49be250e89d47048530f7dd1},
	abstract = {We discuss experiments involving two tasks in Quantum Natural Language Processing (QNLP): text classification and disambiguation. In the classification task, we utilized an amplitude encoding algorithm and achieved perfect accuracy on the lambeq dataset discussed in literature. We obtained accuracy from 55% to 72.5% on the more complex and realistic Amazon review dataset. This is a reasonable result given the current state-of-the-art results in QNLP. Additionally, when using vector dimension reduction for embeddings, we found that UMAP leads to the best results in our experiment setting. All classification results were done on the default. qubit simulator in pennylane 0. 36 python library. Our classification results highlight the potential of quantum algorithms in practical applications. In the disambiguation task, we selected 18 ambiguous nouns, 32 unambiguous nouns, and 18 different verbs. Our experiments using the QASM simulator within the qiskit Python library demonstrated that the simulator could perfectly differentiate between the various meanings of ambiguous nouns in different contexts. Furthermore, we extended our study to a real quantum device, the ibm-kyoto quantum computer. There, we tested our disambiguation approach on a subset of 4 random nouns (2 ambiguous and 2 unambiguous) and observed that ibm-kyoto could achieve an accuracy range of 82.1% to 98.9% in disambiguation tasks, extending the datasets and improving the results of existing ambiguity resolution experiments [1]. Our work demonstrates the capability of quantum computing in dealing with real-world NLP tasks, hence contributing to the advancement of both OML and NLP. © 2024 IEEE.},
	author_keywords = {Natural Language Processing; Semantics; Sentiment Analysis; Supervised Machine Learning},
	keywords = {Natural language processing systems; Network security; Problem oriented languages; Python; Quantum electronics; Quantum entanglement; Self-supervised learning; Semantics; Semi-supervised learning; Ambiguity resolution; Classification results; Classification tasks; Encoding algorithms; Language processing; Natural language processing; Natural languages; Sentiment analysis; Supervised machine learning; Text classification; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ekawaty2024,
	author = {Ekawaty, Anita and Nabila, Efa Ayu and Anjani, Sheila Aulia and Rahardja, Untung and Zebua, Selamat},
	title = {Utilizing Sentiment Analysis to Enhance Customer Feedback Systems in Banking},
	year = {2024},
	journal = {2024 12th International Conference on Cyber and IT Service Management, CITSM 2024},
	doi = {10.1109/CITSM64103.2024.10775629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214880844&doi=10.1109%2fCITSM64103.2024.10775629&partnerID=40&md5=181f933488c50e48b109d565c43988d5},
	abstract = {The banking industry faces challenges in effectively capturing and analyzing customer feedback, particularly in identifying the true sentiments and opinions of customers. Conventional feedback systems often lack accuracy and are slow to respond to customer needs and complaints, which can negatively impact customer satisfaction and loyalty. To address this issue, this study aims to enhance customer feedback systems by utilizing sentiment analysis, a natural language processing (NLP) technique capable of categorizing customer opinions as positive, negative, or neutral. The research method involves collecting customer feedback data from various sources such as social media, surveys, and online reviews. This data is then analyzed using sentiment analysis algorithms designed to identify emotional patterns in the text. The results indicate that the use of sentiment analysis significantly improves the accuracy and efficiency of customer feedback processing, enabling banks to provide faster and more relevant responses to customer needs. In conclusion, sentiment analysis can significantly strengthen customer feedback systems in the banking sector, offering banks better insights into customer sentiments in real-time. This ultimately contributes to improved customer satisfaction and loyalty, as well as enhancing the quality of services provided. © 2024 IEEE.},
	author_keywords = {Customer Feedback; Customer Loyalty; Natural Language Processing (NLP); Sentiment Analysis},
	keywords = {Banking; Customer satisfaction; Natural language processing systems; Banking industry; Customer feedback; Customer loyalty; Customer need; Customers' satisfaction; Feedback systems; Language processing; Natural language processing; Natural languages; Sentiment analysis; Sales},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Singh2025170,
	author = {Singh, Jaiteg and Bhangu, Kamalpreet Singh and Alkhanifer, Abdulrhman and AlZubi, Ahmad Ali and Ali, Farman},
	title = {Quantum neural networks for multimodal sentiment, emotion, and sarcasm analysis},
	year = {2025},
	journal = {Alexandria Engineering Journal},
	volume = {124},
	pages = {170 – 187},
	doi = {10.1016/j.aej.2025.03.023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001341079&doi=10.1016%2fj.aej.2025.03.023&partnerID=40&md5=0ab16362c60a6b5785db9a64871417ac},
	abstract = {Sentiment, emotion, and sarcasm analysis in multimodal dialogues is crucial for understanding the underlying intentions and attitudes expressed by individuals. Traditional methods often struggle to capture the full intensity of these polarities, leading to less accurate results. To address this limitation, we propose a quantum-inspired approach leveraging Quantum Neural Networks (QNNs) for enhanced classification and intensity analysis. A key component of our method is the Variational Quantum Eigensolver (VQE), a hybrid quantum-classical algorithm that optimizes the parameters of the QNN by minimizing the eigenvalues of a Hamiltonian system. This optimization enables the network to learn complex relationships in multimodal data more effectively. Our approach surpasses state-of-the-art methods, achieving up to 7.5 % higher accuracy and 6.8 % greater precision. Experiments on benchmark datasets such as MUStARD, Memotion, CMU-MOSEI, and MELD demonstrate its effectiveness, with an F1-score of 87.3 % on CMU-MOSEI. This method is particularly beneficial in domains like social media, customer support, and entertainment, where both verbal and non-verbal cues play a critical role in accurate sentiment analysis. © 2025 The Authors},
	author_keywords = {Emotion quantification; Multimodal dialogue; Quantum cognition; Quantum Neural Networks (QNN); Variational Quantum Eigensolver (VQE)},
	keywords = {Eigenvalues and eigenfunctions; Neural networks; Quantum communication; Quantum electronics; Quantum optics; Variational techniques; Classification analysis; Eigensolvers; Emotion quantification; Intensity analysis; Multi-modal; Multimodal dialogue; Quantum cognition; Quantum neural network; Quantum neural networks; Variational quantum eigensolver; Hamiltonians},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ruskanda2024,
	author = {Ruskanda, Fariska Zakhralativa and Halim, Michael Jonathan and Kurniawan, Farizki and Syafalni, Infall and Mulyawan, Rahmat and Higo, Akio},
	title = {Enhancing Quantum NLP Robustness - Analysis on Noisy Models for Quantum Sentiment Classification},
	year = {2024},
	journal = {2024 11th International Conference on Advanced Informatics: Concept, Theory and Application, ICAICTA 2024},
	doi = {10.1109/ICAICTA63815.2024.10763118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214675092&doi=10.1109%2fICAICTA63815.2024.10763118&partnerID=40&md5=8fc5245f34cfe5b50a42e3b316209ab4},
	abstract = {This research aims to improve the robustness of Quantum Natural Language Processing (QNLP) models in the presence of noise. Using Lambeq, an open-source library for quantum NLP, we focus on sentiment classification tasks to evaluate the impact of noisy quantum models. Our study involves the application of three types of optimizers: Simultaneous Perturbation Stochastic Approximation (SPSA), Nelder-Mead, and Adam. The performance and resilience of these optimizers are assessed under various noise conditions to determine their effectiveness in maintaining model accuracy and stability. The research shows that the Adam optimizer outperforms SPSA and NelderMead in QNLP simple sentiment analysis tasks, both in noiseless and noisy environments. Adam achieved 96.67 % accuracy in noiseless conditions, significantly higher than SPSA's 83.33 % and Nelder-Mead's 53.33%, highlighting its superior performance in optimizing quantum circuits. Moreover, in noisy simulation, Adam outperforms others with 70.00% accuracy performance. The work is useful for NLP implementations in quantum computers. This research is essential because the noisy nature of current quan-tum computers makes it difficult for QNLP models to perform accurately and reliably.  © 2024 IEEE.},
	author_keywords = {noisy quantum; Quantum Natural Language Processing; robustness; sentiment classification},
	keywords = {Modeling languages; Natural language processing systems; Quantum electronics; Quantum noise; Stochastic models; Stochastic systems; Language processing; Natural languages; Nelder meads; Noisy quantum; Optimizers; Performance; Processing model; Quantum natural language processing; Robustness; Sentiment classification; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2024,
	author = {Liu, Yun},
	title = {Role of Natural Language Processing in Document Understanding and Semantic Analysis: A Chinese Perspective},
	year = {2024},
	journal = {Profesional de la Informacion},
	volume = {33},
	number = {3},
	doi = {10.3145/epi.2025.ene.0324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205785057&doi=10.3145%2fepi.2025.ene.0324&partnerID=40&md5=d52a44977fd75cb0cf4316110c1cff99},
	abstract = {With the recent advancements in Natural Language Processing (NLP), there is a growing need to enhance the effectiveness and accuracy of document understanding and sentiment analysis particularly for Chinese text as it presents unique challenges of linguistics. To conduct this study, a hybrid approach was implemented which combined CNN and BiLSTM models with an ensemble voting mechanism for sentiment analysis on Chinese text. This method attained an accuracy of 97% and outperformed other techniques such as Text_CNN and AttentionBiLSTM with significant improvements in F1 score and recall. Results demonstrated a superior performance achieving 97% accuracy, along with a 95% F1 score and 97% recall. The present study extends the growing body of literature by underscoring the effectiveness of integrating BiLSTM and CNN models in sentiment analysis within the context of Chinese linguistics. It showcased enhanced document comprehension and capabilities of semantic analysis. Practically, this study provides a robust framework for leveraging BiLSTM and CNN models in the sentiment analysis of real-world. It offers significant boost in adequacy and reliability for processing Chinese text. The research limitations and future research indications have also been addressed in the study. © 2024, El Profesional de la Informacion. All rights reserved.},
	author_keywords = {Bidirectional Long short-term Memory; Convolutional Neural Network; Natural Language Processing; Semantic Analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {2024 28th International Conference on Information Technology, IT 2024},
	year = {2024},
	journal = {2024 28th International Conference on Information Technology, IT 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190439140&partnerID=40&md5=7456e48a98a8b686596e9148eaa944d3},
	abstract = {The proceedings contain 52 papers. The topics discussed include: exploring and analyzing spam messages: a comprehensive study using python, natural language processing and machine learning models; a comparative analysis of different natural exponent inertia weight strategies for particle swarm optimization in multilevel image thresholding; machine learning for cybersecurity frameworks in smart farming; implementing an IoT system for sea to fork transparency and consumer engagement; random walk operator-based Fourier transform in connected directed acyclic graphs; formation path following of multiple underactuated surface vehicles in presence of unknown environmental forces; multi-swarm particle swarm optimization with chaotic random inertia weight and dynamic learning strategy for multilevel thresholding image segmentation; a quantum computing based approach for sentiment analysis in bilateral conversations; and assessing compressive sensing methods for impulsive noise reduction in audio signals.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Peral-García2024,
	author = {Peral-García, David and Cruz-Benito, Juan and García-Peñalvo, Francisco José},
	title = {Comparing Natural Language Processing and Quantum Natural Processing approaches in text classification tasks},
	year = {2024},
	journal = {Expert Systems with Applications},
	volume = {254},
	doi = {10.1016/j.eswa.2024.124427},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195522704&doi=10.1016%2fj.eswa.2024.124427&partnerID=40&md5=7cd29a9949f7e56f227dd83cdf776b58},
	abstract = {Quantum physics and mechanics have demonstrated significant advances and promising results in different areas using the current near-term devices. One emerging subarea in quantum machine learning is quantum natural language processing, which combines quantum computing advantages and speedups with language processing algorithms to create and perform natural language tasks such as text classification or generation. The libraries and toolboxes used in this subarea include DisCoPy and lambeq, which are used to transform sentences into string diagrams or monoidal functors, convert these diagrams into quantum circuits or ansatz and embed it into a quantum model. In this study, we used both libraries with different text-based datasets to perform sentiment analysis via classification. To do so, we create synthetic datasets to train the different models. After we obtain satisfactory results, we test the resulting models with known datasets. Despite its promising results, quantum natural language processing is far from achieving its full potential. To achieve this potential, the quantum software and hardware must be improved to make them suitable for use with more extensive and complex datasets and other tasks. © 2024 The Author(s)},
	author_keywords = {Quantum computing; Quantum Machine Learning; Quantum natural language processing},
	keywords = {Algebra; Classification (of information); Libraries; Machine learning; Classification tasks; Language processing; Machine-learning; Natural languages; Processing approach; Quantum Computing; Quantum machine learning; Quantum machines; Quantum natural language processing; Text classification; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{EL Azzaoui2025,
	author = {EL Azzaoui, Abir and Camacho, David and Park, Jong Hyuk},
	title = {Hybrid Quantum Fuzzy Neural Network Approach- Based SNS Sentimental Analysis for Stock Market Prediction},
	year = {2025},
	journal = {Human-centric Computing and Information Sciences},
	volume = {15},
	doi = {10.22967/HCIS.2025.15.015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003626616&doi=10.22967%2fHCIS.2025.15.015&partnerID=40&md5=729e8189f6336407a01dbc1c0aa006fc},
	abstract = {The growing reliance on artificial intelligence (AI) and big data in financial market analysis demands innovative methodologies to improve the accuracy of market trend predictions. Traditional models, which primarily focus on numerical stock market indicators, often fail to account for the psychological and sentiment-driven factors that significantly influence market behavior. This paper presents a hybrid approach that integrates sentiment data from social media platforms, such as Twitter, with conventional stock market indices using quantum fuzzy neural networks (QFNNs). By harnessing the computational power of quantum processors, the adaptability of fuzzy logic, and the pattern recognition capabilities of neural networks, the proposed system achieves enhanced predictive accuracy and provides deeper insights into market dynamics. The QFNN model demonstrates remarkable performance, with classification models like the support vector classifier (SVC) using radial basis function kernels achieving an accuracy of 98% and an F1-score of 97%. Additionally, the random forest (RF) model attains even higher accuracy at 99%, paired with an F1-score of 99%. The robustness of the model is further validated through receiver operating characteristic curves, with area under the curve scores reaching 1.0 for both SVC and RF models, underscoring their exceptional discriminatory power. This integration of qualitative sentiment analysis with quantitative market data represents a significant paradigm shift in financial forecasting, addressing many limitations of classical methods. Beyond stock market prediction, the study highlights the broader applicability of QFNNs in domains requiring large-scale data analysis and decisionmaking under uncertainty. The findings underscore the transformative potential of quantum computing and fuzzy logic in advancing AI-driven economic modeling and shaping the future of financial analytics. © (2024), (Korea Information Processing Society). All Rights Reserved.},
	author_keywords = {Fuzzy Logic; QFNN; Quantum Machine Learning; Sentimental Analysis; Stock Market Prediction},
	keywords = {Discriminant analysis; Emotion Recognition; Fuzzy neural networks; Labeled data; Marketplaces; Quantum channel; Quantum electronics; Quantum optics; F1 scores; Fuzzy-Logic; Fuzzy-neural-networks; Machine-learning; Quantum fuzzy neural network; Quantum machine learning; Quantum machines; Sentimental analyze; Stock market prediction; Support vector classifiers; Qubits},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Talghalit20241024,
	author = {Talghalit, Ismail Ait and Alami, Hamza and El Alaoui, Said Ouatik},
	title = {Contextual Semantic Embeddings Based on Transformer Models for Arabic Biomedical Questions Classification},
	year = {2024},
	journal = {HighTech and Innovation Journal},
	volume = {5},
	number = {4},
	pages = {1024 – 1037},
	doi = {10.28991/HIJ-2024-05-04-011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214349141&doi=10.28991%2fHIJ-2024-05-04-011&partnerID=40&md5=4f34ad5ddebc6f03327f0e02de441230},
	abstract = {Arabic biomedical question classification (ABQC) is a challenging task due to various reasons including, the specialized jargon expressed in Arabic language, complex semantics of Arabic vocabulary and the lack of specific datasets and corpora. When representing questions, only a few studies deal with ABQC by taking into account the word context. In this work, we propose a classification model designed for Arabic biomedical questions. We build vector representations capturing the contextual and semantic information of Arabic biomedical text, which presents numerous challenges, such as the derivational morphology of Arabic language, the specialized terminology of biomedical terms and the lack of capitalization in text. Our representation adapts the extensive knowledge encoded in BERT (Bidirectional Encoder Representations from Transformers) and other transformer models, to address the aforementioned challenges. Several experiments have been conducted on a dedicated Arabic biomedical dataset namely: MAQA, with well-known transformer models including BERT, AraBERT, BioBERT, RoBERTa, and DistilBERT fine-tuned for the classification task. Obtained results show that our method achieves remarkable performance with an accuracy of 93.31% and an F1-score of 93.35%. © Authors retain all.},
	author_keywords = {Arabic Question Classification; BERT; Biomedical Domain; Fine-Tuning; Natural Language Processing; Question Answering Systems; Sentence Embedding; Transformers},
	keywords = {Distribution transformers; Embeddings; Natural language processing systems; Semantics; Arabic question classification; Bidirectional encoder representation from transformer; Biomedical domain; Embeddings; Fine tuning; Language processing; Natural language processing; Natural languages; Question answering systems; Question classification; Sentence embedding; Transformer; Question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Pandey2024695,
	author = {Pandey, Shyambabu and Pakray, Partha and Manna, Riyanka},
	title = {Quantum Classifier for Natural Language Processing Applications},
	year = {2024},
	journal = {Computacion y Sistemas},
	volume = {28},
	number = {2},
	pages = {695 – 700},
	doi = {10.13053/CyS-28-2-5016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197712123&doi=10.13053%2fCyS-28-2-5016&partnerID=40&md5=b6e1d43e0bda0aa49fec6731461ac6a0},
	abstract = {A deep neural network is a branch of machine learning that is capable of learning and representing complex patterns from a dataset through interconnected multiple layers of neurons. This capability makes it applicable in various fields, such as natural language processing, image processing, and computer vision. Deep learning models show effective performance but face challenges such as complexity and resource demands. On the other hand, quantum machine learning algorithms offer an alternative with potential efficiency compared to their classical counterparts. This paper proposes a Quantum Recurrent Neural Network (QRNN) for natural language processing tasks, which classify text data such as parts of speech, named entity recognition, and sentiment analysis. The proposed method utilizes parameterized quantum circuits that contain the tunable parameters. Our approach uses amplitude encoding to represent classical data into quantum states, partial measurement for label determination, and ancilla qubits to transfer the information from the current state to the next. © 2024 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {natural language processing; Quantum computing; quantum machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gîfu2025143,
	author = {Gîfu, Daniela},
	title = {Exploring the potential of e-learning in economic crisis prediction},
	year = {2025},
	journal = {Proceedings of the International Conference on Virtual Learning},
	volume = {20},
	pages = {143 – 154},
	doi = {10.58503/icvl-v20y202512},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003554770&doi=10.58503%2ficvl-v20y202512&partnerID=40&md5=922e7021fbb78bf95e90b956c68a3ac7},
	abstract = {This study explores e-learning’s potential to anticipate economic crises, positioning it as a key tool for global financial stability. By leveraging AI-driven text analysis — proven effective in financial forecasting — five predictive algorithms were assessed: exchange rate processing, logistic regression, linear regression, recurrent neural networks, and sentiment analysis. Using a 2008–2018 dataset, the goal is to develop an e learning system that delivers reliable crisis predictions, enhancing proactive economic risk management. © 2025, National Institute for R and D in Informatics. All rights reserved.},
	author_keywords = {AI; e-learning; economic crisis; financial forecasting; predictive models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2025705,
	author = {Yang, Xi and Zhu, Jia and De Meo, Pasquale},
	title = {A quantum-like zero-shot approach for sentiment analysis in finance},
	year = {2025},
	journal = {Journal of Intelligent Information Systems},
	volume = {63},
	number = {3},
	pages = {705 – 721},
	doi = {10.1007/s10844-024-00912-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211792896&doi=10.1007%2fs10844-024-00912-6&partnerID=40&md5=3a3dd5c84c14917d716ed3e3b52d6d5b},
	abstract = {Sentiment analysis has become an indispensable tool across various domains, including political communication, marketing analytics, and finance. In the financial sector, sentiments such as confidence or fear play a pivotal role in shaping market dynamics, influencing supply and demand, and precipitating significant price fluctuations. The timely extraction of sentiment from sources like financial news articles and social media posts is crucial for devising informed investment strategies. Despite its importance, current approaches to sentiment analysis in finance have not fully harnessed the potential of emerging technologies, such as large language models (LLMs) and quantum computing models. These cutting-edge technologies have demonstrated remarkable success in other areas of natural language processing (NLP), but their application in financial sentiment analysis remains limited. This paper aims to bridge this gap by introducing a novel quantum model for text representation, specifically designed for the financial domain. Our approach integrates this quantum representation with a vector-based representation generated by a pre-trained LLM specialized in finance. The resulting fusion of these two representations yields a more comprehensive input for an LLM, leading to a significant enhancement in the accuracy of the sentiment analysis task. We evaluate our approach through extensive experimental tests on a publicly available dataset and demonstrate that our quantum-based method outperforms state-of-the-art models on a widely recognized financial sentiment analysis benchmark. Our results highlight the potential of integrating quantum computing principles with traditional NLP methods for more accurate and effective sentiment analysis in finance. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Large Language Models; Sentiment Analysis; Zero-shot Learning},
	keywords = {Benchmarking; Economic and social effects; Financial data processing; Financial markets; Investments; Quantum optics; Sentiment analysis; Financial sectors; Indispensable tools; Language model; Language processing; Large language model; Market dynamics; Natural languages; Political communication; Price fluctuation; Sentiment analysis; Zero-shot learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wu2025,
	author = {Wu, Huaiguang and Kong, Delong and Wang, Lijie and Li, Daiyi and Zhang, Jiahui and Han, Yucan},
	title = {Multimodal sentiment analysis method based on image-text quantum transformer},
	year = {2025},
	journal = {Neurocomputing},
	volume = {637},
	doi = {10.1016/j.neucom.2025.130107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001500978&doi=10.1016%2fj.neucom.2025.130107&partnerID=40&md5=00f50fe35e9dbd6cf5cd7683c9ae5095},
	abstract = {Multimodal sentiment analysis aims to recognize and interpret the diverse emotional information contained in different modal data. Although multimodal sentiment analysis methods have achieved significant results, they still have certain limitations in capturing the complex features of high-dimensional data. This paper proposes a multimodal sentiment analysis method utilizing the Image and Text Quantum Transformer (ITQT-MSA), which innovatively combines quantum computing and deep learning technologies to achieve more accurate emotion recognition and analysis. Firstly, a text-oriented parametric quantum circuit is designed that exploits quantum superposition and entanglement properties and combines the transformer model to achieve deep feature extraction from text data. Secondly, another image-oriented parametric quantum circuit is constructed and combined with the Visual Transformer (VIT) to adequately extract the emotional information in the image. Finally, effective alignment and the integration of features from both text and images are achieved by the designed cross-attention fusion mechanism. The experiments are performed on classical computers by designing quantum circuits within a simulated noisy environment, and the results show that the proposed method outperforms SOTA models. © 2025 Elsevier B.V.},
	author_keywords = {Cross-attention fusion; Multimodal sentiment analysis; Parameterized quantum circuit; Quantum transformer; Visual Transformer},
	keywords = {Deep learning; Emotion Recognition; Quantum electronics; Quantum entanglement; Analysis method; Cross-attention fusion; Multi-modal; Multimodal sentiment analyze; Parameterized; Parameterized quantum circuit; Quantum circuit; Quantum transformer; Sentiment analysis; Visual transformer; accuracy; Article; deep learning; emotion; environmental noise; feature extraction; image text  quantum transformer; multimodal sentiment analysis; quantum mechanics; sentiment analysis; simulation; training; Quantum computers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Erkan2024,
	author = {Erkan, Ali and Güngör, Tunga},
	title = {Sentiment analysis using averaged weighted word vector features},
	year = {2024},
	journal = {PLoS ONE},
	volume = {19},
	number = {4 April},
	doi = {10.1371/journal.pone.0299264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189290667&doi=10.1371%2fjournal.pone.0299264&partnerID=40&md5=656e31d4b6043fd7ee58b25520e6b820},
	abstract = {People use the World Wide Web heavily to share their experiences with entities such as products, services or travel destinations. Texts that provide online feedback through reviews and comments are essential for consumer decisions. These comments create a valuable source that may be used to measure satisfaction related to products or services. Sentiment analysis is the task of identifying opinions expressed in such text fragments. In this work, we develop two methods that combine different types of word vectors to learn and estimate the polarity of reviews. We create average review vectors from word vectors and add weights to these review vectors using word frequencies in positive and negative sensitivity-tagged reviews. We applied the methods to several datasets from different domains used as standard sentiment analysis benchmarks. We ensemble the techniques with each other and existing methods, and we compare them with the approaches in the literature. The results show that the performances of our approaches outperform the state-of-the-art success rates.  © 2024 Erkan, Güngör. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Attitude; Humans; Internet; Sentiment Analysis; article; benchmarking; consumer; human; human experiment; Internet; open access publishing; sentiment analysis; travel; attitude},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Faccia2024,
	author = {Faccia, Alessio and McDonald, Julie and George, Babu},
	title = {NLP Sentiment Analysis and Accounting Transparency: A New Era of Financial Record Keeping},
	year = {2024},
	journal = {Computers},
	volume = {13},
	number = {1},
	doi = {10.3390/computers13010005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183374847&doi=10.3390%2fcomputers13010005&partnerID=40&md5=e12b465437d98590cc87fa19bd7e90fc},
	abstract = {Transparency in financial reporting is crucial for maintaining trust in financial markets, yet fraudulent financial statements remain challenging to detect and prevent. This study introduces a novel approach to detecting financial statement fraud by applying sentiment analysis to analyse the textual data within financial reports. This research aims to identify patterns and anomalies that might indicate fraudulent activities by examining the language and sentiment expressed across multiple fiscal years. The study focuses on three companies known for financial statement fraud: Wirecard, Tesco, and Under Armour. Utilising Natural Language Processing (NLP) techniques, the research analyses polarity (positive or negative sentiment) and subjectivity (degree of personal opinion) within the financial statements, revealing intriguing patterns. Wirecard showed a consistent tone with a slight decrease in 2018, Tesco exhibited marked changes in the fraud year, and Under Armour presented subtler shifts during the fraud years. While the findings present promising trends, the study emphasises that sentiment analysis alone cannot definitively detect financial statement fraud. It provides insights into the tone and mood of the text but cannot reveal intentional deception or financial discrepancies. The results serve as supplementary information, enriching traditional financial analysis methods. This research contributes to the field by exploring the potential of sentiment analysis in financial fraud detection, offering a unique perspective that complements quantitative methods. It opens new avenues for investigation and underscores the need for an integrated, multidimensional approach to fraud detection. © 2023 by the authors.},
	author_keywords = {financial statement fraud; forensic accounting; fraud detection; natural language processing (NLP); sentiment analysis; Tesco; Under Armour; Wirecard},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{Zhang2024460,
	author = {Zhang, Chi and Kumari, Akriti and Cavar, Damir},
	title = {Entangled Meanings: Classification and Ambiguity Resolution in Near-Term QNLP},
	year = {2024},
	journal = {Proceedings - IEEE Quantum Week 2024, QCE 2024},
	volume = {2},
	pages = {460 – 461},
	doi = {10.1109/QCE60285.2024.10355},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217188685&doi=10.1109%2fQCE60285.2024.10355&partnerID=40&md5=f8c2556c27427003d8a904cabaa02fd5},
	abstract = {We demonstrate two tasks in Quantum Natural Language Processing (QNLP): classification and disambiguation. For the classification task, we utilized an amplitude encoding algorithm and achieved perfect accuracy on the standard lambeq dataset, which is commonly used for benchmarking in quantum NLP. Additionally, we obtained accuracy from 55% to 72.5 % on a more complex and realistic Amazon review dataset, which is still a reasonable result, given the current capability of quantum computing and QNLP. Additionally, we found that UMAP is the best dimension reduction method in our experiment setting. All classification results were done on the default. qubit simulator in pennylane 0.36 python library. Our classification results highlight the potential of quantum algorithms in practical applications. For the disambiguation task, we selected 18 ambiguous nouns, 32 unambiguous nouns, and 18 different verbs. Our experiments using the QASM simulator within the qiskit Python library demonstrated that the simulator could perfectly differentiate between the various meanings of ambiguous nouns in different contexts, achieving perfect differentiation. Furthermore, we extended our study to a real quantum device, the ibm-kyoto quantum computer. There, we tested our disambiguation approach on a subset of 4 random nouns (two ambiguous and two unambiguous) and observed that ibm-kyoto could achieve an accuracy range of 82.1 % to 98.9% in disambiguation tasks, extending the datasets and improving the results of existing ambiguity resolution experiments [1]. Our work demonstrates the capability of quantum computing in dealing with real-world NLP tasks, hence contributing to the advancement of both QML and NLP. © 2024 IEEE.},
	author_keywords = {Natural Language Processing; Semantics; Sentiment Analysis; Supervised Machine Learning},
	keywords = {Benchmarking; Natural language processing systems; Network security; Problem oriented languages; Python; Quantum electronics; Quantum entanglement; Self-supervised learning; Semi-supervised learning; Ambiguity resolution; Classification results; Classification tasks; Encoding algorithms; Language processing; Natural language processing; Natural languages; Quantum Computing; Sentiment analysis; Supervised machine learning; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Rani202513865,
	author = {Rani, Poonam and Verma, Om Prakash},
	title = {Modified-generative adversarial networks for imbalance text classification},
	year = {2025},
	journal = {Multimedia Tools and Applications},
	volume = {84},
	number = {14},
	pages = {13865 – 13884},
	doi = {10.1007/s11042-024-19528-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004051474&doi=10.1007%2fs11042-024-19528-7&partnerID=40&md5=bd7d5baf8f38470c6133f3f7dbe260fa},
	abstract = {Textual data faces a significant challenge known as class imbalance. This challenge arises when the distribution of classes within a dataset is highly disproportionate. To address this problem, effective algorithms that can handle the imbalance in the data while maintaining high predictive accuracy are needed. To solve the class imbalance problem, numerous methods have been proposed, which include SMOTE (Synthetic Minority Over Sampling), ADASYN (Adaptive Synthetic Sampling), ensemble methods, etc. In this paper we propose the novel Synthetic Minority Over Sampling Technique Nominal Continuous-Generative Adversarial Network (SMOTE NC-GAN) Model to tackle the problem of imbalanced text datasets. This method provides a novel solution for addressing the class imbalance problem. It involves generating synthetic data from the minority class of dataset using SMOTE-NC and subsequently applying that data along with real data fed to the Generative Adversarial Network. By using a combination of SMOTE-NC and GAN techniques, our proposed method can generate synthetic samples that enhance the quality of minority classes in the text datasets. Our proposed model addresses the limitations of both GAN and SMOTE. Empirical findings on various benchmark datasets have demonstrated the superior performance of the SMOTE NC-GAN Model over different state-of-the-art methods. This model enhances sample quality and offers computational efficiency, making it a promising solution for handling imbalanced datasets across various domains. The classification performance is significantly improved when utilizing the SMOTE NC-GAN Model in comparison to the Synthetic Minority Oversampling Technique. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Generative adversarial network; Natural language processing; Synthetic minority over sampling technique; Synthetic minority over sampling technique nominal continuous},
	keywords = {Benchmarking; Classification (of information); Computational efficiency; Learning algorithms; Natural language processing systems; Text processing; Class imbalance problems; Language processing; Natural language processing; Natural languages; Network models; Synthetic minority over sampling technique nominal continuous; Synthetic minority over-sampling techniques; Text classification; Textual data; Generative adversarial networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Li2024,
	author = {Li, Guangxi and Zhao, Xuanqiang and Wang, Xin},
	title = {Quantum self-attention neural networks for text classification},
	year = {2024},
	journal = {Science China Information Sciences},
	volume = {67},
	number = {4},
	doi = {10.1007/s11432-023-3879-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189461365&doi=10.1007%2fs11432-023-3879-7&partnerID=40&md5=81232672ba64cf33c0eb5fd714587662},
	abstract = {An emerging direction of quantum computing is to establish meaningful quantum applications in various fields of artificial intelligence, including natural language processing (NLP). Although some efforts based on syntactic analysis have opened the door to research in quantum NLP (QNLP), limitations such as heavy syntactic preprocessing and syntax-dependent network architecture make them impracticable on larger and real-world data sets. In this paper, we propose a new simple network architecture, called the quantum self-attention neural network (QSANN), which can compensate for these limitations. Specifically, we introduce the self-attention mechanism into quantum neural networks and then utilize a Gaussian projected quantum self-attention serving as a sensible quantum version of self-attention. As a result, QSANN is effective and scalable on larger data sets and has the desirable property of being implementable on near-term quantum devices. In particular, our QSANN outperforms the best existing QNLP model based on syntactic analysis as well as a simple classical self-attention neural network in numerical experiments of text classification tasks on public data sets. We further show that our method exhibits robustness to low-level quantum noises and showcases resilience to quantum neural network architectures. © Science China Press 2024.},
	author_keywords = {natural language processing; parameterized quantum circuits; quantum neural networks; self-attention; text classification},
	keywords = {Classification (of information); Natural language processing systems; Neural networks; Quantum computers; Quantum noise; Syntactics; Text processing; Timing circuits; Language processing; Natural language processing; Natural languages; Neural-networks; Parameterized; Parameterized quantum circuit; Quantum circuit; Quantum neural networks; Self-attention; Text classification; Network architecture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@CONFERENCE{Samuel2024,
	author = {Samuel, Christine Elizabeth and Srishti, Richa},
	title = {An Analysis of Grimms' Transmedia Storytelling in the Age of Technology},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204503489&doi=10.1109%2fTQCEBT59414.2024.10545037&partnerID=40&md5=cf17a45745973be136b45893d3b2adb1},
	abstract = {This research paper delves into an intersection of traditional literature and transmedia storytelling, with particular emphasis on Grimms' tales and its television series adaptation. Providing young audiences with engaging and dynamic experiences, transmedia storytelling involves delivering a single story across numerous platforms. Utilizing narrative analysis, this research seeks to uncover hidden themes, character growth, and story dynamics by breaking down the complex presentation and structure of stories in diverse media. Natural Language Processing (NLP) techniques like thematic analysis, sentiment analysis, keyword sentiment analysis have been employed to examine the differences between the presentation of these stories in varied formats as well as evaluating audience reception. It also assesses the degree to which transmedia adaptations support the resuscitation of beloved children's books in popular culture. By incorporating digital surrealism and aspects of technology, this paper enhances our understanding of how traditional stories captivate audiences across various media forms while maintaining their timeless quality.  © 2024 IEEE.},
	author_keywords = {children's literature; digital surrealism; narrative; NLP techniques; Transmedia storytelling},
	keywords = {Child literature; Digital surrealism; Language processing techniques; Narrative; Narrative analysis; Natural language processing technique; Natural languages; Research papers; Sentiment analysis; Transmedium storytelling; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Ramlakan2024277,
	author = {Ramlakan, Ashish Prithviraj and Gupta, Ruchi},
	title = {Quantum Marketing and Disruptive Technologies: Shaping Customer Purchase Intentions Through Social Media},
	year = {2024},
	journal = {Real-World Applications of Quantum Computers and Machine Intelligence},
	pages = {277 – 320},
	doi = {10.4018/979-8-3693-3601-4.ch021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007124931&doi=10.4018%2f979-8-3693-3601-4.ch021&partnerID=40&md5=400d8bcf81f5595d17cef6ecaca377f6},
	abstract = {Recent advancements in technologies such as quantum marketing, blockchain, Artificial Intelligence (AI), Virtual Reality (VR), and the Internet of Things (IoT) have fundamentally altered customer interactions, consequently influencing their purchasing decisions. The methodology employed encompasses a systematic literature review spanning peer reviewed journals and grey literature sources, including white papers, newspapers, blogs sites, and social media posts, covering the period from Januray 1, 2005, to December 31, 2023.Additionally, the study incorporates a sentiment analysis of Reddit posts drawn from a repository of 30,000 historical subreddits, aimed at evaluating consumer attitudes and behaviours towards purchasing.Through its findings, the study highlights the significant influence of consistent online community interaction on consumer behaviour, serving as a significant predictor of purchasing decisions. The study presents empirical evidence that positive language and digital marketing security fosters high levels of trust and positive sentiments online . © 2025 by IGI Global Scientific Publishing. All rights reserved.},
	keywords = {Consumer behavior; Emotion Recognition; Sales; Block-chain; Customers interactions; Disruptive technology; Grey literature; Journal literature; Purchase intention; Purchasing decisions; Social media; Systematic literature review; White papers; Tweets},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pasin2024205,
	author = {Pasin, Andrea and Cunha, Washington and Gonçalves, Marcos André and Ferro, Nicola},
	title = {A Quantum Annealing Instance Selection Approach for Efficient and Effective Transformer Fine-Tuning},
	year = {2024},
	journal = {ICTIR 2024 - Proceedings of the 2024 ACM SIGIR International Conference on the Theory of Information Retrieval},
	pages = {205 – 214},
	doi = {10.1145/3664190.3672515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202430713&doi=10.1145%2f3664190.3672515&partnerID=40&md5=965e8cb04ff6abccf83e84418cc02507},
	abstract = {Deep Learning approaches have become pervasive in recent years due to their ability to solve complex tasks. However, these models need huge datasets for proper training and good generalization. This translates into high training and fine-tuning time, even several days for the most complex models and large datasets. In this work, we present a novel quantum Instance Selection (IS) approach that allows to significantly reduce the size of the training datasets (by up to 28%) while maintaining the model's effectiveness, thus promoting (training) speedups and scalability. Our solution is innovative in the sense that it exploits a different computing paradigm - Quantum Annealing (QA) - a specific Quantum Computing paradigm that can be used to tackle optimization problems. To the best of our knowledge, there have been no prior attempts to tackle the IS problem using QA. Furthermore, we propose a new Quadratic Unconstrained Binary Optimization formulation specific for the IS problem, which is a contribution in itself. Through an extensive set of experiments with several Text Classification benchmarks, we empirically demonstrate our quantum solution's feasibility and competitiveness with the current state-of-the-art IS solutions. © 2024 Owner/Author.},
	author_keywords = {instance selection; quantum computing; text classification},
	keywords = {Benchmarking; Deep learning; Photons; Quantum efficiency; Quantum electronics; Quantum optics; Complex task; Computing paradigm; Fine tuning; Generalisation; Instance selection; Instance selection problem; Learning approach; Quantum annealing; Quantum Computing; Text classification; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Yu2024,
	author = {Yu, Wenbin and Yin, Lei and Zhang, Chengjun and Chen, Yadang and Liu, Alex X.},
	title = {Application of Quantum Recurrent Neural Network in Low-Resource Language Text Classification},
	year = {2024},
	journal = {IEEE Transactions on Quantum Engineering},
	volume = {5},
	doi = {10.1109/TQE.2024.3373903},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187407659&doi=10.1109%2fTQE.2024.3373903&partnerID=40&md5=9f8f2d5981c968f6aee6942f1b3579c8},
	abstract = {Text sentiment analysis is an important task in natural language processing and has always been a hot research topic. However, in low-resource regions such as South Asia, where languages like Bengali are widely used, the research interest is relatively low compared to high-resource regions due to limited computational resources, flexible word order, and high inflectional nature of the language. With the development of quantum technology, quantum machine learning models leverage the superposition property of qubits to enhance model expressiveness and achieve faster computation compared to classical systems. To promote the development of quantum machine learning in low-resource language domains, we propose a quantum-classical hybrid architecture. This architecture utilizes a pretrained multilingual bidirectional encoder representations from transformer (BERT) model to obtain vector representations of words and combines the proposed batch upload quantum recurrent neural network (BUQRNN) and parameter nonshared batch upload quantum recurrent neural network (PN-BUQRNN) as feature extraction models for sentiment analysis in Bengali. Our numerical results demonstrate that the proposed BUQRNN structure achieves a maximum accuracy improvement of 0.993% in Bengali text classification tasks while reducing average model complexity by 12%. The PN-BUQRNN structure surpasses the BUQRNN structure once again and outperforms classical architectures in certain tasks. © 2020 IEEE.},
	author_keywords = {Natural language processing (NLP); quantum machine learning; quantum recurrent neural network},
	keywords = {Classification (of information); Data mining; Learning algorithms; Learning systems; Network architecture; Sentiment analysis; Bengalis; Language processing; Low resource languages; Machine-learning; Natural language processing; Natural languages; Neural networks structure; Quantum machine learning; Quantum machines; Quantum recurrent neural network; Recurrent neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@CONFERENCE{Rengarajan2024,
	author = {Rengarajan, Aaditya and Senthilkumar, Lohith and Padmanabh, Neelesh and Ramalingam, Akhil},
	title = {SHADOW: A framework for Systematic Heuristic Analysis and Detection of Observations on the Web},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity, ICAMAC 2024},
	doi = {10.1109/ICAMAC62387.2024.10828750},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217360425&doi=10.1109%2fICAMAC62387.2024.10828750&partnerID=40&md5=21937818f6ea7b5787f675b926e5c3bf},
	abstract = {The cyberspace contains vast amounts of information that are crucial for cybersecurity professionals to gather threat intelligence, prevent cyberattacks, and secure organizational networks. Unlike earlier and less targeted attacks, modern cyber-attacks are more organized and sophisticated, often targeting specific groups, which leaves many users unaware of the vulnerable resources within the cyberspace. The increasing freedom on information access in the deep and dark web has led many organizations to identify their data loose on these spaces. Therefore, creating methods to crawl and extract valuable information from the deep web is a critical concern. Some deep web content can be accessed through the surface web by submitting query forms to retrieve the needed information, but it is not as simple in all cases. This paper proposes a system of framework to identify these leaks and notify relevant parties on the same in-time. © 2024 IEEE.},
	author_keywords = {Attack Tree; Blockchain; Cybersecurity; Data Breach; Named Entity Recognition; Ranking; Snowball Sampling; Wayback Machine; Web Scraping},
	keywords = {Information leakage; Phishing; Attack tree; Block-chain; Cyber security; Cyberspaces; Deep web; Named entity recognition; Ranking; Snowball sampling; Wayback machine; Web scrapings; Cyber attacks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Athira20252220,
	author = {Athira and Adith, M. and Gupta, Deepa},
	title = {Effective Complaint Detection in Financial Services through Complaint, Severity, Emotion and Sentiment Analysis},
	year = {2025},
	journal = {Procedia Computer Science},
	volume = {258},
	pages = {2220 – 2231},
	doi = {10.1016/j.procs.2025.04.472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007164034&doi=10.1016%2fj.procs.2025.04.472&partnerID=40&md5=b818b9caa7987a0937a3e0ade4b26f07},
	abstract = {Sentiment analysis plays a crucial role in understanding customer feedback and opinions within the financial domain. This research addresses the problem of sentiment-aware complaint identification using the FINancial Complaint CORpus (FINCORP) dataset, which provides annotated complaints along with sentiment, emotion and severity labels. The dataset encompasses various sentiment classes including Negative, Neutral, and Positive, enabling a wide understanding of customer sentiment towards financial products and services. Leveraging natural language processing (NLP) techniques such as text classification and sentiment analysis, this study aims to develop models capable of accurately detecting and categorizing sentiment, emotion of customers and the severity level of financial complaints. Effectively analyzing these factors allows financial institutions to gain valuable insights into customer satisfaction levels, pinpointing areas for improvement and enhance both customer experience and service quality. This research contributes to the advancement of sentiment analysis methodologies in the financial domain, facilitating better decision-making and customer relationship management strategies. DistilBERT, Glove and RoBERTa has outperformed in classifying the sentiment, emotion and severity of complaints, achieving F1-scores of 0.71, 0.74, and 0.86, respectively using logistic regression and Bi-LSTM classifiers. © 2024 The Authors. Published by ELSEVIER B.V.},
	author_keywords = {Deep Learning; Financial complaint detection; Machine Learning; Natural Language Processing; Sentiment Analysis; Word Embedding},
	keywords = {Customer satisfaction; Deep learning; Logistic regression; Public relations; Risk perception; Sales; Deep learning; Embeddings; Financial complaint detection; Financial service; Language processing; Machine-learning; Natural language processing; Natural languages; Sentiment analysis; Word embedding; Emotion Recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shahin2024,
	author = {Shahin, Nada and Ismail, Leila},
	title = {From rule-based models to deep learning transformers architectures for natural language processing and sign language translation systems: survey, taxonomy and performance evaluation},
	year = {2024},
	journal = {Artificial Intelligence Review},
	volume = {57},
	number = {10},
	doi = {10.1007/s10462-024-10895-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202745785&doi=10.1007%2fs10462-024-10895-z&partnerID=40&md5=5bd844c24f2188d6d124a2c7c49e823d},
	abstract = {With the growing Deaf and Hard of Hearing population worldwide and the persistent shortage of certified sign language interpreters, there is a pressing need for an efficient, signs-driven, integrated end-to-end translation system, from sign to gloss to text and vice-versa. There has been a wealth of research on machine translations and related reviews. However, there are few works on sign language machine translation considering the particularity of the language being continuous and dynamic. This paper aims to address this void, providing a retrospective analysis of the temporal evolution of sign language machine translation algorithms and a taxonomy of the Transformers architectures, the most used approach in language translation. We also present the requirements of a real-time Quality-of-Service sign language machine translation system underpinned by accurate deep learning algorithms. We propose future research directions for sign language translation systems. © The Author(s) 2024.},
	author_keywords = {Artificial intelligence; Deep learning; Natural language processing; Neural machine translation; Sign language translation; Transformers},
	keywords = {Adversarial machine learning; Computer aided language translation; Deep learning; Natural language processing systems; Neural machine translation; Deep learning; Language processing; Language translation; Machine translations; Natural language processing; Natural languages; Sign language; Sign language translation; Transformer; Translation systems; Distribution transformers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{Jayal2025425,
	author = {Jayal, Jyoti and Kumar, Vijay and Sarkar, Paramita and Dutta, Sudipta Kumar},
	title = {Emotion Detection Using Natural Language Processing by Text Classification},
	year = {2025},
	journal = {Natural Language Processing for Software Engineering},
	pages = {425 – 442},
	doi = {10.1002/9781394272464.ch28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217356398&doi=10.1002%2f9781394272464.ch28&partnerID=40&md5=a4c34689581f23abac09fb745276b8d3},
	abstract = {Emotion recognition is one of the branches within the field of emotion analysis. Advanced emotion analysis is required to identify a sentence as positive, negative, or neutral. Our emotions get more profound as we comprehend the positive or negative tone of the statements or ideas. People communicate their emotions using various methods, such as facial expressions, written language, verbal communication, and bodily movements. Opinions and perspectives form the foundation of individuals’ emotions, actions, and the impact of those emotions on their speech and actions. Linguistics and machine learning are broad areas that include subfields like computational linguistics, natural language processing (NLP), and artificial intelligence (AI). Thanks to Natural Language Processing (NLP), computers are now capable of comprehending, analyzing, and interpreting spoken language. Natural language processing (NLP) has become an essential component of our daily lives due to the widespread adoption of machine translation programs, voice assistants, and search engines. This article examines various machine learning and deep learning techniques to the task of emotion recognition through text classification utilizing natural language processing. © 2025 Scrivener Publishing LLC.},
	author_keywords = {deep learning; Emotion detection; ensemble learning; machine learning; natural language processing; text classification},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ni2024,
	author = {Ni, Yingying and Ni, Wei},
	title = {A multi-label text sentiment analysis model based on sentiment correlation modeling},
	year = {2024},
	journal = {Frontiers in Psychology},
	volume = {15},
	doi = {10.3389/fpsyg.2024.1490796},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214026442&doi=10.3389%2ffpsyg.2024.1490796&partnerID=40&md5=b9d9a99eb76bc47276a45e0277d51a3c},
	abstract = {Objective: This study proposes an emotion correlation-enhanced sentiment analysis model (ECO-SAM), a sentiment correlation modeling-based multi-label sentiment analysis model. Methods: The ECO-SAM utilizes a pre-trained BERT encoder to obtain semantic embedding of input texts and then leverages a self-attention mechanism to model the semantic correlation between emotions. Additionally, it utilizes a text emotion matching neural network to make sentiment analysis for input texts. Results: The experiment results in public datasets demonstrate that compared to baseline models, the ECO-SAM obtains the precision score increasing by 13.33% at most, the recall score increasing by 3.69% at most, and the F1 score increasing by 8.44% at most. Meanwhile, the modeled sentiment semantics are interpretable. Limitations: The data modeled by the ECO-SAM are limited to text-only modality, excluding multi-modal data that could enhance classification performance. Additionally, the training data are not large-scale, and there is a lack of high-quality large-scale training data for fine-tuning sentiment analysis models. Conclusion: The ECO-SAM is capable of effectively modeling sentiment semantics and achieving excellent classification performance in many public sentiment analysis datasets. Copyright © 2024 Ni and Ni.},
	author_keywords = {attention mechanism; emotion theory; natural language processing; sentiment analysis; text classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@BOOK{Saha2024155,
	author = {Saha, Soumitra and Lilhore, Umesh Kumar and Simaiya, Sarita},
	title = {An NLP approach to enrich biomedical research through sentiment analysis of patient feedback},
	year = {2024},
	journal = {Revolutionizing AI with Brain-Inspired Technology: Neuromorphic Computing},
	pages = {155 – 187},
	doi = {10.4018/979-8-3693-6303-4.ch007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000239430&doi=10.4018%2f979-8-3693-6303-4.ch007&partnerID=40&md5=e05ede05a27efbd0282cef4120c8b0ca},
	abstract = {This chapter consults the trajectory committed by utilizing patient feedback (PF) in the wake of biomedical research through sentimental analysis (SA) in natural language processing (NLP). PF has been compared to a gold mine for the healthcare industry as it delivers clinical efficacy and preserves quality. Analyzing these patient responses is vastly more time-consuming and subjective. SA employment can efficiently extract beneficial insights from this feedback by automating patients' positive, negative, or neutral sentiments. By systematically examining millions of remarks to identify familiar themes, distinct concerns, and patient satisfaction levels, researchers can employ these sentiments to understand disease status and assist in making intelligent decisions. SA can work with structured and unstructured sentiment data from mixed social media posts and electronic health records to produce favorable results, allowing researchers to improve biomedical research. Eventually, this chapter uncloses worthwhile wisdom to enrich biomedical research by employing PF through SA. © 2025 by IGI Global Scientific Publishing. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Singh2024,
	author = {Singh, Riya and Mahajan, Jayant and Jain, Prity and Saxena, Amit and Saxena, Anshul},
	title = {Analysing Collaborative Contributions and Sentiments in the Quantum Computing Ecosystem},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545251},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204452519&doi=10.1109%2fTQCEBT59414.2024.10545251&partnerID=40&md5=8848f9bba349f895dd080d3ce818b84c},
	abstract = {Quantum computing, a revolutionary paradigm leveraging the principles of quantum mechanics, has emerged as a transformative technology with the potential to solve complex problems at unparalleled speeds. Within the quantum computing ecosystem, companies and research institutes play pivotal roles in advancing hardware, algorithms, and applications. This research explores the transformative landscape of quantum computing, focusing on key contributors such as Google, IBM, D-Wave, Azure, Amazon, Intel, EeroQ, and IonQ. Through sentiment analysis, topic modelling, and thematic analysis, the study aims to comprehensively understand the current state and trends within the quantum computing ecosystem. The findings unveil an overall positive sentiment and identified topics ranging from cloud computing services to quantum computing advancements. Thematic analysis provides actionable insights, emphasizing collaboration within the ecosystem. Rooted in the analysis of secondary data from key companies' articles, the methodology establishes a robust framework for discerning contributions, collaborations, and strategic orientations in quantum computing.  © 2024 IEEE.},
	author_keywords = {Algorithms; Applications; Google; Hardware; IBM; Quantum computing; Transformative technology},
	keywords = {Quantum electronics; Complex problems; Computing ecosystems; Computing research; Google+; Hardware; IBM; Quantum Computing; Research institutes; Thematic analysis; Transformative technology; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{He2024139,
	author = {He, Junyuan and Kan, Yin and Xue, Cheng},
	title = {Training Quantum Self-Attention Model in Near-Term Quantum Computer},
	year = {2024},
	journal = {16th International Conference on Wireless Communications and Signal Processing, WCSP 2024},
	pages = {139 – 144},
	doi = {10.1109/WCSP62071.2024.10827420},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217534652&doi=10.1109%2fWCSP62071.2024.10827420&partnerID=40&md5=931f164c8b604f92423ba3b787f7cf59},
	abstract = {Quantum computing is rapidly emerging as a revolutionary computing paradigm with significant development potential. Variational quantum algorithms, especially those employing variational quantum circuits, have demonstrated notable advantages in domains including finance, chemistry, and machine learning. However, the practical deployment of these algorithms on Noisy Intermediate-Scale Quantum (NISQ) devices faces challenges due to quantum noise, state collapse, and limited qubits numbers. The real-world performance of these algorithms remains largely unexplored. This paper addresses this gap by proposing and implementing a novel method for training quantum self-attention model for text classification directly on quantum computing chips. This initiative marks the first instance of employing such models on actual quantum hardware. Our approach optimizes quantum circuit designs to mitigate the impact of quantum noise and introduces parallel training strategies to enhance efficiency. Our experiments, conducted on the 'Wukong' superconducting 72-qubit quantum computer, demonstrate that our models can be effectively trained on real quantum hardware. The results from the actual quantum chips slightly outperformed those from simulators, confirming the practical feasibility of applying quantum self-attention model to natural language processing tasks. These results validate the effectiveness of our approach and provide valuable insights for the future deployment of quantum machine learning models.  © 2024 IEEE.},
	author_keywords = {near-term quantum computer; quantum computing; quantum machine learning},
	keywords = {Adversarial machine learning; Computer circuits; Integrated circuit design; Machine learning; Modeling languages; Natural language processing systems; Quantum efficiency; Quantum electronics; Quantum entanglement; Quantum optics; Variational techniques; Attention model; Computing paradigm; Development potential; Machine-learning; Near-term quantum computer; Quanta computers; Quantum algorithms; Quantum Computing; Quantum machine learning; Quantum machines; Qubits},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Poornima2025143,
	author = {Poornima, Galiveeti and Meenakshi and Jawarneh, Malik and Shobana, A. and Yuvaraj, K.P. and Pol, Urmila R. and Moharekar, Tejashree Tejpal},
	title = {Machine Learning for Sentiment Analysis Using Social Media Scrapped Data},
	year = {2025},
	journal = {Natural Language Processing for Software Engineering},
	pages = {143 – 154},
	doi = {10.1002/9781394272464.ch9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217340266&doi=10.1002%2f9781394272464.ch9&partnerID=40&md5=58c44b1223d55e03662fe5f8f9a2a7f5},
	abstract = {Social media encompasses a wide range of internet apps that enable users to share, find, and engage with material created by other users. The number of persons utilizing social media increases by up to 3.80 million on a daily basis. By the start of 2020, the number of internet users is projected to reach 1 billion. Social media is a significant catalyst for acquiring and disseminating information in several domains such as entertainment, commerce, science, politics, and crisis management. It enables users to publish and share a diverse range of media formats, including text, videos, pictures, and audio. By conducting data analysis on social media, a person can access a wide range of information, including trends, concerns, and key individuals. Sentiment Analysis (SA) aims to ascertain the emotional response of individuals towards a specific service, business, or product. Sentiment analysis utilizes a diverse range of approaches, strategies, and tools to identify and extract subjective information, such as views and attitudes, from a given language. Traditionally, SA has sought to assess any information that is accessible to the public on the Internet. When utilized in conjunction with theme analysis, sentiment analysis has the capability to accurately detect both positive and negative emotions. Deep Learning Techniques (DLTs) are valuable in Sentiment Analysis (SA) because they have the ability to teach both supervised and unsupervised categories. DLTs comprise several network types such as feature presentation, phrase modeling, text creation, word representation estimation, vector representation, and sentence classification. © 2025 Scrivener Publishing LLC.},
	author_keywords = {Accuracy; AdaBoost; CNN; deep learning social media scrapped data; Sentiment analysis; SVM; Twitter data},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Thota2025669,
	author = {Thota, Srirajarajeswari and Dash, Sandeep Kumar},
	title = {A Comparison of Traditional Natural Language Processing Methods for Emotion Recognition Using Quantum Computing},
	year = {2025},
	journal = {2nd International Conference on Machine Learning and Autonomous Systems, ICMLAS 2025 - Proceedings},
	pages = {669 – 673},
	doi = {10.1109/ICMLAS64557.2025.10968522},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004814715&doi=10.1109%2fICMLAS64557.2025.10968522&partnerID=40&md5=828d1f7e0109adb117f81b2856a2b43c},
	abstract = {Emotion Recognition plays an important role in recognizing human behavior. Human behavior may be represented in text, speech, and facial expressions. In traditional form, natural language processing known as NLP is used to extract features to evaluate emotions. With the evolution of Quantum Computing, Quantum Machine learning often called QML is one of the research areas used to evaluate emotions. This paper is designed to compare traditional ML models with QML models to analyze the sentiments and emotions of multimodal data. Here, NLP techniques are used for preprocessing. A hybrid model is built by combining NLP and QML. The preprocessed data are transmitted into quantum circuits for computation, and its results are compared with conventional machine learning models. This evaluation identifies QML as a promising future as it is useful for large and complex data sets with high dimensions. This study highlights the potential of QML in NLP and outlines the challenges such as encoding and hardware limitations.  © 2025 IEEE.},
	author_keywords = {machine learning; Natural language processing; quantum computing; quantum machine learning},
	keywords = {Chatbots; Emotion recognition; Human behaviors; Language processing; Machine-learning; Natural language processing; Natural languages; Quantum Computing; Quantum machine learning; Quantum machines; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ouamane2024214,
	author = {Ouamane, Nour El Houda and Belhadef, Hacene},
	title = {Proposed Model for QCNN-Based Sentimental Short Sentences Classification},
	year = {2024},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {211},
	pages = {214 – 223},
	doi = {10.1007/978-3-031-59707-7_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194518053&doi=10.1007%2f978-3-031-59707-7_19&partnerID=40&md5=44d4a252bb830efe94b7af431024f2b1},
	abstract = {As social networking continues to expand, web users have been sharing their thoughts and viewpoints daily, utilizing various mediums such as texts, images, videos, and speech. However, despite this active participation, text classification remains a crucial challenge due to the sheer volume of texts received from diverse sources and individuals with different mindsets. The shared opinions often prove to be incomplete, inconsistent, and noisy, further complicated by variations in languages. To address these challenges, NLP (Natural Language Processing) and Quantum Machine Learning (QML) methods have become widely employed. This study focuses on exploring the potential of current quantum computers in enhancing the performance of natural language processing tasks. Specifically, we propose a new approach called the Quantum Convolutional Neural Network (QCNN) for sentiment analysis. Our proposed model is the first model based on QCNN at text classification field; it leverages QCNN to extract more effective features from short sentences; Thereby, improving sentiment analysis accuracy and efficiency. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Natural Language Processing; Quantum Convolutional Neural Network; Quantum Machine Learning; Sentiment Analysis},
	keywords = {Classification (of information); Convolution; Convolutional neural networks; Machine learning; Quantum computers; Convolutional neural network; Language processing; Machine-learning; Natural language processing; Natural languages; Quantum convolutional neural network; Quantum machine learning; Quantum machines; Sentiment analysis; Text classification; Sentiment analysis},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xu202418020,
	author = {Xu, Wenduan and Clark, Stephen and Brown, Douglas and Matos, Gabriel and Meichanetzidis, Konstantinos},
	title = {Quantum Recurrent Architectures for Text Classification},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {18020 – 18027},
	doi = {10.18653/v1/2024.emnlp-main.1000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213902088&doi=10.18653%2fv1%2f2024.emnlp-main.1000&partnerID=40&md5=af57fa288e3a481fd5a46b25b1adec79},
	abstract = {We develop quantum RNNs with cells based on Parametrised Quantum Circuits (PQCs). PQCs can provide a form of hybrid quantum-classical computation where the input and the output is in the form of classical data. The previous “hidden” state is the quantum state from the previous time-step, and an angle encoding is used to define a (non-linear) mapping from a classical word embedding into the quantum Hilbert space. Measurements of the quantum state provide classical statistics which are used for classification. We report results which are competitive with various RNN baselines on the Rotten Tomatoes dataset, as well as emulator results which demonstrate the feasibility of running such models on quantum hardware. © 2024 Association for Computational Linguistics.},
	keywords = {Quantum computers; Quantum electronics; Quantum optics; Vector spaces; Cell-based; Embeddings; Encodings; Hidden state; Nonlinear mappings; Quantum circuit; Quantum state; Quantum-classical; Text classification; Time step; Hilbert spaces},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Karthik2024224,
	author = {Karthik, Durga and Natarajan, Rajeswari and Bhavani, R. and Rajalakshmi, D.},
	title = {Cloud-based offensive code mixed text classification using hierarchical attention network},
	year = {2024},
	journal = {Advanced Applications in Osmotic Computing},
	pages = {224 – 237},
	doi = {10.4018/979-8-3693-1694-8.ch012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189236255&doi=10.4018%2f979-8-3693-1694-8.ch012&partnerID=40&md5=7ae5ae5eba3200c80faeb522571834c2},
	abstract = {The use of mixed language in social media has increased and the need of the hour is to detect abusive and offensive content. Hierarchical attention network (HAN) is employedfor classifying offensive content both at word and sentence level. Data from Thinkspeak cloud tweets containing annotated Tamil and English text is used as a training set for the HAN model. The attention mechanism captures the significance from both word and sentence levels. Cross-entropy loss function and backpropagation algorithm in the model classify offensive code-mixed text with an accuracy of 0.58. The above model can be employed for classifying other mixed language text too. © 2024, IGI Global. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zaman-Khan20242279,
	author = {Zaman-Khan, Haider and Naeem, Muddasar and Guarasci, Raffaele and Bint-Khalid, Umamah and Esposito, Massimo and Gargiulo, Francesco},
	title = {Enhancing Text Classification Using BERT: A Transfer Learning Approach},
	year = {2024},
	journal = {Computacion y Sistemas},
	volume = {28},
	number = {4},
	pages = {2279 – 2295},
	doi = {10.13053/CyS-28-4-5290},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213865027&doi=10.13053%2fCyS-28-4-5290&partnerID=40&md5=5dddee6a6f6cfb8a3f9653c1d6746434},
	abstract = {This paper investigates the application of Natural Language Processing (NLP) techniques for enhancing the performance of document-level classification tasks. The study focuses on leveraging a Transformer-based Neural Language Model (NLM), particularly BERT, combined with cross-validation to exploit transfer learning algorithms for classification tasks. To address the challenges, the approach has been tested on the two different types of the widely-known 20 Newsgroups benchmark dataset using pre-trained BERT models refined through cross-validation, resulting in notable accuracy rates of 92.29% for the pre-processed dataset without noise and 90.08% for the raw filtered dataset. These encouraging results confirm the effectiveness of combining transfer learning, cross-validation, and NLMs in NLP, with a particular focus on the state-of-the-art performance achieved by pre-trained BERT models in real-world text classification tasks. © 2024 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {BERT; NLMs; text classification; transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wulff2024,
	author = {Wulff, Eric and Garcia Amboage, Juan Pablo and Aach, Marcel and Gislason, Thorsteinn Eli and Ingolfsson, Thorsteinn Kristinn and Ingolfsson, Tomas Kristinn and Pasetto, Edoardo and Delilbasic, Amer and Riedel, Morris and Sarma, Rakesh and Girone, Maria and Lintermann, Andreas},
	title = {Distributed hybrid quantum-classical performance prediction for hyperparameter optimization},
	year = {2024},
	journal = {Quantum Machine Intelligence},
	volume = {6},
	number = {2},
	doi = {10.1007/s42484-024-00198-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203866977&doi=10.1007%2fs42484-024-00198-5&partnerID=40&md5=cd0ac038173e6e55efd5dd36bc0db07f},
	abstract = {Hyperparameter optimization (HPO) of neural networks is a computationally expensive procedure, which requires a large number of different model configurations to be trained. To reduce such costs, this work presents a distributed, hybrid workflow, that runs the training of the neural networks on multiple graphics processing units (GPUs) on a classical supercomputer, while predicting the configurations’ performance with quantum-trained support vector regression (QT-SVR) on a quantum annealer (QA). The workflow is shown to run on up to 50 GPUs and a QA at the same time, completely automating the communication between the classical and the quantum systems. The approach is evaluated extensively on several benchmarking datasets from the computer vision (CV), high-energy physics (HEP), and natural language processing (NLP) domains. Empirical results show that resource costs for performing HPO can be reduced by up to 9% when using the hybrid workflow with performance prediction, compared to using a plain HPO algorithm without performance prediction. Additionally, the workflow obtains similar and in some cases even better accuracy of the final hyperparameter configuration, when combining multiple heuristically obtained predictions from the QA, compared to using just a single classically obtained prediction. The results highlight the potential of hybrid quantum-classical machine learning algorithms. The workflow code is made available open-source to foster adoption in the community. © The Author(s) 2024.},
	author_keywords = {Distributed computing; Hyperband; Hyperparameter optimization; Quantum annealing},
	keywords = {Benchmarking; Photons; Problem oriented languages; Quantum computers; Quantum electronics; Supercomputers; Support vector regression; Graphics processing; Hyper-parameter optimizations; Hyperband; Model configuration; Neural-networks; Performance prediction; Processing units; Quantum annealing; Quantum-classical; Work-flows; Graphics processing unit},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Chen2025,
	author = {Chen, Yixiong and Fang, Weichuan},
	title = {Multi-scale feature fusion quantum depthwise Convolutional Neural Networks for text classification},
	year = {2025},
	journal = {Engineering Analysis with Boundary Elements},
	volume = {174},
	doi = {10.1016/j.enganabound.2025.106158},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217936859&doi=10.1016%2fj.enganabound.2025.106158&partnerID=40&md5=4beafc7d8b468c485071232e7e3fe852},
	abstract = {In recent years, with the development of quantum machine learning, Quantum Neural Networks (QNNs) have gained increasing attention in the field of Natural Language Processing (NLP) and have achieved a series of promising results. However, most existing QNN models focus on the architectures of Quantum Recurrent Neural Network (QRNN) and Quantum Self-Attention Mechanism (QSAM). In this work, we propose a novel QNN model based on quantum convolution. We develop the quantum depthwise convolution that significantly reduces the number of parameters and lowers computational complexity. We also introduce the multi-scale feature fusion mechanism to enhance model performance by integrating word-level and sentence-level features. Additionally, we propose the quantum word embedding and quantum sentence embedding, which provide embedding vectors more efficiently. Through experiments on two benchmark text classification datasets, we demonstrate our model outperforms a wide range of state-of-the-art QNN models. Notably, our model achieves a new state-of-the-art test accuracy of 96.77% on the RP dataset. We also show the advantages of our quantum model over its classical counterparts in its ability to improve test accuracy using fewer parameters. Finally, an ablation test confirms the effectiveness of the multi-scale feature fusion mechanism and quantum depthwise convolution in enhancing model performance. © 2025 The Authors},
	author_keywords = {Multi-scale feature fusion; Quantum depthwise convolution; Quantum embedding; Quantum Natural Language Processing; Quantum Neural Networks; Text classification},
	keywords = {Natural language processing systems; Network embeddings; Quantum electronics; Recurrent neural networks; Embeddings; Features fusions; Language processing; Multi-scale feature fusion; Multi-scale features; Natural languages; Quantum depthwise convolution; Quantum embedding; Quantum natural language processing; Quantum neural networks; Text classification; Convolutional neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Yang2024269,
	author = {Yang, Li and Charoenporn, Thatsanee and Sornlertlamvanich, Virach},
	title = {Comparative Study of Traditional Machine Learning and Quantum Computing in Natural Language Processing: A Case Study on Sentiment Analysis},
	year = {2024},
	journal = {Digest of Technical Papers - IEEE International Conference on Consumer Electronics},
	pages = {269 – 273},
	doi = {10.1109/ISCT62336.2024.10791272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215319919&doi=10.1109%2fISCT62336.2024.10791272&partnerID=40&md5=4252b72446079243fcecf7185e195313},
	abstract = {This research paper primarily investigates the application and performance of traditional machine learning and quantum computing in Natural Language Processing (NLP), with a focus on sentiment analysis tasks. By comparing the accuracy, efficiency, and scalability of these two technologies, the study aims to reveal the potential of quantum computing in handling complex NLP tasks and to provide data support for future technology choices and research directions. The paper also details the use of 1M DB and NLTK movie review datasets for experiments and discusses the experimental design, performance evaluation results, and technical challenges faced by both methods. © 2024 IEEE.},
	author_keywords = {Machine Learning; NLP; Performance Comparison; Quantum Computing; Sentiment Analysis},
	keywords = {Adversarial machine learning; Contrastive Learning; Machine learning; Natural language processing systems; Quantum efficiency; Quantum electronics; Case-studies; Comparatives studies; Language processing; Machine-learning; Natural language processing; Natural languages; Performance comparison; Quantum Computing; Research papers; Sentiment analysis; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sundaram2024,
	author = {Sundaram, Aishwarya and Subramaniam, Hema and Ab Hamid, Siti Hafizah and Nor, Azmawaty Mohamad},
	title = {A Three-Step Procedural Paradigm for Domain-Specific Social Media Slang Analytics},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204496218&doi=10.1109%2fTQCEBT59414.2024.10545286&partnerID=40&md5=0b0e06f71a802ce0a05abf7e7ee6e529},
	abstract = {Social media is a crucial aspect of modern society, shaping global communication and information exchange. Social media slang encompasses informal language expressions, abbreviations, and unconventional words on these platforms, serving purposes such as concise communication and identity establishment. Data analytics from social media slang plays a vital role in providing real-time trends, enhancing sentiment analysis, and improving the accuracy of predictive models by capturing evolving linguistic trends. This study aims to address gaps in existing social media slang analytics by proposing a three-step process for extracting and validating domain-specific social media slang terms, specifically focusing on the domain of anxiety prediction in the context of mental health. The proposed approach involves the identification of relevant users, extraction of social media slang terms, and validation by subject matter experts. A pilot study is conducted in the domain of anxiety prediction, employing a self-prepared questionnaire and involving participants aged 13-14 from schools in Selangor, Malaysia. The pilot study identifies ten social media slang terms associated with anxiety, validated by subject matter experts who are licensed mental health practitioners. The slang terms exhibit varying prevalence levels among adolescents, with some terms absent from popular slang dictionaries like Urban Dictionary. The findings highlight the need for extracting slang terms from pertinent users and subject matter expert validation in incorporating social media slang into more appropriate predictive analytics.  © 2024 IEEE.},
	author_keywords = {Anxiety prediction; data extraction; mental health; slang analytics; social media},
	keywords = {Sentiment analysis; Anxiety prediction; Data extraction; Domain specific; Global communication; Global informations; Mental health; Pilot studies; Slang analytic; Social media; Subject matter experts; Data Analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {29th International Conference on Information and Software Technologies, ICIST 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {1979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182551109&partnerID=40&md5=4eefff15d9843f515d3e73a2be25eb7d},
	abstract = {The proceedings contain 27 papers. The special focus in this conference is on Information and Software Technologies. The topics include: Access Control Approach for Controller Management Platforms; Leveraging Semantic Search and LLMs for Domain-Adaptive Information Retrieval; synergizing Reinforcement Learning for Cognitive Medical Decision-Making in Sepsis Detection; towards Data Integration for Hybrid Energy System Decision-Making Processes: Challenges and Architecture; modelling Normative Financial Processes with Process Mining; sentiment Analysis of Lithuanian Youth Subcultures Zines Using Automatic Machine Translation; chatbots Scenarios for Education; understanding User Perspectives on an Educational Game for Civic and Social Inclusion; using Quantum Natural Language Processing for Sentiment Classification and Next-Word Prediction in Sentences Without Fixed Syntactic Structure; Investigation of the Statistical Properties of the CTR Mode of the Block Cipher Based on MPF; analyzing the Impact of Principal Component Analysis on k-Nearest Neighbors and Naive Bayes Classification Algorithms; Comparison of kNN Classifier and Simple Neural Network in Handwritten Digit Recognition Using MNIST Database; comparison of Support Vector Machine, Naive Bayes, and K-Nearest Neighbors Algorithms for Classifying Heart Disease; Iterative Method of Adjusting Parameters in kNN via Minkowski Metric; predicting Diabetes Risk in Correlation with Cigarette Smoking; soft Inference as a Voting Mechanism in k-Nearest Neighbors Clustering Algorithm; The BLDC Motor Efficiency Improvement by Electronical Correction of the Power States Indications; The Impact of Entropy Weighting Technique on MCDM-Based Rankings on Patients Using Ambiguous medical Data; Online PID Tuning of a 3-DoF Robotic Arm Using a Metaheuristic Optimisation Algorithm: A Comparative Analysis; android Malware Detection Using Artificial Intelligence; autoencoder as Feature Extraction Technique for Financial Distress Classification.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wilson2024,
	author = {Wilson, Ezhilan and Saxena, Anshul and Mahajan, Jayant and Panikulangara, Lekha and Kulkarni, Shruti and Jain, Pritty},
	title = {FIN2SUM: Advancing AI-Driven Financial Text Summarization with LLMs},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204440160&doi=10.1109%2fTQCEBT59414.2024.10545078&partnerID=40&md5=f7bdb4c23c107b234716032698ba7576},
	abstract = {In the modern financial sector, the rapid digitalization of financial reports necessitates efficient and reliable text summarization tools. This research introduces FIN2SUM, a novel framework designed for summarizing the managerial analysis and discussion sections of 10-K reports from top NASDAQ-listed companies. The study aims to evaluate Large Language Models (LLMs) in financial text summarization, highlighting LLAMA-2's adeptness in processing complex financial information, thus making FIN2SUM a vital tool for analysts and decision-makers. The methodology includes a thorough evaluation of three state-of-the-art LLMs - LLAMA-2, FLAN, and Claude 2 - using BERT and ROUGE scores. The research concludes that FIN2SUM, enhanced by LLAMA-2, significantly advances AI-driven financial text summarization.  © 2024 IEEE.},
	author_keywords = {10-K Reports Summarization; AI in Financial Analysis; AI-Driven Decision Making; BERT and ROUGE Metrics; FIN2SUM Framework; Financial Data Processing; Financial Reporting Automation; Financial Text Summarization; Large Language Models (LLMs); LLAMA-2 and Financial Data; Semantic Similarity Analysis},
	keywords = {Finance; Financial data processing; Metadata; Modeling languages; Network security; Semantics; 10-K report summarization; AI in financial analyze; AI-driven decision making; BERT and ROUGE metric; Decisions makings; FIN2SUM framework; Financial analysis; Financial data; Financial reporting; Financial reporting automation; Financial text summarization; Language model; Large language model; LLAMA-2 and financial data; Semantic similarity; Semantic similarity analyze; Similarity analysis; Text Summarisation; Decentralized finance},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ardeshir-Larijani2024,
	author = {Ardeshir-Larijani, Ebrahim and Nasiri Fatmehsari, Mohammad Mahdi},
	title = {Hybrid classical-quantum transfer learning for text classification},
	year = {2024},
	journal = {Quantum Machine Intelligence},
	volume = {6},
	number = {1},
	doi = {10.1007/s42484-024-00147-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187935424&doi=10.1007%2fs42484-024-00147-2&partnerID=40&md5=0db2295932066e12e82f2cbcd4167290},
	abstract = {Quantum machine learning (QML) is a promising field that combines the power of quantum computing with machine learning. Variational quantum circuits, where parameters of circuits are learned classically, have been widely used in many recent applications of QML. This is an instance of a hybrid quantum-classical framework, where both classical and quantum components are present. However, applying these techniques to applications involving massive data is a challenging task. One way to overcome this, is using the concept of classical-quantum transfer learning with the help of a dressed quantum circuit, introduced recently, where the underlying neural architecture is pre-trained classically, but at the final steps (decision layer), a quantum circuit is used, followed by quantum measurements and post-processing to classify images with high precision. In this paper, we applied hybrid classical-quantum transfer learning to another task of massive data processing, i.e., natural language processing (NLP). We show how to (binary) classify short texts (e.g., SMS) with classical-quantum transfer learning, which was originally applied to image processing only. Our quantum network uses pre-trained Bidirectional Encoder Representations from the Transformers (BERT) model, and its variational quantum circuit is fine-tuned for text processing. We evaluated the performance of our hybrid neural architecture using the receiver operating characteristic (ROC) curve, which is typically used in the evaluation of classification problems. The results indicate high precision as well as lower loss function. To our knowledge, our work is the first application of quantum transfer learning to the area of NLP. Finally, a comparison with a tool that uses learning but in a different way than transfer learning is presented. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {Natural language processing; Quantum machine learning; Variational quantum computing},
	keywords = {Classification (of information); Data handling; Image processing; Machine learning; Metadata; Natural language processing systems; Network architecture; Quantum computers; Text processing; Classical-quantum; Language processing; Machine-learning; Natural language processing; Natural languages; Quantum Computing; Quantum machine learning; Quantum machines; Transfer learning; Variational quantum computing; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Badri2024,
	author = {Badri, Nabil and Kboubi, Ferihane and Habacha Chaibi, Anja},
	title = {Abusive and Hate speech Classification in Arabic Text Using Pre-trained Language Models and Data Augmentation},
	year = {2024},
	journal = {ACM Transactions on Asian and Low-Resource Language Information Processing},
	volume = {23},
	number = {11},
	doi = {10.1145/3679049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209767527&doi=10.1145%2f3679049&partnerID=40&md5=8f3afa9e3fe26fc022affba4f3950e81},
	abstract = {Hateful content on social media is a worldwide problem that adversely affects not just the targeted individuals but also anyone whose content is accessible. The majority of studies that looked at the automatic identification of inappropriate content addressed the English language, given the availability of resources. Therefore, there are still a number of low-resource languages that need more attention from the community. This article focuses on the Arabic dialect, which has several specificities that make the use of non-Arabic models inappropriate. Our hypothesis is that leveraging pre-trained language models (PLMs) specifically designed for Arabic, along with data augmentation techniques, can significantly enhance the detection of hate speech in Arabic mono- and multi-dialect texts. To test this hypothesis, we conducted a series of experiments addressing three key research questions: (RQ1) Does text augmentation enhance the final results compared to using an unaugmented dataset? (RQ2) Do Arabic PLMs outperform other models utilizing techniques such as fastText and AraVec word embeddings? (RQ3) Does training and fine-tuning models on a multilingual dataset yield better results than training them on a monolingual dataset? Our methodology involved the comparison of PLMs based on transfer learning, specifically examining the performance of DziriBERT, AraBERT v2, and BERT-base-arabic models. We implemented text augmentation techniques and evaluated their impact on model performance. The tools used included fastText and AraVec for word embeddings, as well as various PLMs for transfer learning. The results demonstrate a notable improvement in classification accuracy, with augmented datasets showing an increase in performance metrics (accuracy, precision, recall, and F1-score) by up to 15-21% compared to non-augmented datasets. This underscores the potential of data augmentation in enhancing the models' ability to generalize across the nuanced spectrum of Arabic dialects. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {AraBERT v2; Arabic mono/multi-dialect NLP; BERT-base-arabic; data augmentation; DziriBERT; hate speech detection; Natural Language Processing (NLP); Pre-trained Language Models (PLMs); text classification; transfer learning},
	keywords = {Data assimilation; Embeddings; Linguistics; Natural language processing systems; Network security; Speech enhancement; Speech recognition; AraBERT v2; Arabic mono/multi-dialect natural language processing; BERT-base-arabic; Data augmentation; DziriBERT; Hate speech detection; Language model; Language processing; Natural language processing; Natural languages; Pre-trained language model; Speech detection; Text classification; Transfer learning; Transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Shi20245973,
	author = {Shi, Jinjing and Chen, Tian and Lai, Wei and Zhang, Shichao and Li, Xuelong},
	title = {Pretrained Quantum-Inspired Deep Neural Network for Natural Language Processing},
	year = {2024},
	journal = {IEEE Transactions on Cybernetics},
	volume = {54},
	number = {10},
	pages = {5973 – 5985},
	doi = {10.1109/TCYB.2024.3398692},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194833525&doi=10.1109%2fTCYB.2024.3398692&partnerID=40&md5=85c6fb05e8f73a481954c683835c4efb},
	abstract = {Natural language processing (NLP) may face the inexplicable 'black-box' problem of parameters and unreasonable modeling for lack of embedding of some characteristics of natural language, while the quantum-inspired models based on quantum theory may provide a potential solution. However, the essential prior knowledge and pretrained text features are often ignored at the early stage of the development of quantum-inspired models. To attacking the above challenges, a pretrained quantum-inspired deep neural network is proposed in this work, which is constructed based on quantum theory for carrying out strong performance and great interpretability in related NLP fields. Concretely, a quantum-inspired pretrained feature embedding (QPFE) method is first developed to model superposition states for words to embed more textual features. Then, a QPFE-ERNIE model is designed by merging the semantic features learned from the prevalent pretrained model ERNIE, which is verified with two NLP downstream tasks: 1) sentiment classification and 2) word sense disambiguation (WSD). In addition, schematic quantum circuit diagrams are provided, which has potential impetus for the future realization of quantum NLP with quantum device. Finally, the experiment results demonstrate QPFE-ERNIE is significantly better for sentiment classification than gated recurrent unit (GRU), BiLSTM, and TextCNN on five datasets in all metrics and achieves better results than ERNIE in accuracy, F1-score, and precision on two datasets (CR and SST), and it also has advantage for WSD over the classical models, including BERT (improves F1-score by 5.2 on average) and ERNIE (improves F1-score by 4.2 on average) and improves the F1-score by 8.7 on average compared with a previous quantum-inspired model QWSD. QPFE-ERNIE provides a novel pretrained quantum-inspired model for solving NLP problems, and it lays a foundation for exploring more quantum-inspired models in the future.  © 2024 The Authors. This work is licensed under a Creative Commons Attribution 4.0 License.},
	author_keywords = {Natural language processing (NLP); neural networks; quantum language model; quantum machine learning; quantum-inspired neural network; sentiment classification; word sense disambiguation (WSD)},
	keywords = {Computer circuits; Deep neural networks; Integrated circuits; Modeling languages; Semantics; Timing circuits; Integrated circuit modeling; Language model; Language processing; Machine-learning; Natural language processing; Natural languages; Neural-networks; Quantum inspired neural networks; Quantum language model; Quantum machine learning; Quantum machines; Quantum state; Sentiment classification; Task analysis; Word sense disambiguation; article; benchmarking; deep neural network; human; natural language processing; quantum theory; respiratory gas humidifier; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Saini2024,
	author = {Saini, Jatinderkumar R. and Roy, Saikat},
	title = {Preparation of Rich Lists of Research Gaps in the Specific Sentiment Analysis Tasks of Code-mixed Indian Languages},
	year = {2024},
	journal = {SN Computer Science},
	volume = {5},
	number = {1},
	doi = {10.1007/s42979-023-02408-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180231094&doi=10.1007%2fs42979-023-02408-6&partnerID=40&md5=d2cde835fa6ad00677cc85be78f23d93},
	abstract = {Sentiment Analysis (SA) task for code-mixed Romanized text is an emerging area of research in Natural Language Processing (NLP). Since informal expression of sentiments in Romanized code-mixed Indian Languages (ILs) with emojis and/or emoticons is very common in social media, SA tasks for code-mixed posts/comments on ILs are being paid much attention by researchers. In the present survey, we have studied the evolution of language models over time, dataset details, research gaps, challenges towards building advanced models, possible recommendations to overcome those challenges, and determining the best-performing language models only for SA task on eight code-mixed ILs, namely Bengali–English, Hind–English, Kannada–English, Malayalam–English, Marathi–English, Punjabi–English, Telugu–English, and Tamil–English. Though many researchers have already explored the state-of-art text representation models for the SA task of resource-rich English language, contextual understanding and semantic feature extraction from non-standard code-mixed Romanized text of under-resourced ILs are yet to be explored to a large extent due to resource scarcity. We have focused on an exhaustive and comprehensive survey of very specific 70 research papers on SA tasks to list open research areas on code-mixed ILs. The present work will benefit researchers by providing a clear direction for future research scope in SA task in code-mixed IL pairs. © 2023, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Attention-based models; Deep learning-based model; Lexicon-based models; Machine learning (ML)},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zeguendry2024,
	author = {Zeguendry, Amine and Jarir, Zahi and Quafafou, Mohamed},
	title = {Quantum-Enhanced K-Nearest Neighbors for Text Classification: A Hybrid Approach with Unified Circuit and Reduced Quantum Gates},
	year = {2024},
	journal = {Advanced Quantum Technologies},
	volume = {7},
	number = {11},
	doi = {10.1002/qute.202400122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200152475&doi=10.1002%2fqute.202400122&partnerID=40&md5=8bd89091ad30d45e533f61c595b38c09},
	abstract = {Text classification, a key process in natural language processing (NLP), relies on the k-nearest neighbors (KNN) algorithm for its simplicity and effectiveness. Traditional methods often grapple with the high-dimensional nature of textual data, leading to substantial computational demands. This study introduces a novel classical quantum k-nearest neighbors (CQKNN) algorithm, which integrates quantum circuits into a conventional machine-learning framework to enhance computational efficiency and reduce storage requirements. This hybrid approach uses a unified quantum circuit that simplifies multiple similarity calculations through mid-circuit measurements and qubit reset operations, significantly improving upon traditional multi-circuit quantum k-nearest neighbors (QKNN) models. The CQKNN algorithm, tested on datasets such as SMS Spam Collection, Twitter US Airline Sentiment, and IMDB Movie Reviews, not only outperforms classical KNN but also addresses challenges posed by noisy intermediate-scale quantum (NISQ) devices through advanced error mitigation techniques. This work highlights resource efficiency and reduced gate complexity and demonstrates the practical application of fidelity in quantum similarity calculations, setting new standards for quantum-enhanced machine learning and advancing current quantum technology capabilities in complex data classification tasks. © 2024 Wiley-VCH GmbH.},
	author_keywords = {hybrid classical quantum k-nearest neighbors; quantum computing; quantum machine learning; qubit reuse; text classification},
	keywords = {Classification (of information); Computational efficiency; Digital storage; Learning algorithms; Motion compensation; Natural language processing systems; Nearest neighbor search; Quantum efficiency; Qubits; Text processing; Timing circuits; Classical-quantum; Hybrid classical quantum k-near neighbor; K Nearest Neighbor (k NN) algorithm; Machine-learning; Quantum Computing; Quantum machine learning; Quantum machines; Qubit reuse; Reuse; Text classification; Machine learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Saxena2025,
	author = {Saxena, Anshul and Rishi, Bikramjit},
	title = {Designing an artificial intelligence-enabled large language model for financial decisions},
	year = {2025},
	journal = {Management Decision},
	doi = {10.1108/MD-02-2024-0305},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216339102&doi=10.1108%2fMD-02-2024-0305&partnerID=40&md5=d612ef79f97e1f9611a0bb2ca6d15a18},
	abstract = {Purpose: Artificial intelligence (AI) has profoundly reshaped financial decision-making, introducing a paradigm shift in how institutions and individuals navigate the complex finance landscape. The study evaluates the significant impact of integrating advanced AI and large language models (LLMs) in financial decision analytics. Design/methodology/approach: The study offers FinSageNet, a novel framework designed and tested to harness the potential of LLMs in financial decisions. The framework excels in handling and analyzing large volumes of numerical and textual data through advanced data mining techniques. Findings: FinSageNet demonstrates exceptional text summarization capabilities, outperforming models like FLAN and GPT-3.5 in Rouge score metrics. The proposed model has shown more accuracy than generic models. Originality/value: The study emphasizes the significance of consistently updating models and adopting a comprehensive approach to integrating AI into financial decisions. This study improves our understanding of how artificial intelligence transforms financial analytics and decision-making processes. © 2025, Emerald Publishing Limited.},
	author_keywords = {Artificial intelligence; Financial analytics; Financial decision; FinSageNet; Large language models},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zhang2025293,
	author = {Zhang, Dan and Jia, Delong},
	title = {A disambiguation method for potential ambiguities in Chinese based on knowledge graphs and large language model},
	year = {2025},
	journal = {Alexandria Engineering Journal},
	volume = {126},
	pages = {293 – 302},
	doi = {10.1016/j.aej.2025.04.089},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003805759&doi=10.1016%2fj.aej.2025.04.089&partnerID=40&md5=3c778f840c3574b14ed3163710a04da8},
	abstract = {Traditional disambiguation methods struggle to effectively balance and integrate a wide range of contextual information and world knowledge when dealing with potential ambiguities in Chinese. To address this issue, this paper proposes a disambiguation model that integrates knowledge graphs and large language models (LLMs) to tackle lexical ambiguity in Chinese texts. This article uses an attention based disambiguation model, which is fine-tuned using multiple hyperparameter configurations. It optimizes network layers and knowledge graph embedding dimensions to enhance performance. Visualization of the attention mechanism reveals the model's focus on target words, context, and knowledge graph entities. Experiments conducted on a dataset comprising 200,000 sentences demonstrate significant improvements in accuracy and F1 scores, reaching 92.4 % and 91.9 %, respectively, compared to traditional statistical and deep learning models. Visualization of the attention mechanism reveals the model's focus on target words, context, and knowledge graph entities. The findings suggest that integrating knowledge graphs with LLMs offers an innovative approach to complex language tasks. In practical applications such as machine translation and chatbots, this model is expected to enhance both performance and interpretability. © 2025},
	author_keywords = {Chinese ambiguity; Disambiguation model; Knowledge graph; Large language model; Natural language processing},
	keywords = {Computer aided language translation; Context sensitive grammars; Deep learning; Knowledge graph; Modeling languages; Natural language processing systems; Chinese ambiguity; Disambiguation method; Disambiguation model; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Performance; Chatbots},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Srivastava2024,
	author = {Srivastava, Jyoti and Priyadarsini, Kirupa},
	title = {Uncovering User Attitudes and Satisfaction Levels with HRMS Applications: Insights from Sentiment Analysis},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204496712&doi=10.1109%2fTQCEBT59414.2024.10545119&partnerID=40&md5=08c5b1fe32e69717bafe04c0cf155992},
	abstract = {This study examines employee perspectives on various features and specifications of Human Resource Management System (HRMS) applications, as expressed in online discussion boards. An in-depth literature review was conducted to identify key factors, followed by topic modeling on unstructured text data. Sentiment analysis using the Li-Hu method and a tweet profile helped gauge employee satisfaction with HRMS applications. The findings suggest a moderate level of satisfaction among users, offering insights for companies to enhance user interfaces and software development. By addressing negative attitudes and fostering positive ones, businesses can cultivate better relationships with users. This research also aids in identifying top-performing HRMS applications in the market, highlighting the features and specifications that set them apart from competitors. Overall, the study serves as a valuable resource for organizations aiming to improve their HRMS offerings and user experiences.  © 2024 IEEE.},
	author_keywords = {Human Resource Management System (HRMS); NLP; NLTK; Sentiment analysis; User interface},
	keywords = {Application programs; Human resource management; Information management; Tweets; Discussion boards; Human resource management system; Human resource management systems; Literature reviews; NLTK; Online discussions; Sentiment analysis; System applications; User attitudes; Users' satisfactions; Resource allocation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bar2024,
	author = {Bar, Niyazi Furkan and Yenilmez, Musa and Aksu, Sedef and Karakose, Mehmet},
	title = {A Quantum Computing based Approach for Sentiment Analysis in Bilateral Conversations},
	year = {2024},
	journal = {2024 28th International Conference on Information Technology, IT 2024},
	doi = {10.1109/IT61232.2024.10475718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190407307&doi=10.1109%2fIT61232.2024.10475718&partnerID=40&md5=f450291f67b48485007b18a026a676b7},
	abstract = {Sentiment analysis finds widespread applications in health, marketing, finance, stock markets, media, and politics. To analyze attitudes and emotions in textual data, handling large datasets and significant computational power is essential. Traditional computing methods struggle with the growing data volume, prompting interest in quantum computing as a promising alternative with its inherent high-speed processing capacity. This study focuses on sentiment analysis applied to texts derived from bilateral conversation dialogues. The primary objective is to categorize emotions within the text as positive, neutral, or negative, while concurrently identifying the speaker. To achieve this, a novel quantum-classical hybrid approach is proposed. The quantum side of this approach includes the variational quantum circuit (VQC). On the classical side, preprocessing of the data set, feature extraction with a model containing LSTM, and optimizing the parameters of VQC are performed. The proposed approach was trained and tested using a data set containing bilateral conversations. As a result of the tests, the proposed approach achieved a higher accuracy rate compared to studies using the classical approach. Thus, the effectiveness of the proposed approach is confirmed.  © 2024 IEEE.},
	author_keywords = {deep learning; natural language processing; quantum computing; sentiment analysis},
	keywords = {Data handling; High speed cameras; Large datasets; Long short-term memory; Quantum computers; Data set; Deep learning; Language processing; Media and politics; Natural language processing; Natural languages; Quantum circuit; Quantum Computing; Sentiment analysis; Textual data; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@BOOK{More2024133,
	author = {More, Pratik and Pothula, Shiva Sai Kiran},
	title = {Quantum leap in customer persona development: Enhancing consumer profiles and experiences using quantum AI},
	year = {2024},
	journal = {The Quantum AI Era of Neuromarketing},
	pages = {133 – 156},
	doi = {10.4018/979-8-3693-7673-7.ch006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000270130&doi=10.4018%2f979-8-3693-7673-7.ch006&partnerID=40&md5=5fcfb5d0328a30afecae73472851e8bd},
	abstract = {Quantum Artificial Intelligence offers a new avenue in enhancing customer personas through the combination of quantum computing and AI to process large files in parallel computing. This chapter describes how QAI enables real-time updates of customer profiles in real synchrony with dynamic behaviors, preferences, and practices. Quantum machine learning enhances both sentiment analysis and predictive modeling with the help of natural language processing, which enables high personalized experiences for businesses. QAI's ability to analyse large volumes of data improves the strategies of marketing through better customer segmentation, improvement in the areas of recommendation engines, and accurate predictions about consumer behavior. This chapter showcases the transformative potential of QAI in empowering the task of real-time personalized data-d riven marketing and providing better relations with customers that drives the new age businesses. Integration of QAI in persona development will help companies achieve higher customer satisfaction and loyalty in the evolving digital marketplace. © 2025, IGI Global Scientific Publishing. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Roy2024,
	author = {Roy, Biswajit Nath and Maity, Soumik and Singh, Kabir Raj and Chowdhury, Pankaj and Das, Arijit and Saha, Diganta},
	title = {ECGText: Crafting Emotional Texts through GenAI},
	year = {2024},
	journal = {Intelligent Computing and Emerging Communication Technologies, ICEC 2024},
	doi = {10.1109/ICEC59683.2024.10837153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218038996&doi=10.1109%2fICEC59683.2024.10837153&partnerID=40&md5=4956cd0f31d98d36ca92958050595a6b},
	abstract = {The generation of emotionally nuanced text is a growing area of interest in AI, particularly in enhancing human-machine interaction. This paper presents ECGText (Emotionally Cognizant Generation of Text), a novel model that integrates emotional intelligence into GPT-based text generation. The motivation behind this study stems from the limitations of current text generation models, which lack the ability to generate emotionally resonant content. By incorporating sentiment analysis and emotion recognition into the text generation process, ECGText produces emotionally appropriate outputs, enhancing engagement and relatability. Through comprehensive experiments and evaluations using diverse datasets, results demonstrate that ECGText outperforms baseline models in generating sentiment-rich text while maintaining coherence and fluency. This study advances the field of AI-driven communication, bridging the gap between machine-generated text and human emotional expression.  © 2024 IEEE.},
	author_keywords = {ECGText; Enhancing GPT; Generative AI; Robot with Sentiment; Text Generation},
	keywords = {Adversarial machine learning; Human robot interaction; 'current; Area of interest; Emotional intelligence; Emotionally cognizant generation of text; Enhancing GPT; Generative AI; Human machine interaction; Robot with sentiment; Sentiment analysis; Text generations; Emotion Recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Gadhave2025233,
	author = {Gadhave, Rajashree and Chaudhari, Anita and Ramesh, B. and Raj, Vijilius Helena and Thethi, H. Pal and Ravitheja, A.},
	title = {An Investigation of Various Text Mining Techniques},
	year = {2025},
	journal = {Natural Language Processing for Software Engineering},
	pages = {233 – 243},
	doi = {10.1002/9781394272464.ch16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217356460&doi=10.1002%2f9781394272464.ch16&partnerID=40&md5=9b997dca3cb3cd89be30218fd7719156},
	abstract = {Text summaries are generated from huge quantities of unstructured text, such as customer evaluations, internet log entries, and social media postings, and are an important feature of text mining systems. These synopses emphasize the key data representing the whole text or judgment. There are two major approaches to completing a summary task: extractive and abstractive. The extractive approach identifies the meat of the document, which contains all of the information, and extracts it to make the summary. In comparison to the other method, the abstractive methodology is more difficult since it creates summaries based on the document’s keywords and semantics. The visually appealing summary job is challenging due to redundancy, a large text volume, unpredictability, and the semantics of natural language. Because of the task’s complexity and breadth of applicability, researchers from the academia and business have been working hard on it. This study focuses on two major areas of text mining: feature-based text summarization and text similarity detection, both of which use machine learning-based methods. © 2025 Scrivener Publishing LLC.},
	author_keywords = {classification; clustering; machine learning; text detection; Text mining; text summarization},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chaudhary202591,
	author = {Chaudhary, Varshit and Goel, Aarsh and Yusuf, Mohammad Zubair and Tiwari, Smita},
	title = {Disaster Tweets Classification Using Natural Language Processing},
	year = {2025},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1262},
	pages = {91 – 101},
	doi = {10.1007/978-981-96-1981-8_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005253299&doi=10.1007%2f978-981-96-1981-8_8&partnerID=40&md5=cecd4a031c7d8b587f855508e197b3da},
	abstract = {Tweets provide real-time insights and sentiment from a diverse range of sources, offering data for understanding public opinion, emergencies, and trends. This research focuses on the applications of the Natural Language Processing (NLP) techniques for disaster related tweets. Data preprocessing is performed with the help of NLP techniques such as Bag-of-words (BoW) and term frequency-inverse document frequency (TF-IDF) approaches are used for feature extraction. This paper highlights the elements for creating a model using traditional algorithms, including Logistic Regression, Random Forest Classifier and Support Vector Classifier, were used to classify tweets into disaster and non-disaster categories which resulted in a accuracy of 82%. To further improve the accuracy of our model, we implemented modern algorithms, such as Extreme Gradient Boosting (Xgboost), a Recurrent Neural Network (RNN) model with Long Short-term Memory (LSTM) and a LSTM model was implemented, demonstrated an accuracy of 96.32%. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Bag-of-words (BoW); Disaster; Long short-term memory (LSTM); Machine learning; Natural language processing (NLP); Tweet classification},
	keywords = {Chatbots; Data reduction; Question answering; Sorting; Bag of words; Bag-of-word; Language processing; Language processing techniques; Long short-term memory; Machine-learning; Natural language processing; Natural languages; Short term memory; Tweet classification; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vega2024,
	author = {Vega, Ines and Valencia, Jose and Arcos, Angel and Navarrete, Danny and Baldeon-Calisto, Maria},
	title = {A Comparison Between Transformers and Foundation Models in Sentiment Analysis of Student Evaluation of Teaching},
	year = {2024},
	journal = {12th International Symposium on Digital Forensics and Security, ISDFS 2024},
	doi = {10.1109/ISDFS60797.2024.10527264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194080122&doi=10.1109%2fISDFS60797.2024.10527264&partnerID=40&md5=0dd24206486eb67a0bd77ae554adfe59},
	abstract = {Student evaluation of teaching (SET) serves as a crucial tool for improving educational quality, enabling students to articulate their opinions about instructors. However, manually evaluating student feedback is time-consuming, subjective, and prone to error. Sentiment analysis, which automatically classifies texts using computational algorithms, presents a promising alternative for this task. In this work, we conduct a comparative analysis of sentiment analysis on SET between three Transformer networks and three Foundation models on a dataset from an Ecuadorian university. Our experiments demonstrate that Transformer models trained on the dataset of interest have a better overall performance than general-purpose Foundation models. Furthermore, among the models examined, DistilBERT emerges as the top performer, achieving an accuracy of 84.90% and an F-1 score of 0.836. In comparison, among the Foundation models, Google Bard achieves the highest accuracy and F-1 score with 78.3% and 0.767, respectively. This work contributes valuable insights to the realm of higher education evaluation, showcasing the potential of advanced NLP techniques to expedite and enhance the SET process, ultimately paving the way for continuous improvement in educational settings.  © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; Foundation Models; Sentiment Analysis; Student Evaluation of Teaching; Transformers Models},
	keywords = {Education computing; Foundations; Quality control; Students; Comparative analyzes; Computational algorithm; Educational qualities; Foundation models; Performance; Sentiment analysis; Student evaluation of teaching; Student feedback; Students' evaluations; Transformer modeling; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Buonaiuto202425,
	author = {Buonaiuto, Giuseppe and Guarasci, Raffaele and Esposito, Massimo},
	title = {Quantum Transfer Learning for Sentiment Analysis: an experiment on an Italian corpus},
	year = {2024},
	journal = {QUASAR 2024 - Proceedings of the ACM Workshop on QUAntum Search and Information Retrieval, Part of: HPDC 2024 - 33rd International Symposium on High-Performance Parallel and Distributed Computing},
	pages = {25 – 30},
	doi = {10.1145/3660318.3660325},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204990522&doi=10.1145%2f3660318.3660325&partnerID=40&md5=ac549fe94304d0589c2c368221ea853d},
	abstract = {Exploiting quantum properties to improve performance of different tasks in Natural Language Processing (NLP) and other domains has increasingly becoming a successful trend to deal complex language phenomena or to fill task or domain-specific gaps with an approach that needs less data and minor computational resources. The field that has, to date, yielded more quantum-based attention is the retrieval and classification of textual data. This work aims to replicate the excellent results of hybrid quantum approaches for syntactic tasks on semantic classification tasks. In detail, a quantum machine learning algorithm, namely, the Variational Quantum Classifier (VQC), is used to perform sentiment analysis classification tasks. This algorithm can deduce the relationships between input features and their corresponding class affiliations using a parametrized quantum circuit and an encoding layer that translates classical data into quantum states. The approach has been tested on a well-known benchmark annotated dataset used for the Italian language, and the results have been compared to existing baselines, pointing out state-of-the-art scores. © 2024 Copyright is held by the owner/author(s).},
	author_keywords = {QNLP; quantum transfer learning; variational quantum classifier},
	keywords = {Adversarial machine learning; Contrastive Learning; Natural language processing systems; Network security; Quantum electronics; Syntactics; Transfer learning; Variational techniques; Classification tasks; Improve performance; Language processing; Natural languages; QNLP; Quantum properties; Quantum transfer learning; Sentiment analysis; Transfer learning; Variational quantum classifier; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Adab2024,
	author = {Adab, Aqsa and Jain, Muskan and Gunavathi, R. and Bhagat, Vandana and Hussain, Ashaq G and Johnson, Amala},
	title = {Food Recommendation System using Custom NER and Sentimental Analysis},
	year = {2024},
	journal = {TQCEBT 2024 - 2nd IEEE International Conference on Trends in Quantum Computing and Emerging Business Technologies 2024},
	doi = {10.1109/TQCEBT59414.2024.10545046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204474821&doi=10.1109%2fTQCEBT59414.2024.10545046&partnerID=40&md5=836d5a8c45968a0c5c6fbd6877bc2c03},
	abstract = {In today's fast-paced lifestyle, the need for efficient and personalized solutions is paramount, especially in the category of dining experiences. This research responds to this demand by proposing a better food recommendation system for Zomato reviews. It targets the audience who are not aware of the best cuisines and search for user reviews online. Utilizing custom Named Entity Recognition (NER) and sentiment analysis, the system seeks to understand and cater to individual food preferences extracted from user Reviews. Specifically, improving the analysis by extracting reviews for ten restaurants in the city of Kolkata. By providing a specific solution to address the current research gap in the area of restaurants recommendation systems, the system recommends top choices for neighboring restaurants and best food based on the sentimental analysis of the chosen menu items.  © 2024 IEEE.},
	author_keywords = {Food Recommendation System; Fuzzy Strings; Named Entity Recognition(NER); Pre-trained Roberta based NER model; Sentimental Analysis; TextBlob},
	keywords = {Food chemistry; Recommender systems; Dining experience; Food recommendation system; Fuzzy string; Named entity recognition; Pre-trained robertum based named entity recognition model; Recognition models; Sentimental analyze; Textblob; User reviews; Food ingredients},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cunha2025,
	author = {Cunha, Washington and Moreo Fernández, Alejandro and Esuli, Andrea and Sebastiani, Fabrizio and Rocha, Leonardo and Gonçalves, Marcos André},
	title = {A Noise-Oriented and Redundancy-Aware Instance Selection Framework},
	year = {2025},
	journal = {ACM Transactions on Information Systems},
	volume = {43},
	number = {2},
	doi = {10.1145/3705000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219752575&doi=10.1145%2f3705000&partnerID=40&md5=23b80053e976c743eecbf0eaf39429f6},
	abstract = {Fine-tuning transformer-based deep-learning models are currently at the forefront of natural language processing (NLP) and information retrieval (IR) tasks. However, fine-tuning these transformers for specific tasks, especially when dealing with ever-expanding volumes of data, constant retraining requirements, and budget constraints, can be computationally and financially costly, requiring substantial energy consumption and contributing to carbon dioxide emissions. This article focuses on advancing the state-of-the-art (SOTA) on instance selection (IS) - a range of document filtering techniques designed to select the most representative documents for the sake of training. The objective is to either maintain or enhance classification effectiveness while reducing the overall training (fine-tuning) total processing time. In our prior research, we introduced the E2SC framework, a redundancy-oriented IS method focused on transformers and large datasets - currently the state-of-the-art in IS. Nonetheless, important research questions remained unanswered in our previous work, mostly due to E2SC's sole emphasis on redundancy. In this article, we take our research a step further by proposing biO-IS - an extended bi-objective instance selection solution, a novel IS framework aimed at simultaneously removing redundant and noisy instances from the training. biO-IS estimates redundancy based on scalable, fast, and calibrated weak classifiers and captures noise with the support of a new entropy-based step. We also propose a novel iterative process to estimate near-optimum reduction rates for both steps. Our extended solution is able to reduce the training sets by 41% on average (up to 60%) while maintaining the effectiveness in all tested datasets, with speedup gains of 1.67 on average (up to 2.46x). No other baseline, not even our previous SOTA solution, was capable of achieving results with this level of quality, considering the tradeoff among training reduction, effectiveness, and speedup. To ensure reproducibility, our documentation, code, and datasets can be accessed on GitHub - https://github.com/waashk/bio-is.  © 2025 Copyright held by the owner/author(s).},
	author_keywords = {Document Filtering; Instance Selection; Transformer-Based Text Classification},
	keywords = {Deep learning; Distribution transformers; Large datasets; Metadata; Natural language processing systems; Network security; Redundancy; Search engines; Wiener filtering; Document filtering; Fine tuning; Instance selection; Language informations; Learning models; Natural languages; Selection framework; State of the art; Text classification; Transformer-based text classification; Budget control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Laakkonen2024162,
	author = {Laakkonen, Tuomas and Meichanetzidis, Konstantinos and Coecke, Bob},
	title = {Quantum Algorithms for Compositional Text Processing},
	year = {2024},
	journal = {Electronic Proceedings in Theoretical Computer Science, EPTCS},
	volume = {406},
	pages = {162 – 196},
	doi = {10.4204/EPTCS.406.8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202032230&doi=10.4204%2fEPTCS.406.8&partnerID=40&md5=32ca97f495922cce44405480f425b650},
	abstract = {Quantum computing and AI have found a fruitful intersection in the field of natural language processing. We focus on the recently proposed DisCoCirc framework for natural language, and propose a quantum adaptation, QDisCoCirc. This is motivated by a compositional approach to rendering AI interpretable: the behavior of the whole can be understood in terms of the behavior of parts, and the way they are put together. For the model-native primitive operation of text similarity, we derive quantum algorithms for fault-tolerant quantum computers to solve the task of question-answering within QDisCoCirc, and show that this is BQP-hard; note that we do not consider the complexity of question-answering in other natural language processing models. Assuming widely-held conjectures, implementing the proposed model classically would require super-polynomial resources. Therefore, it could provide a meaningful demonstration of the power of practical quantum processors. The model construction builds on previous work in compositional quantum natural language processing. Word embeddings are encoded as parameterized quantum circuits, and compositionality here means that the quantum circuits compose according to the linguistic structure of the text. We outline a method for evaluating the model on near-term quantum processors, and elsewhere we report on a recent implementation of this on quantum hardware. In addition, we adapt a quantum algorithm for the closest vector problem to obtain a Grover-like speedup in the fault-tolerant regime for our model. This provides an unconditional quadratic speedup over any classical algorithm in certain circumstances, which we will verify empirically in future work. © T. Laakkonen, K. Meichanetzidis, B. Coecke.},
	keywords = {Computation theory; Fault tolerant computer systems; Modeling languages; Natural language processing systems; Polynomial approximation; Problem oriented languages; Quantum electronics; Quantum optics; Word processing; Fault-tolerant; Language processing; Natural languages; Primitive operations; Quantum algorithms; Quantum circuit; Quantum Computing; Quantum processors; Question Answering; Text-processing; Quantum computers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}@CONFERENCE{Alexander2022355,
	author = {Alexander, Aaranya and Widdows, Dominic},
	title = {Quantum Text Encoding for Classification Tasks},
	year = {2022},
	journal = {Proceedings - 2022 IEEE/ACM 7th Symposium on Edge Computing, SEC 2022},
	pages = {355 – 361},
	doi = {10.1109/SEC54971.2022.00052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146674893&doi=10.1109%2fSEC54971.2022.00052&partnerID=40&md5=14bb4419736abefe8553afbc924bcf39},
	abstract = {This paper explores text classification on quantum computers. Previous results have achieved perfect accuracy on an artificial dataset of 100 short sentences, but at the unscalable cost of using a qubit for each word. This paper demonstrates that an amplitude encoded feature map combined with a quantum support vector machine can achieve 62% average accuracy predicting sentiment using a dataset of 50 actual movie reviews. This is still small, but considerably larger than previously-reported results in quantum NLP.  © 2022 IEEE.},
	author_keywords = {QSVM; Quantum Kernels; Quantum NLP},
	keywords = {Classification (of information); Qubits; Signal encoding; Support vector machines; Text processing; Artificial datasets; Classification tasks; Feature map; QSVM; Quanta computers; Quantum kernel; Quantum NLP; Support vectors machine; Text classification; Text encoding; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Prabha20222172,
	author = {Prabha, Sneh and Sardana, Neetu},
	title = {Question Tags or Text for Topic Modeling: Which is better},
	year = {2022},
	journal = {Procedia Computer Science},
	volume = {218},
	pages = {2172 – 2180},
	doi = {10.1016/j.procs.2023.01.193},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163731146&doi=10.1016%2fj.procs.2023.01.193&partnerID=40&md5=c7d2bb7f157c2f432c937292c6a00a8d},
	abstract = {Topic modelling is a probabilistic based statistical model used to find the latent topics that best depicts the content of the documents. Community Question Answering websites such as Quora, Stack Overflow and Yahoo! Answers have been prevalently in use, performs topic modeling as lot of queries pour in on daily basis which make it challenging to understand, summarize and synthesize the main topic of discussions. On these websites there are basically two sources of information that are available to analyze the key latent topics: questions text and tags. Questions are in textual format and tags are the keywords or tokens that are related to the question being asked which describes the content of the question. In past studies, most of the researchers have used question text for the purpose of topic modeling. It is still unclear why tag is not being considered for topic modeling. To combat this issue, this paper performs topic modeling using both question tags and text. The topic modeling based on tags has been compared with text based on two metrics namely coherence and perplexity. Experiment has been conducted on three real time datasets namely Artificial intelligence, Software Engineering and quantum computing from Stack exchange website. At high level tag-based topic modelling looked promising but closer observation revealed the opposite. It has been found that topic modeling using question text is preferable as topic modelling using tags collapses after a certain number of topics. © 2022 Elsevier B.V.. All rights reserved.},
	author_keywords = {Latent Dirichlet Allocation; Tag-based topic modelling; text-based topic modelling; Topic modelling},
	keywords = {Quantum computers; Software engineering; Statistics; Community question answering; Latent Dirichlet allocation; Probabilistics; Statistic modeling; Tag-based; Tag-based topic modeling; Text-based topic modeling; Topic Modeling; Websites},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Day2023246,
	author = {Day, Wei and Chen, Hao-Sheng and Sun, Min-Te},
	title = {QNet: A Quantum-Native Sequence Encoder Architecture},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Quantum Computing and Engineering, QCE 2023},
	volume = {1},
	pages = {246 – 255},
	doi = {10.1109/QCE57702.2023.00035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180004719&doi=10.1109%2fQCE57702.2023.00035&partnerID=40&md5=9fc51996b00bc02e8f62457624ba8f0a},
	abstract = {This work proposes QNet, a novel sequence encoder model that entirely inferences on the quantum computer using a minimum number of qubits. Let n and d represent the length of the sequence and the embedding size, respectively. The dot-product attention mechanism requires a time complexity of O(n2 ·d), while QNet has merely O(n+d) quantum circuit depth. In addition, we introduce ResQNet, a quantum-classical hybrid model composed of several QNet blocks linked by residual connections, as an isomorph Transformer Encoder. We evaluated our work on various natural language processing tasks, including text classification, rating score prediction, and named entity recognition. Our models exhibit compelling performance over classical state-of-the-art models with a thousand times fewer parameters. In summary, this work investigates the advantage of machine learning on near-term quantum computers in sequential data by experimenting with natural language processing tasks. © 2023 IEEE.},
	author_keywords = {deep learning model; natural language processing; quantum machine learning},
	keywords = {Classification (of information); Learning algorithms; Learning systems; Natural language processing systems; Qubits; Signal encoding; Text processing; Deep learning model; Language processing; Learning models; Machine-learning; Native sequences; Natural language processing; Natural languages; Quanta computers; Quantum machine learning; Quantum machines; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{De Felice202084,
	author = {De Felice, Giovanni and Meichanetzidis, Konstantinos and Toumi, Alexis},
	title = {Functorial question answering},
	year = {2020},
	journal = {Electronic Proceedings in Theoretical Computer Science, EPTCS},
	volume = {323},
	pages = {84 – 94},
	doi = {10.4204/EPTCS.323.6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092643055&doi=10.4204%2fEPTCS.323.6&partnerID=40&md5=775735cb373be5e87fc84be47668d2fe},
	abstract = {Distributional compositional (DisCo) models are functors that compute the meaning of a sentence from the meaning of its words. We show that DisCo models in the category of sets and relations correspond precisely to relational databases. As a consequence, we get complexity-theoretic reductions from semantics and entailment of a fragment of natural language to evaluation and containment of conjunctive queries, respectively. Finally, we define question answering as an NP-complete problem. © G. de Felice, K. Meichanetzidis & A. Toumi.},
	keywords = {Algebra; NP-hard; Semantics; Conjunctive queries; Functors; Natural languages; Question Answering; Relational Database; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Han2023,
	author = {Han, Yin-Xiao and Pan, Yun and Wang, Jing-Tao},
	title = {Quantum semantic coding for structure extraction and matching applications},
	year = {2023},
	journal = {Modern Physics Letters A},
	volume = {38},
	number = {12-13},
	doi = {10.1142/S0217732323500694},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168846736&doi=10.1142%2fS0217732323500694&partnerID=40&md5=ab7c9c93acf93c7a585922dfbff76c5b},
	abstract = {Quantum Natural Language Processing (QNLP) is coded in the semantic space using a combined semantic distribution classification model with tensor operations. Its theoretical results on quantum circuit mapping and quantum semantic coding of text have been tested in practice with the recent development of quantum back-end equipment. In view of the small scale of quantum natural language processing tasks, single sentence structure of quantum semantic coding, low text coverage and lack of application, this paper proposes a combination of syntactic structure to extract text and extend the sentence components of quantum semantic coding, which improves the utilization of text processing task of quantum computing resources. In view of the fact that quantum natural language processing has few cases in specific applications, this paper studies the application expansion possibility of quantum text matching and question answering applications. The development path of classical natural language processing is referred to enhance the usefulness and explore the practical ability of QNLP in the current resource-constrained conditions.  © 2023 World Scientific Publishing Company.},
	author_keywords = {DisCoCat model; natural language processing; Quantum computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vinay2023,
	author = {Vinay, R. and Badari Nath, K.},
	title = {Quantum video classification leveraging textual video representations},
	year = {2023},
	journal = {4th International Conference on Communication, Computing and Industry 6.0, C216 2023},
	doi = {10.1109/C2I659362.2023.10430918},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186530507&doi=10.1109%2fC2I659362.2023.10430918&partnerID=40&md5=1b46adb79b54ce14367285459494b7e9},
	abstract = {Quantum video classification is an emerging area of research which unites machine learning and quantum computing principles. This paper describes an approach for quantum video classification which combines video captioning and quantum natural language processing (QNLP) techniques. The proposed approach involves generating captions for videos and using these captions to produce quantum circuits, which are fed as inputs to a classifier running on a quantum simulator. This technique essentially reduces the quantum video classification problem into a quantum text classification problem. The text-based quantum circuits generated for videos also serve the purpose of acting as a new type of dataset for further research on quantum video processing. The proposed quantum video classifier performs well, with an accuracy of 89 percent when trained and tested on a subset of the kinetics dataset. © 2023 IEEE.},
	author_keywords = {lambeq; mPLUG-2; Quantum computing; quantum entanglement; Quantum Natural Language Processing; Quantum Video Classification; Quantum Video Processing; qubit; string diagram; superposition},
	keywords = {Classification (of information); Natural language processing systems; Qubits; Text processing; Video signal processing; Lambeq; Language processing; MPLUG-2; Natural languages; Quantum Computing; Quantum natural language processing; Quantum video classification; Quantum video processing; String diagram; Superposition; Video classification; Video processing; Quantum entanglement},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zheng20231058,
	author = {Zheng, Jin and Gao, Qing and Miao, Zibo},
	title = {Design of a Quantum Self-Attention Neural Network on Quantum Circuits},
	year = {2023},
	journal = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
	pages = {1058 – 1063},
	doi = {10.1109/SMC53992.2023.10393989},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187243650&doi=10.1109%2fSMC53992.2023.10393989&partnerID=40&md5=d80770741b8b7a0ce75871acb8302a5a},
	abstract = {This paper proposes a quantum self-attention neural network (QSAN) model that can be deployed on quantum circuits, providing a novel avenue to processing text classification tasks in natural language processing (NLP). The QSAN framework is established by integrating four basic blocks: the data preprocessing block, the quantum encoding block, the model design block, and the network optimization block. Simulation results demonstrate remarkable convergence and accuracy on various text classification datasets. In particular, the proposed QSAN surpasses the existing state-of-the-art quantum NLP (QNLP) model in terms of test accuracy.  © 2023 IEEE.},
	keywords = {Natural language processing systems; Neural network models; Quantum theory; Text processing; Timing circuits; Basic blocks; Classification tasks; Data preprocessing; Language processing; Natural languages; Network frameworks; Neural network model; Neural-networks; Quantum circuit; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Omar2023,
	author = {Omar, Ahmed and Abd El-Hafeez, Tarek},
	title = {Quantum computing and machine learning for Arabic language sentiment classification in social media},
	year = {2023},
	journal = {Scientific Reports},
	volume = {13},
	number = {1},
	doi = {10.1038/s41598-023-44113-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174185062&doi=10.1038%2fs41598-023-44113-7&partnerID=40&md5=0e0ad7f2626e2dcf24a7f3c3687ced9c},
	abstract = {With the increasing amount of digital data generated by Arabic speakers, the need for effective and efficient document classification techniques is more important than ever. In recent years, both quantum computing and machine learning have shown great promise in the field of document classification. However, there is a lack of research investigating the performance of these techniques on the Arabic language. This paper presents a comparative study of quantum computing and machine learning for two datasets of Arabic language document classification. In the first dataset of 213,465 Arabic tweets, both classic machine learning (ML) and quantum computing approaches achieve high accuracy in sentiment analysis, with quantum computing slightly outperforming classic ML. Quantum computing completes the task in approximately 59 min, slightly faster than classic ML, which takes around 1 h. The precision, recall, and F1 score metrics indicate the effectiveness of both approaches in predicting sentiment in Arabic tweets. Classic ML achieves precision, recall, and F1 score values of 0.8215, 0.8175, and 0.8121, respectively, while quantum computing achieves values of 0.8239, 0.8199, and 0.8147, respectively. In the second dataset of 44,000 tweets, both classic ML (using the Random Forest algorithm) and quantum computing demonstrate significantly reduced processing times compared to the first dataset, with no substantial difference between them. Classic ML completes the analysis in approximately 2 min, while quantum computing takes approximately 1 min and 53 s. The accuracy of classic ML is higher at 0.9241 compared to 0.9205 for quantum computing. However, both approaches achieve high precision, recall, and F1 scores, indicating their effectiveness in accurately predicting sentiment in the dataset. Classic ML achieves precision, recall, and F1 score values of 0.9286, 0.9241, and 0.9249, respectively, while quantum computing achieves values of 0.92456, 0.9205, and 0.9214, respectively. The analysis of the metrics indicates that quantum computing approaches are effective in identifying positive instances and capturing relevant sentiment information in large datasets. On the other hand, traditional machine learning techniques exhibit faster processing times when dealing with smaller dataset sizes. This study provides valuable insights into the strengths and limitations of quantum computing and machine learning for Arabic document classification, emphasizing the potential of quantum computing in achieving high accuracy, particularly in scenarios where traditional machine learning techniques may encounter difficulties. These findings contribute to the development of more accurate and efficient document classification systems for Arabic data. © 2023, Springer Nature Limited.},
	keywords = {Computing Methodologies; Humans; Language; Machine Learning; Quantum Theory; Sentiment Analysis; Social Media; Arabic (language); article; comparative study; controlled study; human; human experiment; machine learning; random forest; recall; sentiment analysis; social media; computer analysis; language; machine learning; quantum theory; sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Di Sipio20228612,
	author = {Di Sipio, Riccardo and Huang, Jia-Hong and Chen, Samuel Yen-Chi and Mangini, Stefano and Worring, Marcel},
	title = {THE DAWN OF QUANTUM NATURAL LANGUAGE PROCESSING},
	year = {2022},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	volume = {2022-May},
	pages = {8612 – 8616},
	doi = {10.1109/ICASSP43922.2022.9747675},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130568784&doi=10.1109%2fICASSP43922.2022.9747675&partnerID=40&md5=0769e5fa9ce2ea6bb4aea773d15ceaca},
	abstract = {In this paper, we discuss the initial attempts at boosting understanding human language based on deep-learning models with quantum computing. We successfully train a quantum-enhanced Long Short-Term Memory network to perform the parts-of-speech tagging task via numerical simulations. Moreover, a quantum-enhanced Transformer is proposed to perform the sentiment analysis based on the existing dataset. © 2022 IEEE},
	author_keywords = {LSTM; Natural Language Processing; Quantum Computing; Quantum Machine Learning; Quantum Neural Networks; Transformer; Variational Quantum Circuits},
	keywords = {Learning algorithms; Long short-term memory; Quantum computers; Timing circuits; Language processing; LSTM; Machine-learning; Natural language processing; Natural languages; Quantum circuit; Quantum Computing; Quantum machine learning; Quantum machines; Quantum neural networks; Transformer; Variational quantum circuit; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66}
}

@BOOK{Shrivastava2023395,
	author = {Shrivastava, Madhav and Patil, Rajat and Bhardwaj, Vivek and Rawat, Romil and Telang, Shrikant and Rawat, Anjali},
	title = {Quantum computing and security aspects of attention-based visual question answering with long short-term memory},
	year = {2023},
	journal = {Quantum Computing in Cybersecurity},
	pages = {395 – 412},
	doi = {10.1002/9781394167401.ch23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176327294&doi=10.1002%2f9781394167401.ch23&partnerID=40&md5=47e7dc1c14528b9bf3954db81be8d2ec},
	abstract = {In this write-up, we will study the core concept of VQA the LSTM with Att.-based models and CNN Att. models that combine the local images' hidden features and the answer of the question which is raised by end user is produced from the portion of the image which is generated by image dataset. So, the word Att. means that it only keeps Att. on those parts which are relevant to both object and keywords in the question. We are not considering the outlier to reduce the chances of mistakes. To combine the results from the image and given questions we are using multi-layer awareness. In this proposal of QC in field of VQA and LSTM, we tried to use this concept of MM Networks and presented our view on vulnerability of a primary/novel kind of attack that we call as DKMB. This hard kind of theft breaks the complex fusion (Combinations) mechanism take into consideration by a prime state-of-art networks to fuse BDs which are both effective, efficient, and stealthy. Here, we are proposing a multi-model for VQA with Att.-Based LSTM along with loopholes where attacker can attack and influence system which can be tackled with Quantum Computing and Cybersecurity Concepts. © 2023 Scrivener Publishing LLC.},
	author_keywords = {Convolutional neural network; Image processing; Neural networks; Quantum attacks; Quantum machine; Visual question answering},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Bronze Open Access}
}

@CONFERENCE{Asinthara2022,
	author = {Asinthara, K. and Jayan, Meghna and Jacob, Lija},
	title = {Classification of Disaster Tweets using Machine Learning and Deep Learning Techniques},
	year = {2022},
	journal = {2022 International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2022},
	doi = {10.1109/TQCEBT54229.2022.10041629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149176827&doi=10.1109%2fTQCEBT54229.2022.10041629&partnerID=40&md5=9a15cd7ae61a9f15b2085cfad0420a2e},
	abstract = {Social networks provide a plethora of information for gathering extra data on people's behavior, trends, opinions, and feelings during human-affecting occurrences, such as natural catastrophes. Twitter is an inevitable communication medium during calamities. People mainly depend on Twitter to announce real-time emergencies. However, it is rarely straightforward if someone is declaring a tragedy. Sentiment analysis of disaster tweets aid in situational awareness and realizing the disaster dynamics. In our paper, we perform a sentimental analysis of disaster tweets using techniques based on machine learning and deep learning. The tweets are pre-processed before being converted into a structured form using Natural Language Processing (NLP) methods. Supervised learning techniques such as the Support Vector Machine and the Naive Bayes Classifier algorithm are used to develop the Classifier, which categorizes tweets into distinct catastrophes and selects the most appropriate algorithm. The chosen algorithm is further enriched with an emoticon detection algorithm for explicit elucidation. Our research would help disaster relief organizations and news agencies to conclude about the state of affairs and do the needful.  © 2022 IEEE.},
	author_keywords = {deep learning; disaster management; disaster tweets; machine learning; natural language processing; Twitter},
	keywords = {Deep learning; Disaster prevention; Learning algorithms; Learning systems; Sentiment analysis; Social networking (online); Support vector machines; Deep learning; Disaster management; Disaster tweet; Language processing; Learning techniques; Machine-learning; Natural language processing; Natural languages; People behavior; Twitter; Disasters},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Nandi2023822,
	author = {Nandi, Basanti Pal and Jain, Amita and Tayal, Devendra Kumar},
	title = {Aspect Based Sentiment Analysis Using Long-Short Term Memory and Weighted N-Gram Graph-Cut},
	year = {2023},
	journal = {Cognitive Computation},
	volume = {15},
	number = {3},
	pages = {822 – 837},
	doi = {10.1007/s12559-022-10104-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147284755&doi=10.1007%2fs12559-022-10104-5&partnerID=40&md5=2d32c61cb7aba2fff99bc8a1aa62a1f0},
	abstract = {In the current domain, aspect-based sentiment analysis is a much-explored area in sentiment classification. In this paper, an optimization method, Graph-Cut, is used first time for aspect-based sentiment analysis. In this research, a new concept of N-gram Graph-Cut is applied on aspect-based sentiment analysis. Also, a hybrid approach on a combination of Graph-Cut and long short-term memory (LSTM) algorithm is proposed. In the hybrid approach, knowledge is transferred from 1-g Graph-Cut to LSTM and is applied on two-way and three-way (positive, negative, and neutral) sentiment classification. The 1-g Graph-Cut, 2-g Graph-Cut, and combined 1-g Graph-Cut and LSTM algorithms are applied on restaurant, laptop, and Mams datasets for two-way and three-way classification. It has been observed that for multiword aspect terms in the laptop dataset, it is enhancing the accuracy in both two-way and three-way sentiment classification. Besides, term-based aspect sentiment classification is giving enhanced results in both the ways. Moreover, the proposed hybrid method 1-g Graph-Cut-LSTM gives better accuracy than a single LSTM or CNN model and increases the accuracy by 9% in three-way classification for laptop dataset. One-gram Graph-Cut and 2-g Graph-Cut methods have an advantage over other deep learning methods because they do not require any training, and it is completely unsupervised. The hybrid model 1-g Graph-Cut-LSTM gives better results than LSTM due to the selection of relevant words from a sentence according to its aspect by Graph-Cut method, which is a novel concept. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Aspect; Graph-Cut; Long short-term memory; N-gram Graph-Cut; Sentiment},
	keywords = {Brain; Classification (of information); Graphic methods; Laptop computers; Learning systems; Sentiment analysis; Aspect; Graph-cut; Hybrid approach; N-gram graph-cut; N-grams; Sentiment; Sentiment analysis; Sentiment classification; Two ways; Long short-term memory},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Correia2022,
	author = {Correia, A.D. and Moortgat, M. and Stoof, H.T.C.},
	title = {Quantum computations for disambiguation and question answering},
	year = {2022},
	journal = {Quantum Information Processing},
	volume = {21},
	number = {4},
	doi = {10.1007/s11128-022-03441-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127544777&doi=10.1007%2fs11128-022-03441-9&partnerID=40&md5=205b2e4fb3ad0be536c7a575a6db0dac},
	abstract = {Automatic text processing is now a mature discipline in computer science, and so attempts at advancements using quantum computation have emerged as the new frontier, often under the term of quantum natural language processing. The main challenges consist in finding the most adequate ways of encoding words and their interactions on a quantum computer, considering hardware constraints, as well as building algorithms that take advantage of quantum architectures, so as to show improvement on the performance of natural language tasks. In this paper, we introduce a new framework that starts from a grammar that can be interpreted by means of tensor contraction, to build word representations as quantum states that serve as input to a quantum algorithm. We start by introducing an operator measurement to contract the representations of words, resulting in the representation of larger fragments of text. We then go on to develop pipelines for the tasks of sentence meaning disambiguation and question answering that take advantage of quantum features. For the first task, we show that our contraction scheme deals with syntactically ambiguous phrases storing the various different meanings in quantum superposition, a solution not available on a classical setting. For the second task, we obtain a question representation that contains all possible answers in equal quantum superposition, and we implement Grover’s quantum search algorithm to find the correct answer, agnostic to the specific question, an implementation with the potential of delivering a result with quadratic speedup. © 2022, The Author(s).},
	author_keywords = {Grover’s algorithm; Quantum natural language processing; Quantum search; Question answering; Syntactic ambiguities},
	keywords = {Computer hardware; Quantum computers; Quantum theory; Text processing; Automatic text processing; Grov’s algorithm; Hardware constraints; Quanta computers; Quantum natural language processing; Quantum search; Quantum superpositions; Question Answering; S-algorithms; Syntactic Ambiguities; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Singh2022115108,
	author = {Singh, Jaiteg and Ali, Farman and Shah, Babar and Bhangu, Kamalpreet Singh and Kwak, Daehan},
	title = {Emotion Quantification Using Variational Quantum State Fidelity Estimation},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {115108 – 115119},
	doi = {10.1109/ACCESS.2022.3216890},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141489106&doi=10.1109%2fACCESS.2022.3216890&partnerID=40&md5=dedba2c53aeb76fe2948dc3d265aab86},
	abstract = {Sentiment analysis has been instrumental in developing artificial intelligence when applied to various domains. However, most sentiments and emotions are temporal and often exist in a complex manner. Several emotions can be experienced at the same time. Instead of recognizing only categorical information about emotions, there is a need to understand and quantify the intensity of emotions. The proposed research intends to investigate a quantum-inspired approach for quantifying emotional intensities in runtime. The inspiration comes from manifesting human cognition and decision-making capabilities, which may adopt a brief explanation through quantum theory. Quantum state fidelity was used to characterize states and estimate emotion intensities rendered by subjects from the Amsterdam Dynamic Facial Expression Set (ADFES) dataset. The Quantum variational classifier technique was used to perform this experiment on the IBM Quantum Experience platform. The proposed method successfully quantifies the intensities of joy, sadness, contempt, anger, surprise, and fear emotions of labelled subjects from the ADFES dataset.  © 2013 IEEE.},
	author_keywords = {Emotion detection; quantification of emotions; quantum computation; quantum machine learning; sentiment analysis},
	keywords = {Artificial intelligence; Computation theory; Data mining; Decision making; Decision theory; Emotion Recognition; Learning algorithms; Learning systems; Quantum computers; Variational techniques; Classification algorithm; Computational modelling; Emotion detection; Emotion recognition; Machine learning algorithms; Machine-learning; Quantification of emotion; Quantum Computing; Quantum machine learning; Quantum machines; Sentiment analysis; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access}
}

@ARTICLE{Ogbuokiri2023200,
	author = {Ogbuokiri, Blessing and Ahmadi, Ali and Mellado, Bruce and Wu, Jiahong and Orbinski, James and Asgary, Ali and Kong, Jude},
	title = {Can Post-vaccination Sentiment Affect the Acceptance of Booster Jab?},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {716 LNNS},
	pages = {200 – 211},
	doi = {10.1007/978-3-031-35501-1_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164263435&doi=10.1007%2f978-3-031-35501-1_20&partnerID=40&md5=0924762064048714a5dac11f08d38683},
	abstract = {In this paper, Twitter posts discussing the COVID-19 vaccine booster shot from nine African countries were classified according to sentiments to understand the effect of citizens’ sentiments towards accepting the booster shot. The number of booster shot-related tweets significantly positively correlated with the increase in booster shots across different countries (Corr = 0.410, P = 0.028). Similarly, the increase in the number of positive tweets discussing booster shots significantly positively correlated with the increase in positive tweet intensities (Corr = 0.992, P &lt; 0.001). The increase in intensities of positive tweets also positively correlated with an increase in likes and re-tweets (Corr = 0.560, P &lt; 0.001). Topics were identified from the tweets using the LDA model, including – booster safety, booster efficacy, booster type, booster uptake, and vaccine uptake. The 77% of tweets discussing these topics are mostly from South Africa, Nigeria (19%), and Namibia (3%). Our result showed that there is an average 45.5% chance of tweets discussing these topics carrying positive sentiments. The outcome suggests that users’ expressions on social media regarding booster shots could likely affect the acceptance of booster shots either positively or negatively. This research should be relevant to health policy-makers in gathering insight from social media data for the management and planning of vaccination programs during a disease outbreak. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Booster shot; Boostered; Data mining; Sentiment analysis; Social media; Vaccination},
	keywords = {COVID-19; Data mining; Social networking (online); Vaccines; Booster shot; Boostered; Classifieds; Namibia; Nigeria; Sentiment analysis; Social media; South Africa; Twitter posts; Vaccination; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@BOOK{Gutierrez202376,
	author = {Gutierrez, Ray},
	title = {Unifying linguistic landscapes: The potential of AI and nanotechnology in facilitating real-time translation},
	year = {2023},
	journal = {Artificial Intelligence in the Age of Nanotechnology},
	pages = {76 – 97},
	doi = {10.4018/9798369303689.ch005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182092562&doi=10.4018%2f9798369303689.ch005&partnerID=40&md5=21bf222cbfe2ae4ac7c11242b496c20b},
	abstract = {This chapter examines how recent artificial intelligence and nanotechnology innovations could help overcome persistent global language barriers that hamper communication. It explores the progression of machine translation capabilities leveraging neural networks to achieve near-human-level accuracy. The chapter also considers how nanotechnology may enable real-time translation through augmented reality and wearable devices. However, these technologies also pose challenges regarding potential misuse, biases, and unintended cultural impacts. Therefore, responsible advancement of these technologies is imperative, ensuring they are deployed equitably to benefit all of society. This chapter aims to provide a comprehensive overview of the associated technologies and their integrated applications while also discussing prudent research directions and policies needed to steer these fields toward the greater good. Overall, it strikes a balance between enthusiasm for the future capabilities of AI and nanotech in translation and a cautious approach to their development. © 2023, IGI Global. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Punugoti2023,
	author = {Punugoti, Rajasrikar and Duggar, Ronak and Dhargalkar, Risha Ranganath and Bhati, Neha},
	title = {Intelligent Healthcare: Using NLP and ML to Power Chatbots for Improved Assistance},
	year = {2023},
	journal = {2023 International Conference on IoT, Communication and Automation Technology, ICICAT 2023},
	doi = {10.1109/ICICAT57735.2023.10263708},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174847860&doi=10.1109%2fICICAT57735.2023.10263708&partnerID=40&md5=adfaa325544820190384c11fb9a0e14d},
	abstract = {This research examines the fundamental reasons chatbots exist, their functions, and their challenges. The applicability and consistency of the analysis are improved by the utilization of quantitative data that is gathered in real-time. The research also compares past techniques of creating chatbots with modern ones, highlighting how far chatbots have progressed from being able to merely engage in scripted scenarios to the advanced skills they have today thanks to end-to-end neural networks. Microsoft Research carried out the research and published it in the journal Science. The first paragraph of this essay presents a detailed examination of chatbots' roles, significance, and potential. This research sheds new insight into the concept of chatbots by investigating their development and many uses in greater detail than previously.  © 2023 IEEE.},
	author_keywords = {Chatbot; Conversational Agents; Intelligence; Machine Learning; Modelling of Conversations; Natural Language Processing (NLP); Neural Machine Translation},
	keywords = {Computational linguistics; Learning algorithms; Modeling languages; Natural language processing systems; Neural machine translation; Chatbots; Conversational agents; Intelligence; Language processing; Machine-learning; Modeling of conversation; Natural language processing; Natural languages; Power; Quantitative data; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Bausch2020,
	author = {Bausch, Johannes},
	title = {Recurrent quantum neural networks},
	year = {2020},
	journal = {Advances in Neural Information Processing Systems},
	volume = {2020-December},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108450620&partnerID=40&md5=c3f9bca7372df24cb03615b1e88e020f},
	abstract = {Recurrent neural networks are the foundation of many sequence-to-sequence models in machine learning, such as machine translation and speech synthesis. With applied quantum computing in its infancy, there already exist quantum machine learning models such as variational quantum eigensolvers which have been used e.g. in the context of energy minimization tasks. Yet, to date, no viable recurrent quantum network has been proposed. In this work we construct the first quantum recurrent neural network (QRNN) with demonstrable performance on non-trivial tasks such as sequence learning and integer digit classification. The QRNN cell is built from parametrized quantum neurons, which, in conjunction with amplitude amplification, creates a nonlinear activation of polynomials of its inputs and cell state, and allows the extraction of a probability distribution over predicted classes at each step. To study the model’s performance, we provide an implementation in pytorch, which allows the relatively efficient optimization of parametrized quantum circuits with tens of thousands of parameters, and which demonstrates that the model does not appear to suffer from the vanishing gradient problem that plagues many existing quantum classifiers and classical RNNs. We establish a QRNN training setup by benchmarking optimization hyperparameters, and analyse suitable network topologies for simple memorisation and sequence prediction tasks from Elman’s seminal paper (1990). We then proceed to evaluate the QRNN on MNIST classification, by feeding the QRNN each image pixel-by-pixel; with a network utilizing only 12 qubits we reach a test set accuracy over 95% when discriminating between the digits ‘0’ and ‘1’. © 2020 Neural information processing systems foundation. All rights reserved.},
	keywords = {Classification (of information); Computer aided language translation; Learning systems; Pixels; Probability distributions; Quantum computers; Quantum theory; Speech synthesis; Speech transmission; Digit classification; Energy minimization; Machine translations; Non-linear activation; Non-trivial tasks; Quantum neural networks; Sequence prediction; Vanishing gradient; Recurrent neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 93}
}

@CONFERENCE{Ananth2022,
	author = {Ananth, Kavitha and Kirubanand, V.B.},
	title = {Building an Industry Standard Novel Language Model Using Named Entities},
	year = {2022},
	journal = {2022 International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2022},
	doi = {10.1109/TQCEBT54229.2022.10041678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149177678&doi=10.1109%2fTQCEBT54229.2022.10041678&partnerID=40&md5=8b883391cc85d667ad3de2b63c34d38a},
	abstract = {In every Industry, there is a significant amount of text used in their specific domains. As these are less prevalent in the testing set, anticipating entity names in a language model is a problem faced by the entire industry. In this research a unique and very effective strategy for creating exclusionary classification models that could map entity names based on entity type information is provided. A group of benchmark datasets based on Mortgage is presented, which we used to test the below-presented model. According to experimental findings, our model achieves a perplexity level that is 64% higher than that of the most advanced language models.  © 2022 IEEE.},
	author_keywords = {CTC(Connectionist Temporal Classification); FSM(Finite State Machine); LM(Language Model); NER(Named Entity Recognition); NLP(Natural Language Processing); PTB(Pen Tree Bank)},
	keywords = {Classification (of information); Computational linguistics; Connectionist temporal classification; Finite states machine; Industry standards; Language model; Language processing; Named entity recognition; Natural language processing; Natural languages; Pen tree bank; Temporal classification; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vydeki2023,
	author = {Vydeki, D. and Victor, Davis and Mamoo, Zoheb and Rohit, Varun and Annis Fathima, A.},
	title = {Machine Translation using Dictionary based Techniques},
	year = {2023},
	journal = {2023 IEEE 8th International Conference for Convergence in Technology, I2CT 2023},
	doi = {10.1109/I2CT57861.2023.10126256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161345471&doi=10.1109%2fI2CT57861.2023.10126256&partnerID=40&md5=cab4e0f8e8ee3b641a865cd3837ba410},
	abstract = {Translating words and sentences is a major challenge, let alone a whole book. Tradition-ally, publishers used to manually translate a whole book. As computers and Internet came into being, it was used for translating words and sentences from one language to other using various methods. Dictionary based techniques are one of the oldest machine translation techniques. Mod-ern day apps use statistical machine translation techniques along with neural networks and/or natural language processing methods, where there is a high chance of error as they focus more on the language diversity. The major mo-tivation of this research work is to improve the English learning skills of ru-ral South Indian school students. As per a survey conducted by the authors, the rural students lack in command over English, due to the difficulty in translation services. The authors created a dataset consisting of English words from Tamil Nadu State textbooks of classes up to grade 10, to execute the translation. In this paper, we have used dictionary mapping, such as lin-ear, binary and Trie search methods, for performing word translation from English to Tamil, and compared them in different conditions to identify the best one. It is observed that the Binary search method performs better in all cases and hence it was selected to be implemented in the translation app. It is then clubbed with natural lan-guage processing (NLP) techniques and Rule Based Machine Translation (RBMT) techniques to carry out the trans-lation of a whole sentence. This whole technique is integrat-ed into an app, which is intended for students who are not fluent in English and requires an assistance. © 2023 IEEE.},
	author_keywords = {Binary search; Dictionary mapping; Natural language processing; Rule based machine translation; Trie},
	keywords = {Computational linguistics; Computer aided language translation; Machine translation; Natural language processing systems; Students; Binary search; Dictionary mapping; Language processing; Machine translations; Natural language processing; Natural languages; Rule-based machine translations; Search method; Statistical machine translation; Trie; Mapping},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ruskanda202387520,
	author = {Ruskanda, Fariska Zakhralativa and Abiwardani, Muhammad Rifat and Mulyawan, Rahmat and Syafalni, Infall and Larasati, Harashta Tatimma},
	title = {Quantum-Enhanced Support Vector Machine for Sentiment Classification},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {87520 – 87532},
	doi = {10.1109/ACCESS.2023.3304990},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168284942&doi=10.1109%2fACCESS.2023.3304990&partnerID=40&md5=59cfb32b5b0e3fafa0e8fe31885d887e},
	abstract = {Quantum computers have potential computational abilities such as speeding up complex computations, parallelism by superpositions, and handling large data sets. Moreover, the field of natural language processing (NLP) is rapidly attracting researchers and engineers in order to build larger model computations of NLP. Thus, the use of quantum technology in NLP tasks, especially sentiment classification, has the potential to be developed. In this research, we investigate the best technique to represent sentiment sentences so that sentiment can be analyzed using the Quantum-Enhanced Support Vector Machine (QE-SVM) algorithm. Investigations were carried out using circuit parameter optimization methods and data transformation. The pipeline of the proposed method consists of sentence-to-circuit conversion, circuit parameter training, state vector formation, and finally the training and testing processes. As a result, we obtained the best classification results with an accuracy of 93.33% using the SPSA optimization method and PCA transformation data. These results have also outperformed the baseline SVM method.  © 2013 IEEE.},
	author_keywords = {quantum representation; quantum-enhanced; Sentiment classification; SVM},
	keywords = {Job analysis; Metadata; Optimization; Quantum computers; Support vector machines; Vectors; Kernel; Quantum Computing; Quantum representation; Quantum-enhanced; Sentiment analysis; Sentiment classification; Support vectors machine; SVM; Task analysis; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access}
}

@BOOK{Arlt20231,
	author = {Arlt, Fabian and Arlt, Hans-Jürgen},
	title = {Gaming is unlikely: A Theory of Ludic Action},
	year = {2023},
	journal = {Gaming is unlikely: A Theory of Ludic Action},
	pages = {1 – 176},
	doi = {10.1007/978-3-658-39964-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161939357&doi=10.1007%2f978-3-658-39964-1&partnerID=40&md5=177f8a782d529f046ff36cf8bea89ed7},
	abstract = {A concept of game is justified and unfolded that revolves around the lure and threat of the unexpected. The author duo places their theory of ludic action in classical concepts of the game as well as in the current discourse of game studies. The phenomenal multiplicity of games is outlined in historical perspective and structured in a systematic manner. The authors explain the media-technical and communicative preconditions of the computer game boom and reflect on the discussion about escalations of ludic violence. The instrumentalization of games, which is becoming increasingly popular under the heading of gamification, is critically examined. The conspicuous inflation of the game metaphor is brought into connection with ludic connotations in the social structures of modern and digital society. Fabian Arlt, M. A., studied media management and is doing his doctorate in social and business communication at the University of the Arts (UdK) in Berlin. Prof. Dr. Hans-Jürgen Arlt is a social scientist and publicist, he teaches at the Institute for Theory and Practice of Communication at the University of the Arts (UdK) in Berlin. This book is a translation of an original German edition. The translation was done with the help of artificial intelligence (machine translation by the service DeepL.com). A subsequent human revision was done primarily in terms of content, so that the book will read stylistically differently from a conventional translation. © The Editor(s) (if applicable) and The Author(s), under exclusive licence to Springer Fachmedien Wiesbaden GmbH, part of Springer Nature 2023.},
	author_keywords = {Communication; Computer games; Expect the unexpected; Fiction; Games; Gamification; Interaction; Narration; Probability; Speculation; Thrill},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Ruskanda2023120612,
	author = {Ruskanda, Fariska Zakhralativa and Abiwardani, Muhammad Rifat and Syafalni, Infall and Larasati, Harashta Tatimma and Mulyawan, Rahmat},
	title = {Simple Sentiment Analysis Ansatz for Sentiment Classification in Quantum Natural Language Processing},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {120612 – 120627},
	doi = {10.1109/ACCESS.2023.3327873},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176454853&doi=10.1109%2fACCESS.2023.3327873&partnerID=40&md5=cdebad016c1573f3bd5665123639992e},
	abstract = {Sentiment classification is a valuable application of natural language processing that has seen wide usage in optimizing business processes. This paper explores a novel implementation of sentiment analysis using the Variational Quantum Algorithms (VQA) framework. As ansatz choice determines model performance in VQA, this paper proposes an alternative ansatz for the sentiment classification task in quantum representation. Specifically, it builds upon previous work in quantum sentiment classification by proposing an alternative ansatz to the Instantaneous Quantum Polytime ansatz, entitled Simple Sentiment Analysis (SimpleSA) ansatz. A key feature of the SimpleSA ansatz is the decision to neglect noun parameterization. The proposed SimpleSA has less complexity than the other ansätze in terms of the number of parameters and the number of gates. Moreover, experimental results show that the SimpleSA ansatz with H-CNOT-Rz-H compound block construction outperforms the Instantaneous Quantum Polytime (IQP) ansatz at 85.00% accuracy. Furthermore, SimpleSA optimization converges 20.89% faster than Instantaneous Quantum Polytime (IQP) for the Simultaneous Perturbation Stochastic Approximation (SPSA) method with 130 iterations. The proposed work is useful for applications of quantum computers for sentiment analyses and classifications.  © 2013 IEEE.},
	author_keywords = {ansatz; quantum circuit; quantum machine learning; Quantum natural language processing; sentiment classification},
	keywords = {Learning algorithms; Machine learning; Optimization; Quantum computers; Quantum optics; Stochastic systems; Timing circuits; Ansatz; Language processing; Machine-learning; Natural languages; Quantum circuit; Quantum machine learning; Quantum machines; Quantum natural language processing; Sentiment analysis; Sentiment classification; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Guarasci2022,
	author = {Guarasci, Raffaele and De Pietro, Giuseppe and Esposito, Massimo},
	title = {Quantum Natural Language Processing: Challenges and Opportunities},
	year = {2022},
	journal = {Applied Sciences (Switzerland)},
	volume = {12},
	number = {11},
	doi = {10.3390/app12115651},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131733513&doi=10.3390%2fapp12115651&partnerID=40&md5=bc0884749aacd6a77e6821b00a3cbb41},
	abstract = {The meeting between Natural Language Processing (NLP) and Quantum Computing has been very successful in recent years, leading to the development of several approaches of the so-called Quantum Natural Language Processing (QNLP). This is a hybrid field in which the potential of quantum mechanics is exploited and applied to critical aspects of language processing, involving different NLP tasks. Approaches developed so far span from those that demonstrate the quantum advantage only at the theoretical level to the ones implementing algorithms on quantum hardware. This paper aims to list the approaches developed so far, categorizing them by type, i.e., theoretical work and those implemented on classical or quantum hardware; by task, i.e., general purpose such as syntax-semantic representation or specific NLP tasks, like sentiment analysis or question answering; and by the resource used in the evaluation phase, i.e., whether a benchmark dataset or a custom one has been used. The advantages offered by QNLP are discussed, both in terms of performance and methodology, and some considerations about the possible usage QNLP approaches in the place of state-of-the-art deep learning-based ones are given. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {natural language processing; quantum computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Gold Open Access}
}

@ARTICLE{Abbaszade2021130434,
	author = {Abbaszade, Mina and Salari, Vahid and Mousavi, Seyed Shahin and Zomorodi, Mariam and Zhou, Xujuan},
	title = {Application of Quantum Natural Language Processing for Language Translation},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {130434 – 130448},
	doi = {10.1109/ACCESS.2021.3108768},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114721682&doi=10.1109%2fACCESS.2021.3108768&partnerID=40&md5=19914022c8544fd65637d84cbdc80492},
	abstract = {In this paper, we develop compositional vector-based semantics of positive transitive sentences using quantum natural language processing (Q-NLP) to compare the parametrized quantum circuits of two synonymous simple sentences in English and Persian. We propose a protocol based on quantum long short-term memory (Q-LSTM) for Q-NLP to perform various tasks in general but specifically for translating a sentence from English to Persian. Then, we generalize our method to use quantum circuits of sentences as an input for the Q-LSTM cell. This enables us to translate sentences in different languages. Our work paves the way toward representing quantum neural machine translation, which may demonstrate quadratic speedup and converge faster or reaches a better accuracy over classical methods.  © 2013 IEEE.},
	author_keywords = {DisCoCat diagrams; Q-LSTM; Q-NLP; quantum circuits; ZX-calculus},
	keywords = {Computer aided language translation; Long short-term memory; Semantics; Classical methods; Language translation; Machine translations; NAtural language processing; Persians; Quadratic speedup; Quantum circuit; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sawicki2023707,
	author = {Sawicki, Jan and Ganzha, Maria and Paprzycki, Marcin},
	title = {The State of the Art of Natural Language Processing—A Systematic Automated Review of NLP Literature Using NLP Techniques},
	year = {2023},
	journal = {Data Intelligence},
	volume = {5},
	number = {3},
	pages = {707 – 749},
	doi = {10.1162/dint_a_00213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175084705&doi=10.1162%2fdint_a_00213&partnerID=40&md5=c5a39e0c62906a925729d857309ab693},
	abstract = {Nowadays, natural language processing (NLP) is one of the most popular areas of, broadly understood, artificial intelligence. Therefore, every day, new research contributions are posted, for instance, to the arXiv repository. Hence, it is rather difficult to capture the current “state of the field” and thus, to enter it. This brought the id-art NLP techniques to analyse the NLP-focused literature. As a result, (1) meta-level knowledge, concerning the current state of NLP has been captured, and (2) a guide to use of basic NLP tools is provided. It should be noted that all the tools and the dataset described in this contribution are publicly available. Furthermore, the originality of this review lies in its full automation. This allows easy reproducibility and continuation and updating of this research in the future as new researches emerge in the field of NLP. © 2023 Chinese Academy of Sciences.},
	author_keywords = {Keyphrase search; Literature survey; Natural language processing; search; Text embeddings; Text processing; Text summarizations},
	keywords = {Natural language processing systems; Embeddings; Key-phrase; Keyphrase search; Language processing; Literature survey; Natural language processing; Natural languages; Search; Text embedding; Text Summarisation; Text-processing; Text processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access}
}

@ARTICLE{Sadiq202395008,
	author = {Sadiq, Saima and Aljrees, Turki and Ullah, Saleem},
	title = {Deepfake Detection on Social Media: Leveraging Deep Learning and FastText Embeddings for Identifying Machine-Generated Tweets},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {95008 – 95021},
	doi = {10.1109/ACCESS.2023.3308515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168710919&doi=10.1109%2fACCESS.2023.3308515&partnerID=40&md5=05c96be4fd33375851e0c31338d01a4d},
	abstract = {Recent advancements in natural language production provide an additional tool to manipulate public opinion on social media. Furthermore, advancements in language modelling have significantly strengthened the generative capabilities of deep neural models, empowering them with enhanced skills for content generation. Consequently, text-generative models have become increasingly powerful allowing the adversaries to use these remarkable abilities to boost social bots, allowing them to generate realistic deepfake posts and influence the discourse among the general public. To address this problem, the development of reliable and accurate deepfake social media message-detecting methods is important. Under this consideration, current research addresses the identification of machine-generated text on social networks like Twitter. In this study, a simple deep learning model in combination with word embeddings is employed for the classification of tweets as human-generated or bot-generated using a publicly available Tweepfake dataset. A conventional Convolutional Neural Network (CNN) architecture is devised, leveraging FastText word embeddings, to undertake the task of identifying deepfake tweets. To showcase the superior performance of the proposed method, this study employed several machine learning models as baseline methods for comparison. These baseline methods utilized various features, including Term Frequency, Term Frequency-Inverse Document Frequency, FastText, and FastText subword embeddings. Moreover, the performance of the proposed method is also compared against other deep learning models such as Long short-term memory (LSTM) and CNN-LSTM displaying the effectiveness and highlighting its advantages in accurately addressing the task at hand. Experimental results indicate that the design of the CNN architecture coupled with the utilization of FastText embeddings is suitable for efficient and effective classification of the tweet data with a superior 93% accuracy.  © 2013 IEEE.},
	author_keywords = {deep learning; deepfake; machine generated text; machine learning; Text classification},
	keywords = {Computational linguistics; Convolution; Deep neural networks; E-learning; Inverse problems; Long short-term memory; Modeling languages; Natural language processing systems; Network architecture; Personnel training; Social aspects; Social networking (online); Text messaging; Text processing; Chatbots; Convolutional neural network; Deep learning; Deepfake; Electronic messaging; Machine-generated texts; Machine-learning; Social networking (online); Task analysis; Text categorization; Text classification; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access}
}

@ARTICLE{Alfonse2023313,
	author = {Alfonse, Marco and Gawich, Mariam},
	title = {Emotions-Based Disaster Tweets Classification: Real or Fake},
	year = {2023},
	journal = {WSEAS Transactions on Information Science and Applications},
	volume = {20},
	pages = {313 – 321},
	doi = {10.37394/23209.2023.20.34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176325246&doi=10.37394%2f23209.2023.20.34&partnerID=40&md5=ea379e29e657989664ebde93e45d9e45},
	abstract = {Social media platforms are considered interactive communication channels between governments, civil society organizations, and the public. During disaster occurrences, social media platforms play a crucial role such as the alertness of people towards the disaster occurrence, its risks, and consequences. They are used as tools to spread real updated information rapidly related to the disaster. Furthermore, social media platforms can facilitate the mobilization of volunteers as well as the organization of campaign donations after the disaster occurrence. Nevertheless, the benefits of social media platforms can be a double-edged sword through the dissemination of unreal information such as rumors or fake disasters. Unfortunately, the public can easily believe unreal information due to the anxiety that they experienced during the occurrence of a past real disaster. This paper presents a model to distinguish between the fake disaster tweets and the real ones. The implementation of this model is established twice; the first implementation involves the use of Machine Learning with the traditional Natural Language Processing techniques on the disaster dataset provided by Kaggle, and the second implementation involves using the emotions that are extracted from the tweets in the classification process. The proposed model achieves an accuracy of 88,34% without the usage of the emotion extraction module while it achieves an accuracy of 89,39 % with the inclusion of the emotion extraction module. © 2023 Sustainable Development Press Limited. All rights reserved},
	author_keywords = {Artificial Intelligence; Fake Disasters Tweets; Knowledge Discovery; Machine Learning; Natural Language Processing; Sentiment Analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Qureshi202224945,
	author = {Qureshi, Muhammad Aasim and Asif, Muhammad and Hassan, Mohd Fadzil and Abid, Adnan and Kamal, Asad and Safdar, Sohail and Akber, Rehan},
	title = {Sentiment Analysis of Reviews in Natural Language: Roman Urdu as a Case Study},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {24945 – 24954},
	doi = {10.1109/ACCESS.2022.3150172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124833996&doi=10.1109%2fACCESS.2022.3150172&partnerID=40&md5=24218b44dcaaf385ddb4450b32d55a24},
	abstract = {Opinion Mining from user reviews is an emerging field. Sentiment Analysis of Natural Language helps us in finding the opinion of the customers. These reviews can be in any language e.g. English, Chinese, Arabic, Japanese, Urdu, and Hindi. This research presents a model to classify the polarity of the review(s) in Roman Urdu (reviews). For the purpose, raw data was scraped from the reviews of 20 songs from Indo-Pak Music Industry. In this research a new dataset of 24000 reviews of Roman Urdu is created. Nine Machine Learning algorithms - Naïve Bayes, Support Vector Machine, Logistic Regression, K-Nearest Neighbors, Artificial Neural Networks, Convolutional Neural Network, Recurrent Neural Networks, ID3 and Gradient Boost Tree, are attempted. Logistic Regression outperformed the rest, based on testing and cross validation accuracies that are 92.25% and 91.47% respectively. © 2013 IEEE.},
	author_keywords = {ANN; classification; CNN; decision tree; deep learning; K-NN; machine learning; NaÃ¯ve Bayes; RNN; Roman Urdu; Roman Urdu corpus; Sentiment analysis; sentiment classification; song reviews; supervised learning},
	keywords = {Classification (of information); Data mining; Decision trees; Filtration; Learning algorithms; Music; Nearest neighbor search; Recurrent neural networks; Regression analysis; Support vector machines; ANN; Annotation; Benchmark testing; CNN; Deep learning; License; Machine-learning; Na&#x00ef;; RNN; Roman urdu; Roman urdu corpus; Sentiment analysis; Sentiment classification; Song review; Supervised learning; Text classification; Ve baye; Video; Sentiment analysis},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@CONFERENCE{Ganguly2022,
	author = {Ganguly, Srinjoy and Morapakula, Sai Nandan and Coronado, Luis Miguel Pozo},
	title = {Quantum Natural Language Processing Based Sentiment Analysis Using Lambeq Toolkit},
	year = {2022},
	journal = {ICPC2T 2022 - 2nd International Conference on Power, Control and Computing Technologies, Proceedings},
	doi = {10.1109/ICPC2T53885.2022.9776836},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132135105&doi=10.1109%2fICPC2T53885.2022.9776836&partnerID=40&md5=ac9caae32993906112cd43f0ad206cd2},
	abstract = {Sentiment classification is one of the best use cases of classical natural language processing (NLP). We witness its power in various domains such as banking, business, and the marketing industry. We already know how classical AI and machine learning can change and improve technology. Quantum natural language processing (QNLP) is a young and gradually emerging technology that can provide a quantum advantage for NLP tasks. In this paper, we show the first application of QNLP for sentiment analysis and achieve perfect test set accuracy for three different kinds of simulations and decent accuracy for experiments run on a noisy quantum device. We utilize the lambeq QNLP toolkit and t|ket > by Cambridge Quantum (Quantinuum) to produce the results.  © 2022 IEEE.},
	author_keywords = {lambeq; Quantum Computing; Quantum Natural Language Processing},
	keywords = {Learning algorithms; Quantum computers; Technology transfer; Emerging technologies; Lambeq; Language processing; Machine-learning; Natural languages; Power; Quantinuum computing; Quantinuum natural language processing; Sentiment analysis; Sentiment classification; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@ARTICLE{Bhagawati20234041,
	author = {Bhagawati, Rupam and Subramanian, Thiruselvan},
	title = {An approach of a quantum-inspired document ranking algorithm by using feature selection methodology},
	year = {2023},
	journal = {International Journal of Information Technology (Singapore)},
	volume = {15},
	number = {8},
	pages = {4041 – 4053},
	doi = {10.1007/s41870-023-01543-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173943879&doi=10.1007%2fs41870-023-01543-w&partnerID=40&md5=df15c3fb982e0ebb87a0e821d25eedea},
	abstract = {The main goal of an information retrieval system (IR) is ranking. Several methodologies were adopted with the integration of computing and advanced applied systems. However, traditional techniques have low stability, and machine learning techniques suffer from feature selection (FS) problems for exponentially growing data. This study speculates that combining quadratic unconstrained binary optimization (QUBO) with quantum annealing (QA) enhances the FS during the ranking process. QA is applied to reduce noisy and redundant data from the various state-of-the-art datasets in the field of IR. This study used the LETOR dataset. LETOR is divided into two versions: LETOR 3.0 (30,000 scientific documents) and LETOR 4.0 (more than 25 million documents). QA reveals the requisite quantum behavior in the findings using a processing unit known as the quantum processing unit (QPU). QPU addresses FS issues written as QUBO optimization problems successfully. The FS problem was QUBO formulated utilizing three quadratic models. A comparison was also made between the linear and QPU solvers employed in the ranking procedure. Quantum-based solutions outperform traditional methods in addressing ranking issues. Compared to the standard algorithms (LTR and LamdaMART), our suggested technique based on QA yields a normalized discounted cumulative gain of 0.39 and 0.80, respectively. QA can address real-world issues by offering practical solutions. QUBO and the QA process have improved feature selection for the ranking process. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.},
	author_keywords = {Feature selection; Information retrieval; Quantum annealer; Quantum computing; Ranking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Dalvi2022,
	author = {Dalvi, Ashwini and Shah, Vaishnavi and Gandhi, Dhruvin and Shah, Siddharth and Bhirud, S.G.},
	title = {Name Entity Recognition (NER) Based Drug Related Page Classification on Dark Web},
	year = {2022},
	journal = {2022 International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2022},
	doi = {10.1109/TQCEBT54229.2022.10041261},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149184125&doi=10.1109%2fTQCEBT54229.2022.10041261&partnerID=40&md5=c8dab7229ed4da2b330ab1decd04ca7e},
	abstract = {While researching the dark web marketplaces, it was observed that the drugs' names varied on different marketplaces. Therefore, the same drug might refer to different names on different dark web marketplaces. For example, some marketplaces use the chemical name or medical name as their product name to ensure the exact product; meanwhile, some marketplaces use the street name as the product name to attract users and get more orders. The present work discussed a NER based method to find if a website on the dark web has mentioned drugs. First, the dark web crawler crawled data from the dark web. Then, the authors introduced the Named Entity Recognition (NER) drug dataset with two categories of drug-named entities: Street name and Chemical name. Further, to identify drug-related web pages comprising street and chemical names of drugs with the NER model employed on scraped data. The proposed NER model was tested with the Drug-NER dataset. The DrugcrossNER project contains a predefined Drug-NER dataset with over 3500 listings from the dark web markets. The proposed work also generates a DRUG entity for the NER model in spaCy, an open-source NLP library in python, as it does not have the in-built ability to classify objects into custom categories.  © 2022 IEEE.},
	author_keywords = {Chemical names; Dark web; Drug marketplace; NER model; spaCy; Street names},
	keywords = {Commerce; Natural language processing systems; Web crawler; Chemical name; Dark web; Drug marketplace; Name entity recognition; Name entity recognition model; Named entity recognition; Product name; Recognition models; Spacy; Street name; Websites},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Bouakba2023407,
	author = {Bouakba, Yousra and Belhadef, Hacene},
	title = {Ensemble Learning Based Quantum Text Classifiers},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1850 CCIS},
	pages = {407 – 414},
	doi = {10.1007/978-3-031-42941-5_35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171979935&doi=10.1007%2f978-3-031-42941-5_35&partnerID=40&md5=9acec68d8e3cd947d3ee72a20c292dbc},
	abstract = {Quantum Natural Language Processing (QNLP) is a very young area of research, aimed at the design and implementation of NLP models that exploit certain quantum phenomena such as superposition, entanglement, and interference to perform language-related tasks on quantum hardware. To explore the structural relationships between quantum theory and natural languages Lambeq toolkit was created. This first high-level open-source Python toolkit for quantum natural language processing offers a fully automated quantum machine learning pipeline. Lambeq currently includes five compositional models that use varying degrees of syntactic information. While the previous studies focus on Discocat model, the aim of this study is to conducte an extensive evaluation of various classifiers based on different compositional models for text classification applications, focusing on the potential advantages of ensemble learning. The classifiers, including Spider, Cups, Stairs, Tree, and DisCoCat, were examined on two datasets: MC and RP. Performance evaluation was carried out using accuracy, precision, recall, and F1-score as the metrics. The results revealed notable variations in the performance of the classifiers across the datasets. Spider emerged as the top-performing classifier on the MC dataset, achieving remarkable scores of 100% in accuracy, precision, recall, and F1-score. However, on the RP dataset, Stairs outperformed the other classifiers with an accuracy of 68%, precision of 71%, recall of 68%, and F1-score of 69%. Furthermore, ensemble models using hard voting and soft voting techniques were constructed and evaluated. The ensemble models showcased improved performance compared to individual classifiers, with the soft voting ensemble achieving a score of 97% for all metrics on the MC dataset, and a precision of 72% and F1-score of 68% on the RP dataset. These findings highlight the potential benefits of ensemble learning in enhancing the overall performance of text classification tasks on both the MC and RP datasets using soft voting method, allowing for more accurate and reliable predictions. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Ensemble Learning; Quantum machine learning; Quantum natural language processing; Quantum Text Classifier},
	keywords = {Classification (of information); Computational linguistics; High level languages; Learning algorithms; Learning systems; Natural language processing systems; Quantum entanglement; Stairs; Text processing; Ensemble learning; F1 scores; Language processing; Machine-learning; Natural languages; Quantum machine learning; Quantum machines; Quantum natural language processing; Quantum text classifier; Text classifiers; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Li2023,
	author = {Li, Shuyue Stella and Zhang, Xiangyu and Zhou, Shu and Shu, Hongchao and Liang, Ruixing and Liu, Hexin and Garcia, Leibny Paola},
	title = {PQLM - Multilingual Decentralized Portable Quantum Language Model},
	year = {2023},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	volume = {2023-June},
	doi = {10.1109/ICASSP49357.2023.10095215},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177603456&doi=10.1109%2fICASSP49357.2023.10095215&partnerID=40&md5=3717a4b78e2b7a690c5bea3288ec2d17},
	abstract = {With careful manipulation, malicious agents can reverse engineer private information encoded in pre-trained language models. Security concerns motivate the development of quantum pre-training. In this work, we propose a highly portable quantum language model (PQLM) that can easily transmit information to downstream tasks on classical machines. The framework consists of a cloud PQLM built with random Variational Quantum Classifiers (VQC) and local models for downstream applications. We demonstrate the ad hoc portability of the quantum model by extracting only the word embeddings and effectively applying them to downstream tasks on classical machines. Our PQLM exhibits comparable performance to its classical counterpart on both intrinsic evaluation (loss, perplexity) and extrinsic evaluation (multilingual sentiment analysis accuracy) metrics. We also perform ablation studies on the factors affecting PQLM performance to analyze model stability. Our work establishes a theoretical foundation for a portable quantum pre-trained language model that could be trained on private data and made available for public use with privacy protection guarantees. © 2023 IEEE.},
	author_keywords = {Federated Learning; Language Modeling; Model Portability; Quantum Machine Learning},
	keywords = {Computational linguistics; Learning systems; Modeling languages; Decentralised; Down-stream; Federated learning; Language model; Machine-learning; Malicious agent; Model portability; Private information; Quantum machine learning; Quantum machines; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Lai2023,
	author = {Lai, Wei and Shi, Jinjing and Chang, Yan},
	title = {Quantum-Inspired Fully Complex-Valued Neutral Network for Sentiment Analysis},
	year = {2023},
	journal = {Axioms},
	volume = {12},
	number = {3},
	doi = {10.3390/axioms12030308},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151117512&doi=10.3390%2faxioms12030308&partnerID=40&md5=4a05f8f65165fe9d50e624164d6ecab0},
	abstract = {Most of the existing quantum-inspired models are based on amplitude-phase embedding to model natural language, which maps words into Hilbert space. In quantum-computing theory, the vectors corresponding to quantum states are all complex values, so there is a gap between these two areas. Presently, complex-valued neural networks have been studied, but their practical applications are few, let alone in the downstream tasks of natural language processing such as sentiment analysis and language modeling. In fact, the complex-valued neural network can use the imaginary part information to embed hidden information and can express more complex information, which is suitable for modeling complex natural language. Meanwhile, quantum-inspired models are defined in Hilbert space, which is also a complex space. So it is natural to construct quantum-inspired models based on complex-valued neural networks. Therefore, we propose a new quantum-inspired model for NLP, ComplexQNN, which contains a complex-valued embedding layer, a quantum encoding layer, and a measurement layer. The modules of ComplexQNN are fully based on complex-valued neural networks. It is more in line with quantum-computing theory and easier to transfer to quantum computers in the future to achieve exponential acceleration. We conducted experiments on six sentiment-classification datasets comparing with five classical models (TextCNN, GRU, ELMo, BERT, and RoBERTa). The results show that our model has improved by 10% in accuracy metric compared with TextCNN and GRU, and has competitive experimental results with ELMo, BERT, and RoBERTa. © 2023 by the authors.},
	author_keywords = {machine learning; natural language processing; quantum theory; sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access}
}

@CONFERENCE{Stein202320,
	author = {Stein, Jonas and Christ, Ivo and Kraus, Nicolas and Mansky, Maximilian Balthasar and Muller, Robert and Linnhoff-Popien, Claudia},
	title = {Applying QNLP to Sentiment Analysis in Finance},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Quantum Computing and Engineering, QCE 2023},
	volume = {2},
	pages = {20 – 25},
	doi = {10.1109/QCE57702.2023.10178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180007897&doi=10.1109%2fQCE57702.2023.10178&partnerID=40&md5=49fb8fe92f512fec05a5a559207b46f4},
	abstract = {As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat (Distributional Compositional Categorical) and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.  © 2023 IEEE.},
	author_keywords = {DisCoCat; Finance; QLSTM; QNLP; Quantum Computing; Sentiment Analysis},
	keywords = {Finance; Quantum computers; Applications domains; Case-studies; Data generation; Distributional compositional categorical; Language processing; Natural languages; Quantum Computing; Quantum natural language processing; Quantum-enhanced long short-term memory; Sentiment analysis; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Balthasar Mansky2023591,
	author = {Balthasar Mansky, Maximilian and Wörle, Franziska and Korbinian Stein, Jonas and Müller, Robert and Linnhoff-Popien, Claudia},
	title = {Adapting the DisCoCat-Model for Question Answering in the Chinese Language},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Quantum Computing and Engineering, QCE 2023},
	volume = {1},
	pages = {591 – 600},
	doi = {10.1109/QCE57702.2023.00073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180011302&doi=10.1109%2fQCE57702.2023.00073&partnerID=40&md5=31ca8a2f5d12c69c3f313f26ab58e1e4},
	abstract = {We introduce quantum natural language processing for the Chinese language. Our approach focuses on Question-answering on a set of sentences, whether a particular sentence is truthful with respect to the whole corpus of sentences. We employ the Categorical Distributional Compositional (DisCoCat) model to translate sentences to valid quantum circuits. We achieve a fitting score of 97% on the test set. Our sentence set is also significantly larger than previous experiments. The results show general applicability of the framework to other languages. We also show that it can be used to introspect natural language models and provide new approaches to model explainability. © 2023 IEEE.},
	author_keywords = {DisCoCat; Natural Language Processing; QNLP; Quantum Natural Language Processing},
	keywords = {Chinese language; Discocat; Language processing; Natural language processing; Natural languages; QNLP; Quantum natural language processing; Question Answering; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hou20222360,
	author = {Hou, Xiaokai and Yang, Yingli and Wang, Xiaoting},
	title = {Realization of Long Short-Term Memory Networks on Quantum Circuits},
	year = {2022},
	journal = {ASCC 2022 - 2022 13th Asian Control Conference, Proceedings},
	pages = {2360 – 2366},
	doi = {10.23919/ASCC56756.2022.9828335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135610164&doi=10.23919%2fASCC56756.2022.9828335&partnerID=40&md5=3f07501853ffd181b52b03c16542e1a7},
	abstract = {As one of the well-known methods to solve natural language processing (NLP) problems, the long short-term memory neural network (LSTM) has been designed to implement on quantum computers. However, existing method requires the number of qubits is equal to the dimension of the word vectors, and may result in a surge of the qubit number. To address this problem, we propose a duplication-free quantum long short-term memory neural network (DQLSTM). Specifically, our DQLSTM adopts the amplitude encoding method to store the classical information, and further can reduce the requirement for the number of qubits. Our numerical results show that our DQLSTM has similar effectiveness to the classical counterpart in a Chinese sentiment analysis task, and outperforms several previous proposals in the same task.  © 2022 ACA.},
	author_keywords = {Natural language processing; Quantum long short-term memory neural network; Quantum machine learning},
	keywords = {Brain; Learning algorithms; Long short-term memory; Qubits; Sentiment analysis; Language processing; Machine-learning; Memory network; Natural language processing; Natural languages; Neural-networks; Quantum circuit; Quantum long short-term memory neural network; Quantum machine learning; Quantum machines; Timing circuits},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Shi20234335,
	author = {Shi, Jinjing and Li, Zhenhuan and Lai, Wei and Li, Fangfang and Shi, Ronghua and Feng, Yanyan and Zhang, Shichao},
	title = {Two End-to-End Quantum-Inspired Deep Neural Networks for Text Classification},
	year = {2023},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {35},
	number = {4},
	pages = {4335 – 4345},
	doi = {10.1109/TKDE.2021.3130598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149914672&doi=10.1109%2fTKDE.2021.3130598&partnerID=40&md5=25f7d8208b3d3e95680e275065911231},
	abstract = {In linguistics, the uncertainty of context due to polysemy is widespread, which attracts much attention. Quantum-inspired complex word embedding based on Hilbert space plays an important role in natural language processing (NLP), which fully leverages the similarity between quantum states and word tokens. A word containing multiple meanings could correspond to a single quantum particle which may exist in several possible states, and a sentence could be analogous to the quantum system where particles interfere with each other. Motivated by quantum-inspired complex word embedding, interpretable complex-valued word embedding (ICWE) is proposed to design two end-to-end quantum-inspired deep neural networks (ICWE-QNN and CICWE-QNN representing convolutional complex-valued neural network based on ICWE) for binary text classification. They have the proven feasibility and effectiveness in the application of NLP and can solve the problem of text information loss in CE-Mix [1] model caused by neglecting the important linguistic features of text, since linguistic feature extraction is presented in our model with deep learning algorithms, in which gated recurrent unit (GRU) extracts the sequence information of sentences, attention mechanism makes the model focus on important words in sentences and convolutional layer captures the local features of projected matrix. The model ICWE-QNN can avoid random combination of word tokens and CICWE-QNN fully considers textual features of the projected matrix. Experiments conducted on five benchmarking classification datasets demonstrate our proposed models have higher accuracy than the compared traditional models including CaptionRep BOW, DictRep BOW and Paragram-Phrase, and they also have great performance on F1-score. Eespecially, CICWE-QNN model has higher accuracy than the quantum-inspired model CE-Mix as well for four datasets including SST, SUBJ, CR and MPQA. It is a meaningful and effictive exploration to design quantum-inspired deep neural networks to promote the performance of text classification.  © 1989-2012 IEEE.},
	author_keywords = {Complex-valued word embedding; deep learning; deep neural network; natural language processing; text classification},
	keywords = {Benchmarking; Classification (of information); Complex networks; Convolution; Embeddings; Linguistics; Natural language processing systems; Quantum optics; Text processing; Complex-valued; Complex-valued word embedding; Deep learning; Embeddings; End to end; Language processing; Linguistic features; Natural language processing; Natural languages; Text classification; Deep neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Singh2023,
	author = {Singh, Jaiteg and Bhangu, Kamalpreet Singh},
	title = {Quantifying emotions through quantum computations},
	year = {2023},
	journal = {International Journal of Quantum Information},
	volume = {21},
	number = {3},
	doi = {10.1142/S0219749923500041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151913154&doi=10.1142%2fS0219749923500041&partnerID=40&md5=7c7760024d42bc109d395bdc39f32f0d},
	abstract = {Quantum computations are extensively used to solve challenging problems and emotion detection is one such field that has lot of potential to be explored. Classical studies can identify emotions but fail to observe their intensities at such minute level. The proposed research primarily intends to quantify the intensities related with happy and sad emotions on a quantum computer examining subjects within Amsterdam Dynamic Facial Expression Set (ADFES) dataset. Leveraging quantum ability to compute quantum state fidelity established closeness of the encoded states. We used quantum variational classifier technique for this experiment performed on the quantum simulator available on the IBM Quantum Experience platform.  © 2023 World Scientific Publishing Company.},
	author_keywords = {Emotion quantification; quantum computation; quantum machine learning; sentiment analysis},
	keywords = {Machine learning; Quantum computers; Quantum theory; Amsterdam; Dynamic facial expression; Emotion detection; Emotion quantification; Machine-learning; Problem detection; Quanta computers; Quantum machine learning; Quantum machines; Sentiment analysis; Sentiment analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sun2023,
	author = {Sun, Haoran and Zou, Jie and Li, Xiaopeng},
	title = {Fermion sampling made more efficient},
	year = {2023},
	journal = {Physical Review B},
	volume = {107},
	number = {3},
	doi = {10.1103/PhysRevB.107.035119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146329318&doi=10.1103%2fPhysRevB.107.035119&partnerID=40&md5=aecb9cd50f88a6e7f2b7ac17c36bd179},
	abstract = {Fermion sampling is to generate probability distribution of a many-body Slater-determinant wave function, which is termed "determinantal point process"in statistical analysis. For its inherently embedded Pauli exclusion principle, its application reaches beyond simulating fermionic quantum many-body physics to constructing machine learning models for diversified datasets. Here we propose a fermion sampling algorithm, which has a polynomial time complexity - quadratic in the fermion number and linear in the system size. This algorithm is about 100% more efficient in computation time than the best known algorithms. In sampling the corresponding marginal distribution, our algorithm has a more drastic improvement, achieving a scaling advantage. We demonstrate its power on several test applications, including sampling fermions in a many-body system and a machine learning task of text summarization, and confirm its improved computation efficiency over other methods by counting floating-point operations.  © 2023 American Physical Society.},
	keywords = {Computational efficiency; Digital arithmetic; Machine learning; Polynomial approximation; Probability distributions; Wave functions; ITS applications; Machine learning models; Many body; Pauli exclusion principle; Point process; Polynomial time complexity; Probability: distributions; Sampling algorithm; Slater determinants; System size; Sampling},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Mehta2022234,
	author = {Mehta, Kusum and Panda, Supriya P.},
	title = {Sentiment Analysis on E-Commerce Apparels using Convolutional Neural Network},
	year = {2022},
	journal = {International Journal of Computing},
	volume = {21},
	number = {2},
	pages = {234 – 241},
	doi = {10.47839/ijc.21.2.2592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133548393&doi=10.47839%2fijc.21.2.2592&partnerID=40&md5=4f6cb1376a5b3a178e6abc5a1b05ef56},
	abstract = {The Fourth Industrial Revolution (4.0) is a fusion of advances in Artificial Intelligence (AI), Robotics, the Internet of Things (IoT), Genetic Engineering, Quantum Computing, and other technologies. A large number of people are using internet-based services as a result of enhanced internet infrastructure and decreased costs. As a result, such businesses' attempts to penetrate internet media are disrupted. The e-commerce company, like Amazon, offers both customer-to-customer and business-to-business services in the apparel sector. Companies must understand the needs of buyers to maximize their profits. As a result, consumer sentiment analysis is carried out. However, because this procedure is time-consuming, it is made automatically utilizing artificial intelligence approaches. According to the findings of a study on sentiment analysis on an E-Commerce-based web store for women, the apparels review dataset using the CNN method with the word vector generator and TF-IDF can produce a higher accuracy of 94%. © 2022. International Journal of Computing.All Rights Reserved},
	author_keywords = {Convolutional neural networks; Deep learning; Long short term memory (lstm); Sentiment analysis; Term frequency – inverse document frequency (tf-idf).; Word2vec},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Coecke2022277,
	author = {Coecke, Bob and de Felice, Giovanni and Meichanetzidis, Konstantinos and Toumi, Alexis},
	title = {How to make qubits speak},
	year = {2022},
	journal = {Quantum Computing in the Arts and Humanities: An Introduction to Core Concepts, Theory and Applications},
	pages = {277 – 297},
	doi = {10.1007/978-3-030-95538-0_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158832268&doi=10.1007%2f978-3-030-95538-0_8&partnerID=40&md5=37f22036d9b369d73a5fa8eed47e76c6},
	abstract = {This is a story about making quantum computers speak, and doing so in a quantum-native, compositional and meaning-aware manner. Recently we did question-answering with an actual quantum computer. We explain what we did, stress that this was all done in terms of pictures, and provide many pointers to the related literature. In fact, besides natural language, many other things can be implemented in a quantum-native, compositional and meaning-aware manner, and we provide the reader with some indications of that broader pictorial landscape, including our account on the notion of compositionality. We also provide some guidance for the actual execution, so that the reader can give it a go as well. © Springer Nature Switzerland AG 2022.},
	author_keywords = {Compositionality; DisCoPy software; Quantum natural language processing; String diagrams; ZX-calculus},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Chan202346,
	author = {Chan, Ka-Hou and Im, Sio-Kei},
	title = {An Investigation of Multilayer RNNs in Sentiment Analysis},
	year = {2023},
	journal = {Proceedings - 2023 3rd International Conference on Engineering Education and Information Technology, EEIT 2023},
	pages = {46 – 50},
	doi = {10.1109/EEIT58928.2023.00019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190644244&doi=10.1109%2fEEIT58928.2023.00019&partnerID=40&md5=715e99251859499387423b50ac1a0204},
	abstract = {Recurrent Neural Network (RNN) is one of the most powerful deep learning architectures and is commonly used to process various sequential input features, such as video sequences and natural sentence. It outperforms in solving some tasks of Neural Language Processing (NLP) about the sentiment analyse. RNN models have the advantage of allowing to receive data recurrently and extract the main information from the feature encoding of the previous time steps. In this work, there are four types of RNN's units have been analysed, including the Linear RNN, Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU) and Content-Adaptive Recurrent Unit (CARU). The implementation of all these units on multilayer RNN architectures is investigated, and their performance is tested on two benchmark sentiment analysis datasets: IMDB and SST2. The complete source code and experimental results are also provided for future study. © 2023 IEEE.},
	author_keywords = {CARU; GRU; LSTM; NLP; RNN; Sentiment Analysis},
	keywords = {Benchmarking; Long short-term memory; Multilayer neural networks; Multilayers; Network architecture; Content-adaptive; Content-adaptive recurrent unit; Gated recurrent unit; Input features; Language processing; Learning architectures; Neural language processing; Recurrent neural network model; Sentiment analysis; Video sequences; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rath2022,
	author = {Rath, Asutosh and Hridaya, B. and Vimala, Duggaraju and George, Jossy},
	title = {Multilingual Sentiment Analysis of YouTube Live Stream using Machine Translation and Transformer in NLP},
	year = {2022},
	journal = {2022 International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2022},
	doi = {10.1109/TQCEBT54229.2022.10041483},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149181876&doi=10.1109%2fTQCEBT54229.2022.10041483&partnerID=40&md5=c2ee75dbb4a945fc04234e7ab49d14e4},
	abstract = {YouTube has become one of the all-inclusive video streaming sources on the internet. Today, the news is streamed on YouTube, marketing of a product is done live on YouTube and it has become a platform for one of the biggest PR producers for companies. Various companies have proposed an optimized way of understanding and getting the opinions of the viewers from YouTube live chat and find the best possible way to provide relevant and informative content to boost the business strategy. This study uses Natural Language Processing (NLP) based approach along with NLP transformers to classify and analyses the sentiment.  © 2022 IEEE.},
	author_keywords = {live chat; live stream; multilingual; sentiment analysis; transformer; YouTube},
	keywords = {Language processing; Live chat; Live stream; Machine translations; Multilingual; Natural languages; Sentiment analysis; Transformer; Video-streaming; YouTube; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Pandey2023,
	author = {Pandey, Shyambabu and Basisth, Nihar Jyoti and Sachan, Tushar and Kumari, Neha and Pakray, Partha},
	title = {Quantum machine learning for natural language processing application},
	year = {2023},
	journal = {Physica A: Statistical Mechanics and its Applications},
	volume = {627},
	doi = {10.1016/j.physa.2023.129123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168426556&doi=10.1016%2fj.physa.2023.129123&partnerID=40&md5=d12d9fbf5f8399314592fc6be2d06b01},
	abstract = {Quantum computing is a speedily emerging area that applies quantum mechanics properties to solve complex problems that are difficult for classical computing. Machine learning is a sub-field of artificial intelligence which makes computers learn patterns from experiences. Due to the exponential growth of data, machine learning algorithms may be insufficient for big data, whereas on other side quantum computing can do fast computing. A combination of quantum computing and machine learning gave rise to a new field known as quantum machine learning. Quantum machine learning algorithms take advantage of the fast processing of quantum computing and show speedup compared to their classical counterpart. Natural language processing is another area of artificial intelligence that enables the computer to understand human languages. Now, researchers are trying to take advantage of quantum machine learning speedup in natural language processing applications. In this paper, first, we discuss the path from quantum computing to quantum machine learning. Then we review the state of the art of quantum machine learning for natural language processing applications. We also provide classical and quantum-based long short-term memory for parts of speech tagging on social media code mixed language. Our experiment shows that quantum-based long short-term memory performance is better than classical long short-term memory for parts of speech tagging of code-mixed datasets. © 2023 Elsevier B.V.},
	author_keywords = {Natural language processing; POS tagging; Quantum computing; Quantum machine learning},
	keywords = {Brain; Codes (symbols); Computational linguistics; Long short-term memory; Natural language processing systems; Quantum computers; Quantum theory; Syntactics; Language processing; Machine learning algorithms; Machine-learning; Natural language processing; Natural language processing applications; Natural languages; POS tagging; Quantum Computing; Quantum machine learning; Quantum machines; Learning algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@ARTICLE{Katyayan2023457,
	author = {Katyayan, Pragya and Joshi, Nisheeth},
	title = {Implications of Deep Circuits in Improving Quality of Quantum Question Answering},
	year = {2023},
	journal = {Studies in Computational Intelligence},
	volume = {1085},
	pages = {457 – 479},
	doi = {10.1007/978-981-19-9530-9_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152007268&doi=10.1007%2f978-981-19-9530-9_23&partnerID=40&md5=ca5971c0d9d5808be24558b5ecb8751a},
	abstract = {Question Answering (QA) has proved to be an arduous challenge in the area of natural language processing (NLP) and artificial intelligence (AI). Many attempts have been made to develop complete solutions for QA as well as improving significant sub-modules of the QA systems to improve the overall performance through the course of time. Questions are the most important piece of QA, because knowing the question is equivalent to knowing what counts as an answer (Harrah in Philos Sci 28:40–46, 1961, [1]). In this work, we have attempted to understand questions in a better way by using Quantum Machine Learning (QML). The properties of Quantum Computing (QC) have enabled classically intractable data processing. So, in this paper, we have performed question classification on questions from two classes of SelQA (Selection-based Question Answering) dataset using quantum-based classifier algorithms—quantum support vector machine (QSVM) and variational quantum classifier (VQC) from Qiskit (Quantum Information Science toolKIT) for Python. We perform classification with both classifiers in almost similar environments and study the effects of circuit depths while comparing the results of both classifiers. We also use these classification results with our own rule-based QA system and observe significant performance improvement. Hence, this experiment has helped in improving the quality of QA in general. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Quantum computing; Quantum natural language processing; Quantum support vector machines; Question answering; Question classification; Variational quantum classifier},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Ruskanda202267,
	author = {Ruskanda, Fariska Z. and Rifat Abiwardani, Muhammad and Al Bari, Muhammad Akram and Arya Bagaspati, Kinantan and Mulyawan, Rahmat and Syafalni, Infall and Larasati, Harashta Tatimma},
	title = {Quantum Representation for Sentiment Classification},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Quantum Computing and Engineering, QCE 2022},
	pages = {67 – 78},
	doi = {10.1109/QCE53715.2022.00025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143623740&doi=10.1109%2fQCE53715.2022.00025&partnerID=40&md5=4b5f1c2d50dff21e7f41ec6b5ec2123f},
	abstract = {While the application of quantum computing to natural language processing (NLP) has seen substantial work in recent years, not much has been presented on sentiment analysis to systematically identify, extract, quantify, and study affective states and subjective information. This preliminary study investigates how sentiment can be represented correctly and efficiently for quantum natural language processing (QNLP). In particular, we present four possible approaches for representing sentiment words in the quantum case. We propose to utilize two quantum operations (i.e., X gate and Z-X gate), each with two different placements, to represent a negative sentence in a quantum circuit. Subsequently, we train the corresponding state vector using several classical classifiers: SVM, SPSA, and a combination of both, then evaluate the result in terms of accuracy. Experimental results show that the third approach, i.e., adding an X-gate at the end of the sentence outperforms other settings. Additionally, the third approach, along with the combined classifier of SVM and SPSA, reaches up to 81.67% accuracy. The proposed method can be helpful for applications of sentiment analysis in quantum computers.  © 2022 IEEE.},
	author_keywords = {quantum representation; sentiment classification; SPSA; SVM},
	keywords = {Optimization; Quantum computers; Quantum theory; Support vector machines; Affective state; Language processing; Natural languages; Quantum Computing; Quantum representation; Sentiment analysis; Sentiment classification; SPSA; State information; SVM; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Bishwas2022,
	author = {Bishwas, Arit Kumar and Mani, Ashish and Palade, Vasile},
	title = {Parts of Speech Tagging in NLP- an Investigation on Runtime Optimization with Quantum Formulation and ZX Calculus},
	year = {2022},
	journal = {2022 International Conference for Advancement in Technology, ICONAT 2022},
	doi = {10.1109/ICONAT53423.2022.9725821},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127555846&doi=10.1109%2fICONAT53423.2022.9725821&partnerID=40&md5=4ef643450552a648e05364bfe76b855f},
	abstract = {This paper presents an optimized formulation of the parts of speech tagging in Natural Language Processing (NLP) with a quantum computing approach, and it further demonstrates the quantum gate-level runnable optimization with ZX-calculus, keeping the implementation target in the context of Noisy Intermediate Scale Quantum Systems (NISQ). The discussed quantum formulation exhibits quadratic speed up over the classical counterpart and further demonstrates the implementable optimization with the help of ZX calculus postulates.  © 2022 IEEE.},
	author_keywords = {Natural Language Processing; Noisy Intermediate Scale Quantum Systems (NISQ); Quantum Algorithms; Quantum Optimization},
	keywords = {Calculations; Computational linguistics; Natural language processing systems; Quantum computers; Noisy intermediate scale quantum system; Optimisations; Part of speech tagging; Parts-of-speech tagging; Quantum algorithms; Quantum Computing; Quantum gates; Quantum optimization; Quantum system; Runtime optimization; Quantum optics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Mojrian2021,
	author = {Mojrian, Mohammad and Mirroshandel, Seyed Abolghasem},
	title = {A novel extractive multi-document text summarization system using quantum-inspired genetic algorithm: MTSQIGA},
	year = {2021},
	journal = {Expert Systems with Applications},
	volume = {171},
	doi = {10.1016/j.eswa.2020.114555},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100158708&doi=10.1016%2fj.eswa.2020.114555&partnerID=40&md5=3ce8708594e430ec5ecd998990b2ceac},
	abstract = {The explosive growth of textual data on the web and the problem of obtaining desired information through this enormous volume of data has led to a dramatic increase in demand for developing automatic text summarization systems. For this reason, this paper presents a novel multi-document text summarization approach, called MTSQIGA, which extracts salient sentences from source document collection to generate the summary. The proposed generic summarizer models extractive summarization as a binary optimization problem that applies a modified quantum-inspired genetic algorithm (QIGA) in its processing stage to find the best solution. Objective function of our approach plays an important role in optimizing linear combination of coverage, relevance, and redundancy factors which consists of six sentence scoring measures. To ensures the generation of a summary with predefined length limit, the presented QIGA employs a modified quantum measurement and a self-adaptive quantum rotation gate based on the quality and length of the summary. Evaluation of the proposed system was performed on DUC 2005 and 2007 benchmark datasets in terms of ROUGE standard measures. Comparison of MTSQIGA with existing state-of-the-art approaches for multi-document summarization shows superior performance of the proposed systems over other methods on both existing benchmark datasets. It also indicates promising efficiency of our proposed algorithm on applying quantum-inspired genetic algorithm to the text summarization tasks. © 2020 Elsevier Ltd},
	author_keywords = {Extractive summarization; Multi-document summarization; Objective function; Quantum measurement; Quantum-inspired genetic algorithm; Self-adaptive rotation gate},
	keywords = {Benchmarking; Text processing; Automatic text summarization; Document collection; Extractive summarizations; Linear combinations; Multi-document summarization; Quantum inspired genetic algorithm; Quantum measurement; State-of-the-art approach; Genetic algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@ARTICLE{Silvestri2023,
	author = {Silvestri, Stefano and Gargiulo, Francesco and Ciampi, Mario},
	title = {Integrating PubMed Label Hierarchy Knowledge into a Complex Hierarchical Deep Neural Network †},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {24},
	doi = {10.3390/app132413117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192495572&doi=10.3390%2fapp132413117&partnerID=40&md5=45057296e17138a557480808f86a43e6},
	abstract = {This paper proposes an innovative method that exploits a complex deep learning network architecture, called Hierarchical Deep Neural Network (HDNN), specifically developed for the eXtreme Multilabel Text Classification (XMTC) task, when the label set is hierarchically organized, such as the case of the PubMed article labeling task. In detail, the topology of the proposed HDNN architecture follows the exact hierarchical structure of the label set to integrate this knowledge directly into the DNN. We assumed that if a label set hierarchy is available, as in the case of the PubMed Dataset, forcing this information into the network topology could enhance the classification performances and the interpretability of the results, especially related to the hierarchy. We performed an experimental assessment of the PubMed article classification task, demonstrating that the proposed HDNN provides performance improvement for a baseline based on a classic flat Convolution Neural Network (CNN) deep learning architecture, in particular in terms of hierarchical measures. These results provide useful hints for integrating previous and innate knowledge in a deep neural network. The drawback of the HDNN is the high computational time required to train the neural network, which can be addressed with a parallel implementation planned as a future work. © 2023 by the authors.},
	author_keywords = {BioBERT; extreme multilabel text classification; hierarchical deep neural network; natural language processing; PubMed MeSH},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Pandey2022,
	author = {Pandey, Shyambabu and Dadure, Pankaj and Nunsanga, Morrel V. L. and Pakray, Partha},
	title = {Parts of speech tagging towards classical to quantum computing},
	year = {2022},
	journal = {Proceedings - 2022 IEEE Silchar Subsection Conference, SILCON 2022},
	doi = {10.1109/SILCON55242.2022.10028796},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147856737&doi=10.1109%2fSILCON55242.2022.10028796&partnerID=40&md5=43c9502f55fc7ecd6eaeb1d628ef2a12},
	abstract = {Quantum computing is a fast-emerging field that follows the laws of quantum mechanics to solve complex problems for classical systems. In the last few years, several researchers have emerged in quantum computing in accordance with the artificial intelligence field. Natural language processing is one of the prominent subfields of artificial intelligence. Quantum computing can be applied to the applications of natural language processing for better performance. One of the vital applications of natural language processing is Parts-Of-Speech (POS) tagging. It is prerequired for many natural language processing applications. In this paper, we have performed POS tagging of the Mizo language using classical Long short-term memory (LSTM). Subsequently, quantum-enhanced long short-term memory (QLSTM) has also been used to perform POS tagging of the Mizo language. The approaches mentioned above have been tested on the Mizo-tagged corpus, and experimental results have shown that quantum computing approaches such as QLSTM need the inclusion of new technologies to achieve significant results.  © 2022 IEEE.},
	author_keywords = {Natural language processing; POS tagging; Quantum computing; Quantum machine learning},
	keywords = {Brain; Computational linguistics; Learning algorithms; Natural language processing systems; Quantum computers; Syntactics; Complex problems; Language processing; Machine-learning; Natural language processing; Natural languages; Part of speech tagging; Parts-of-speech tagging; Quantum Computing; Quantum machine learning; Quantum machines; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Mohammad Masum20231006,
	author = {Mohammad Masum, Abu Kaisar and Maurya, Anshul and Murthy, Dhruthi Sridhar and Pratibha and Mahmud, Naveed},
	title = {Hybrid Quantum-Classical Machine Learning for Sentiment Analysis},
	year = {2023},
	journal = {Proceedings - 22nd IEEE International Conference on Machine Learning and Applications, ICMLA 2023},
	pages = {1006 – 1011},
	doi = {10.1109/ICMLA58977.2023.00149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190094770&doi=10.1109%2fICMLA58977.2023.00149&partnerID=40&md5=1c051d575a8f54ff195ebb6c294fbdbb},
	abstract = {The collaboration between quantum computing and classical machine learning offers potential advantages in natural language processing, particularly in the sentiment analysis of human emotions and opinions expressed in large-scale datasets. In this work, we propose a methodology for sentiment analysis using hybrid quantum-classical machine learning algorithms. We investigate quantum kernel approaches and variational quantum circuit-based classifiers and integrate them with classical dimension reduction techniques such as PCA and Haar wavelet transform. The proposed methodology is evaluated using two distinct datasets, based on English and Bengali languages. Experimental results show that after dimensionality reduction of the data, performance of the quantum-based hybrid algorithms were consistent and better than classical methods. © 2023 IEEE.},
	author_keywords = {Haar Transform; Quantum Machine Learning; Sentiment Analysis; SVM},
	keywords = {Large datasets; Learning algorithms; Quantum computers; Sentiment analysis; Support vector machines; Haar transform; Language processing; Machine-learning; Natural languages; Quantum Computing; Quantum machine learning; Quantum machines; Quantum-classical; Sentiment analysis; SVM; Wavelet transforms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Chandrasekaran2023104,
	author = {Chandrasekaran, Sriramakrishnan and Dutt, Vishal and Vyas, Narayan and Kumar, Raj},
	title = {Student Sentiment Analysis Using Various Machine Learning Techniques},
	year = {2023},
	journal = {2023 International Conference on Artificial Intelligence and Smart Communication, AISC 2023},
	pages = {104 – 107},
	doi = {10.1109/AISC56616.2023.10085018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153508200&doi=10.1109%2fAISC56616.2023.10085018&partnerID=40&md5=0d25762b00c526471b3c7f78548c9dfc},
	abstract = {In terms of social, psychological, physical, technological, and other elements, the educational system is undergoing significant transformation. Today, education is becoming a joint venture between the state, the market, and the community. Alternative education and training providers that place a greater emphasis on employability provide a problem, and university professors represent a particular breed of career academics that remain cut off from developments in the outside world. The sentiment analysis of student comments is presented in this work using a combination of Methodologies based on lexicons and machine learning. The textual feedback, which is often gathered around the conclusion of a semester, offers helpful insights into the general quality of teaching and makes insightful recommendations for ways to enhance instructional design. The article describes a sentiment analysis model trained using TF-IDF and linguistic characteristics to look at the opinions expressed by participants in their textual feedback. Additionally, a comparison among the existing sentiment analysis techniques is done.  © 2023 IEEE.},
	author_keywords = {Feedback; Lexicon; Sentiment; SVM},
	keywords = {Education computing; Students; Support vector machines; Education and training; Educational systems; Joint ventures; Lexicon; Machine learning techniques; Machine-learning; Sentiment; Sentiment analysis; SVM; Training providers; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@ARTICLE{Singh20211,
	author = {Singh, Siddhant and Deepak, Gerard},
	title = {Towards a Knowledge Centric Semantic Approach for Text Summarization},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {290},
	pages = {1 – 9},
	doi = {10.1007/978-981-16-4486-3_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115102467&doi=10.1007%2f978-981-16-4486-3_1&partnerID=40&md5=49c8e8fc14afa17ca6d3eecc8a7a0223},
	abstract = {Text Summarization is one of the important process for extracting important data from a text document. In the proposed method, the useful text or data collected is obtained as abridged form of the document and it is provided to the user as summary. In this current world where there is almost limitless information online, we must understand what data and its context is relevant to our objective for a certain task. As the enormous information is getting collected on the internet, it is a tedious and a challenging task and to go through the accessible information on the Web. This paper proposes a knowledge centric approach for text summarization. The dataset used for training this system is the DUC 2007 which contains manually created summaries, automatic baseline summaries and additional supporting data with results, documents etc. which is combined with TF-IDF algorithm. A domain-based ontology is created in addition Cross Entropy and Normalized Point Wise Mutual Information and ANOVA Normalized Point Wise Mutual Information is calculated based on which the sentences are grouped and eliminated. The proposed approach is superior in terms of performance and recorded F-Measure and False Negative Rate is 88.20% and 0.14 respectively © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {ANOVA-NPMI; Cross Entropy; Text summarization; TF-IDF},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Walter2022,
	author = {Walter, Lothar and Denter, Nils M. and Kebel, Jan},
	title = {A review on digitalization trends in patent information databases and interrogation tools},
	year = {2022},
	journal = {World Patent Information},
	volume = {69},
	doi = {10.1016/j.wpi.2022.102107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126660774&doi=10.1016%2fj.wpi.2022.102107&partnerID=40&md5=28cad79dc94685f7d67b2c9bcc9ffa89},
	abstract = {Digitalization is a strong driver in society, business, and science. Patent management, especially the search for and analysis of patents, is also being shaped by digitalization advances. Unlike prior studies – which mainly focus on the purposes and methods used for patent search and analysis –, this review focuses on the underlying digitalization trends that have become mainstream in the landscape of providers’ patent information databases and interrogation tools. By analyzing seven public and 20 commercial providers, a total of 15 different digitalization trends are outlined. Public providers specifically focus on trends for patent search, e.g. machine translation, while commercial providers rather focus on more sophisticated trends for patent analysis, e.g. predictive analytics. All of the 15 identified trends point toward four digitalization domains that were discerned by means of a hybrid coding approach, namely cloud computer technology, data management, data analytics, and artificial intelligence. Conclusively, tensions that are caused by the progress of these trends are discussed, e.g. the seamless transition from search to analysis versus less explainability. © 2022 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Cloud computer technology; Data analytics; Data management; Digitalization; Patent search and analysis},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Yawalkar2022,
	author = {Yawalkar, Prajakta and Birari, Abhijeet and Bharathan, Gayathri and Vakayil, Sunil and Sharma, Rohit},
	title = {Subscriber Preference and Content Consumption Pattern toward OTT platform: An Opinion Mining},
	year = {2022},
	journal = {2022 International Conference on Trends in Quantum Computing and Emerging Business Technologies, TQCEBT 2022},
	doi = {10.1109/TQCEBT54229.2022.10041265},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149179432&doi=10.1109%2fTQCEBT54229.2022.10041265&partnerID=40&md5=9193960b1846666a5b6cdcc17bb8624f},
	abstract = {Introduction: The outburst of the pandemic has paved the way for the immense popularity of over-The-Top (OTT) platforms among viewers. Furnishing an alternate medium to watch favorite shows and making it a new normal, the OTT platform has replaced the traditional entertainment platform. However, migrating from traditional television to an OTT platform is still a challenge in developing countries. Hence, the understanding of subscriber preferences and content consumption patterns becomes essential to planning and strategizing future business models. Purpose: The purpose of the paper is to examine the subscriber preference and content consumption pattern toward the OTT platform. In addition, this paper also investigates the popularity of leading OTT platforms among Indian viewers. Methodology: Data has been collected from the subscribers of three major OTT: Amazon Prime, Netflix Video, and Disney+Disney+Hotstar. A total of 1860 reviews were scraped as textual data and analyzed using the lexicon-based method. The polarity of the sentiments pertaining to the reviews of different platforms was analyzed using sentiment analysis. Furthermore, the topic modeling on the reviews was performed using natural language programming(NLP). Findings: The findings of sentiment analysis showed that Netflix and Disney+Disney+Hotstar had a considerable number of positive sentiments among viewers when compared to Amazon Prime Video. Eventually, the paper also showed negative sentiment towards Amazon Prime Video regarding streaming content, ad pop-ups, interface issue, shows, etc. Our findings help OTT platforms to determine which factors are driving this dramatic shift in viewer behaviour so that better strategies for attracting and retaining subscribers can be developed. Despite the rise in OTT platform popularity, this is the first study to investigate the content consumption pattern of OTT viewers comprehensively.  © 2022 IEEE.},
	author_keywords = {Content Consumption Pattern; OTT platform; Sentiment Analysis; Subscriber Preference},
	keywords = {Developing countries; Modeling languages; Business models; Consumption patterns; Content consumption; Content consumption pattern; Netflix; Opinion mining; Over-the-top platform; Sentiment analysis; Subscriber preference; Textual data; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Payares202369,
	author = {Payares, Esteban and Puertas, Edwin and Martinez-Santos, Juan C.},
	title = {Quantum N-Gram Language Models for Tweet Classification},
	year = {2023},
	journal = {Proceedings - 2023 IEEE 5th International Conference on Cognitive Machine Intelligence, CogMI 2023},
	pages = {69 – 74},
	doi = {10.1109/CogMI58952.2023.00019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186499263&doi=10.1109%2fCogMI58952.2023.00019&partnerID=40&md5=8707a1bf5f064f56e02266ab3db31f51},
	abstract = {This paper presents a novel approach to text classification using n-grams and quantum machine learning models. We demonstrate the effectiveness of our approach by applying it to classify tweets, a challenging and noisy text classification task. Specifically, we show that using quantum models can significantly improve classification performance compared to classical ones. Additionally, we leverage quantum hardware to compute higher-order n-grams (more than bi-grams) and observe a boost in computation performance. Our experimental results demonstrate the potential of quantum computing for text classification tasks and pave the way for further exploration of quantum machine learning methods in natural language processing.  © 2023 IEEE.},
	author_keywords = {n-grams; natural language processing; quantum computing; quantum machine learning},
	keywords = {Computational linguistics; Learning algorithms; Machine learning; Natural language processing systems; Quantum computers; Text processing; Classification tasks; Language processing; Machine-learning; N-grams; Natural language processing; Natural languages; Quantum Computing; Quantum machine learning; Quantum machines; Text classification; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang20228602,
	author = {Yang, Chao-Han Huck and Qi, Jun and Chen, Samuel Yen-Chi and Tsao, Yu and Chen, Pin-Yu},
	title = {WHEN BERT MEETS QUANTUM TEMPORAL CONVOLUTION LEARNING FOR TEXT CLASSIFICATION IN HETEROGENEOUS COMPUTING},
	year = {2022},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	volume = {2022-May},
	pages = {8602 – 8606},
	doi = {10.1109/ICASSP43922.2022.9746412},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131259735&doi=10.1109%2fICASSP43922.2022.9746412&partnerID=40&md5=6a14e5fc2d9393978bed33b4cf6372a4},
	abstract = {The rapid development of quantum computing has demonstrated many unique characteristics of quantum advantages, such as richer feature representation and more secured protection on model parameters. This work proposes a vertical federated learning architecture based on variational quantum circuits to demonstrate the competitive performance of a quantum-enhanced pre-trained BERT model for text classification. In particular, our proposed hybrid classical-quantum model consists of a novel random quantum temporal convolution (QTC) learning framework replacing some layers in the BERT-based decoder. Our experiments on intent classification show that our proposed BERT-QTC model attains competitive experimental results in the Snips and ATIS spoken language datasets. Particularly, the BERT-QTC boosts the performance of the existing quantum circuit-based language model in two text classification datasets by 1.57% and 1.52% relative improvements. Furthermore, BERT-QTC can be feasibly deployed on both existing commercial-accessible quantum computation hardware and CPU-based interface for ensuring data isolation. © 2022 IEEE},
	author_keywords = {heterogeneous computing; Quantum machine learning; spoken language understanding; temporal convolution; text classification},
	keywords = {Classification (of information); Learning systems; Machine learning; Quantum computers; Text processing; Heterogeneous computing; Machine-learning; Quantum circuit; Quantum Computing; Quantum machine learning; Quantum machines; Rich features; Spoken language understanding; Temporal convolution; Text classification; Convolution},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42; All Open Access, Green Open Access}
}